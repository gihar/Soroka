# Предложения по улучшению логики "Умного выбора" шаблона

Текущая реализация использует гибридный подход (Keyword Matching + Vector Similarity), который эффективен и быстр, но имеет ряд ограничений. Ниже представлены стратегии по улучшению качества рекомендаций, от простых оптимизаций до внедрения новых архитектурных решений.

## 1. Работа с данными и контекстом (Data & Context)

### 1.1. Расширение контекста анализа
**Проблема:** Сейчас анализируются только первые 1500 символов транскрипции. Если встреча начинается с "small talk" или организационных моментов, суть может быть упущена.
**Решение:**
*   **Sliding Window:** Брать 3 фрагмента (начало, середина, конец) и усреднять их эмбеддинги.
*   **Summarization:** Сначала генерировать краткое саммари встречи (через быструю модель), и уже его использовать для поиска шаблона.
*   **Metadata Embedding:** Включать в вектор поиска тему встречи (`meeting_topic`), если она известна заранее (например, из календаря).

### 1.2. Учет структуры участников
**Проблема:** Роли участников игнорируются при выборе, хотя они критичны (например, наличие "Студента" и "Преподавателя" явно указывает на образовательный шаблон).
**Решение:**
*   Добавить эвристику: если есть роли `Teacher`, `Student` -> boost `Educational`.
*   Если есть `Product Owner`, `Scrum Master` -> boost `Scrum/Agile` шаблонов.

## 2. Алгоритмические улучшения (Algorithmic Refinements)

### 2.1. Динамические веса (Dynamic Weighting)
**Проблема:** Веса (`history_boost`, `category_boost`) жестко закодированы (0.3, 0.15).
**Решение:**
*   Вынести веса в конфигурацию.
*   Сделать веса зависимыми от уверенности модели (если `similarity` очень высокий, уменьшать влияние истории, чтобы не застревать в "пузыре фильтров").

### 2.2. Улучшение классификатора (Classifier Upgrade)
**Проблема:** Классификация строится на жестких списках ключевых слов (`meeting_classifier.py`).
**Решение:**
*   **Расширение словарей:** Использовать LLM для генерации синонимов и связанных терминов для каждой категории.
*   **TF-IDF / BM25:** Использовать статистические методы для определения важности слов, вместо простого подсчета вхождений.

### 2.3. Специализированные эмбеддинги
**Проблема:** Используется универсальная модель `paraphrase-multilingual-MiniLM-L12-v2`.
**Решение:**
*   Дообучить (fine-tune) модель на корпусе реальных транскрипций и выбранных шаблонов, чтобы она лучше понимала специфику деловой лексики.

## 3. Интеграция с LLM (LLM Integration)

### 3.1. LLM-Reranking (Двухэтапный выбор)
**Идея:** Использовать текущий алгоритм для отбора топ-5 кандидатов, а финальный выбор доверить "умной" модели.
**Алгоритм:**
1.  `SmartSelector` находит 5 кандидатов.
2.  Формируется промпт для LLM (например, GPT-3.5-turbo или локальная Llama 3):
    > "Вот краткое содержание встречи: {...}. Вот 5 шаблонов: {Названия и описания}. Какой шаблон лучше всего подходит? Верни ID."
3.  LLM принимает финальное решение, учитывая нюансы, недоступные векторному поиску.

### 3.2. LLM-Classification
**Идея:** Заменить `MeetingClassifier` на вызов LLM.
**Плюс:** Высокая точность понимания контекста.
**Минус:** Задержка (latency) и стоимость. Можно использовать только для сложных случаев, когда уверенность обычного классификатора низкая.

## 4. Петля обратной связи (Feedback Loop)

### 4.1. Обучение на действиях пользователя
**Проблема:** Сейчас система учитывает только *факт использования* шаблона (`user_history`), но не *исправления*.
**Решение:**
*   Если система предложила шаблон А, но пользователь выбрал шаблон Б -> это сильный сигнал.
*   Сохранять пару `(embedding_встречи, выбранный_шаблон_ID)` в базу "Negative/Positive Samples".
*   Использовать эти данные для корректировки весов или дообучения классификатора.

### 4.2. Персонализация категорий
**Идея:** Позволить пользователям привязывать свои шаблоны к категориям (Техническая, Бизнес и т.д.) явно, чтобы `Category Boost` работал корректнее для кастомных шаблонов.
