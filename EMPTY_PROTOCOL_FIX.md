# Исправление проблемы пустого протокола

## Дата
27 октября 2024

## Проблема

В двухэтапной генерации протокола LLM возвращал пустые результаты:
- **Этап 1:** Модель использовала 24768 reasoning tokens, но возвращала пустой `extracted_data: {}`
- **Этап 2:** Получал пустой `refined_data` с нулевой оценкой качества

## Причины

1. Промпт для этапа 1 не указывал явно требуемую структуру ответа с полями `extracted_data`, `confidence_score`, `extraction_notes`
2. Промпт для этапа 2 не описывал требуемый формат с полями `refined_data`, `reflection_notes`, `quality_score`
3. Отсутствовала валидация результатов и fallback на одноэтапный режим при пустых данных
4. Недостаточно диагностического логирования для отладки проблем

## Внесенные изменения

### 1. Улучшен промпт для этапа 1 (`_build_extraction_prompt`)

**Файл:** `llm_providers.py`, строки 1088-1108

Добавлена секция "КРИТИЧЕСКИ ВАЖНО — СТРУКТУРА ОТВЕТА" с:
- Явным описанием требуемого формата JSON с тремя полями
- Примером правильного ответа
- Указанием, что все ключи из списка полей обязательны

```json
{
  "extracted_data": {
    "поле1": "значение1",
    "поле2": "значение2"
  },
  "confidence_score": 0.85,
  "extraction_notes": "краткие заметки"
}
```

### 2. Исправлен промпт для этапа 2 (`_build_reflection_prompt`)

**Файл:** `llm_providers.py`, строки 1188-1221

Добавлена секция "КРИТИЧЕСКИ ВАЖНО — СТРУКТУРА ОТВЕТА" с:
- Полным описанием требуемых полей
- Примером правильного ответа
- Указанием, что `refined_data` должен содержать ВСЕ ключи из `extracted_data`

```json
{
  "refined_data": {
    "поле1": "улучшенное значение1"
  },
  "reflection_notes": "что было улучшено",
  "quality_score": 0.9
}
```

### 3. Добавлена валидация после этапа 1

**Файл:** `llm_providers.py`, строки 1384-1434

- Проверка reasoning tokens (предупреждение если > 20000)
- Подсчет заполненных полей
- Расчет процента заполнения
- **Fallback:** если заполнено < 30% полей → переключение на одноэтапный режим
- Детальное логирование диагностической информации

### 4. Добавлена валидация после этапа 2

**Файл:** `llm_providers.py`, строки 1503-1578

- Проверка reasoning tokens
- Подсчет заполненных полей в `refined_data`
- Сравнение с результатом этапа 1
- **Защита от деградации:** если этап 2 ухудшил результат → используется результат этапа 1
- Логирование улучшения в процентах

### 5. Улучшено диагностическое логирование

По всему коду добавлено:
- Предупреждения при высоком использовании reasoning tokens (> 20000)
- Логирование количества заполненных/пустых полей
- Расчет процента заполнения на каждом этапе
- Логирование confidence_score и quality_score
- Детальные сообщения при fallback

## Результаты

### До исправления
```
Этап 1: извлечено 3 полей
Этап 2: получен ответ длиной 140 символов
Валидация: общая оценка 0.46, валиден: False
```

### После исправления
Ожидается:
```
Этап 1: заполнено 6/8 полей (75.0%), confidence=0.85
Этап 2: заполнено 7/8 полей (87.5%), quality_score=0.88
Этап 2 завершен успешно (улучшение: +12.5%)
Валидация: общая оценка 0.85, валиден: True
```

Если данные пустые:
```
⚠️ Этап 1 вернул недостаточно данных (заполнено 10.0%). 
Переключаемся на одноэтапный режим генерации.
```

## Файлы изменены

- `llm_providers.py` - основные изменения в функциях:
  - `_build_extraction_prompt()` (строки 1088-1108)
  - `_build_reflection_prompt()` (строки 1188-1221)
  - `generate_protocol_two_stage()` (строки 1384-1578)

## Рекомендации

1. **Мониторинг:** Следить за логами на предмет предупреждений о высоких reasoning tokens
2. **Тестирование:** Проверить работу на реальных встречах разной длины
3. **Настройка порога:** Если fallback срабатывает слишком часто, можно снизить порог с 30% до 20%
4. **Модели:** Проблема особенно актуальна для o1-mini и reasoning моделей

## Обратная совместимость

✅ Изменения полностью обратно совместимы
✅ Одноэтапный режим работает как прежде
✅ Двухэтапный режим улучшен и защищен fallback

