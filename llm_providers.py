"""
ะะพะดัะปั ะดะปั ะธะฝัะตะณัะฐัะธะธ ั ัะฐะทะปะธัะฝัะผะธ LLM ะฟัะพะฒะฐะนะดะตัะฐะผะธ
"""

import json
import asyncio
import httpx
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, Tuple, List, TYPE_CHECKING
from loguru import logger
from config import settings

import openai
from anthropic import Anthropic

# ะะผะฟะพัั ะดะปั ะบะพะฝัะตะบััะฝะพ-ะทะฐะฒะธัะธะผัั ะฟัะพะผะฟัะพะฒ
# ะะผะฟะพัั ะดะปั ะบะพะฝัะตะบััะฝะพ-ะทะฐะฒะธัะธะผัั ะฟัะพะผะฟัะพะฒ
# from src.services.meeting_classifier import meeting_classifier - MOVED TO LOCAL SCOPE TO AVOID CIRCULAR IMPORT

# ะะผะฟะพัั ะดะปั retry ะปะพะณะธะบะธ
from src.reliability.retry import RetryManager, LLM_RETRY_CONFIG

# ะะผะฟะพัั ะธัะบะปััะตะฝะธะน
from src.exceptions.processing import LLMInsufficientCreditsError

# ะะผะฟะพัั ะฟัะฐะฒะธะป ะดะปั ะฟะพะปะตะน ะฟัะพัะพะบะพะปะฐ ะธ ััะฝะบัะธะธ ะณะตะฝะตัะฐัะธะธ ะดะธะฝะฐะผะธัะตัะบะธั ะฟัะฐะฒะธะป
from src.prompts.prompts import FIELD_SPECIFIC_RULES, _build_field_specific_rules

# ะะผะฟะพัั JSON Schema ะดะปั structured outputs
from src.models.llm_schemas import (
    PROTOCOL_SCHEMA, TWO_STAGE_EXTRACTION_SCHEMA, TWO_STAGE_REFLECTION_SCHEMA
)

# ะะผะฟะพัั ััะธะปะธั ะดะปั ะพะฟัะธะผะธะทะฐัะธะธ ะบะพะฝัะตะบััะฐ
from src.utils.context_extraction import (
    extract_relevant_excerpts,
    build_structure_summary,
    add_prompt_caching_markers,
    build_anthropic_messages_with_caching
)

# ะะผะฟะพัั ััะธะปะธั ะดะปั ะปะพะณะธัะพะฒะฐะฝะธั ะบะตัะธัะพะฒะฐะฝะธั ัะพะบะตะฝะพะฒ
from src.utils.token_cache_logger import log_cached_tokens_usage, check_cache_support




# -------------------------------------------------------------
# ะฃัะธะปะธัะฐ ะดะปั ะฑะตะทะพะฟะฐัะฝะพะณะพ ะฟะฐััะธะฝะณะฐ JSON
# -------------------------------------------------------------
def safe_json_parse(content: str, context: str = "LLM response") -> Dict[str, Any]:
    """
    ะะตะทะพะฟะฐัะฝัะน ะฟะฐััะธะฝะณ JSON ั ะพะฑัะฐะฑะพัะบะพะน ัะฐะทะปะธัะฝัั edge cases.
    
    Args:
        content: ะกััะพะบะฐ ั JSON ะดะปั ะฟะฐััะธะฝะณะฐ
        context: ะะพะฝัะตะบัั ะดะปั ะปะพะณะธัะพะฒะฐะฝะธั (ะฝะฐะฟัะธะผะตั, "OpenAI response")
        
    Returns:
        ะะฐัะฟะฐััะตะฝะฝัะน JSON ัะปะพะฒะฐัั
        
    Raises:
        ValueError: ะัะปะธ ะฝะต ัะดะฐะปะพัั ัะฐัะฟะฐััะธัั JSON ะฟะพัะปะต ะฒัะตั ะฟะพะฟััะพะบ
    """
    if not content or not content.strip():
        raise ValueError(f"ะะพะปััะตะฝ ะฟัััะพะน ะพัะฒะตั ะฒ {context}")
    
    original_content = content
    content_length = len(content)
    
    # ะจะฐะณ 1: ะฃะดะฐะปัะตะผ BOM (Byte Order Mark) ะธ ะฝะตะฒะธะดะธะผัะต ัะธะผะฒะพะปั
    content = content.strip()
    if content.startswith('\ufeff'):
        content = content[1:]
        logger.debug(f"ะฃะดะฐะปะตะฝ BOM ะธะท {context}")
    
    # ะจะฐะณ 2: ะะพะฟััะบะฐ ะฟััะผะพะณะพ ะฟะฐััะธะฝะณะฐ
    try:
        result = json.loads(content)
        logger.debug(f"ะััะผะพะน ะฟะฐััะธะฝะณ JSON ััะฟะตัะตะฝ ะดะปั {context}")
        return result
    except json.JSONDecodeError as e:
        logger.warning(f"ะััะผะพะน ะฟะฐััะธะฝะณ JSON ะฝะต ัะดะฐะปัั ะดะปั {context}: {e}")
    
    # ะจะฐะณ 3: ะฃะดะฐะปัะตะผ markdown ะฑะปะพะบะธ (```json ... ``` ะธะปะธ ``` ... ```)
    import re
    markdown_pattern = r'```(?:json)?\s*\n?(.*?)\n?```'
    markdown_match = re.search(markdown_pattern, content, re.DOTALL)
    if markdown_match:
        content = markdown_match.group(1).strip()
        logger.debug(f"ะะทะฒะปะตัะตะฝ JSON ะธะท markdown ะฑะปะพะบะฐ ะฒ {context}")
        try:
            result = json.loads(content)
            logger.info(f"ะะฐััะธะฝะณ JSON ะฟะพัะปะต ัะดะฐะปะตะฝะธั markdown ััะฟะตัะตะฝ ะดะปั {context}")
            return result
        except json.JSONDecodeError as e:
            logger.warning(f"ะะฐััะธะฝะณ ะฟะพัะปะต ัะดะฐะปะตะฝะธั markdown ะฝะต ัะดะฐะปัั ะดะปั {context}: {e}")
    
    # ะจะฐะณ 4: ะัะตะผ JSON ะพะฑัะตะบั ะฒ ัะตะบััะต (ะผะตะถะดั ะฟะตัะฒะพะน { ะธ ะฟะพัะปะตะดะฝะตะน })
    start_idx = content.find('{')
    end_idx = content.rfind('}') + 1
    
    if start_idx != -1 and end_idx > start_idx:
        json_str = content[start_idx:end_idx]
        logger.debug(f"ะะทะฒะปะตัะตะฝ JSON ะธะท ะฟะพะทะธัะธะธ {start_idx} ะดะพ {end_idx} ะฒ {context}")
        try:
            result = json.loads(json_str)
            logger.info(f"ะะฐััะธะฝะณ ะธะทะฒะปะตัะตะฝะฝะพะณะพ JSON ััะฟะตัะตะฝ ะดะปั {context}")
            return result
        except json.JSONDecodeError as e:
            logger.warning(f"ะะฐััะธะฝะณ ะธะทะฒะปะตัะตะฝะฝะพะณะพ JSON ะฝะต ัะดะฐะปัั ะดะปั {context}: {e}")
    
    # ะจะฐะณ 5: ะะพะฟััะบะฐ ะฝะฐะนัะธ JSON ะผะฐััะธะฒ (ะผะตะถะดั ะฟะตัะฒะพะน [ ะธ ะฟะพัะปะตะดะฝะตะน ])
    start_idx = content.find('[')
    end_idx = content.rfind(']') + 1
    
    if start_idx != -1 and end_idx > start_idx:
        json_str = content[start_idx:end_idx]
        logger.debug(f"ะะทะฒะปะตัะตะฝ JSON ะผะฐััะธะฒ ะธะท ะฟะพะทะธัะธะธ {start_idx} ะดะพ {end_idx} ะฒ {context}")
        try:
            result = json.loads(json_str)
            logger.info(f"ะะฐััะธะฝะณ JSON ะผะฐััะธะฒะฐ ััะฟะตัะตะฝ ะดะปั {context}")
            return result
        except json.JSONDecodeError as e:
            logger.warning(f"ะะฐััะธะฝะณ JSON ะผะฐััะธะฒะฐ ะฝะต ัะดะฐะปัั ะดะปั {context}: {e}")
    
    # ะจะฐะณ 6: ะะพัะปะตะดะฝัั ะฟะพะฟััะบะฐ - ัะดะฐะปัะตะผ ะฒัะต ะดะพ ะฟะตัะฒะพะน { ะธ ะฟะพัะปะต ะฟะพัะปะตะดะฝะตะน }
    # ะธ ะฟััะฐะตะผัั ะธัะฟัะฐะฒะธัั common issues
    try:
        # ะฃะดะฐะปัะตะผ ะบะพะผะผะตะฝัะฐัะธะธ ะฒ ััะธะปะต // ะธ /* */
        content_no_comments = re.sub(r'//.*?$', '', content, flags=re.MULTILINE)
        content_no_comments = re.sub(r'/\*.*?\*/', '', content_no_comments, flags=re.DOTALL)
        
        # ะฃะดะฐะปัะตะผ trailing commas
        content_no_comments = re.sub(r',(\s*[}\]])', r'\1', content_no_comments)
        
        result = json.loads(content_no_comments)
        logger.info(f"ะะฐััะธะฝะณ JSON ะฟะพัะปะต ะพัะธััะบะธ ะบะพะผะผะตะฝัะฐัะธะตะฒ ััะฟะตัะตะฝ ะดะปั {context}")
        return result
    except json.JSONDecodeError:
        pass
    
    # ะัะต ะฟะพะฟััะบะธ ะธััะตัะฟะฐะฝั - ะปะพะณะธััะตะผ ะฟะพะดัะพะฑะฝัั ะธะฝัะพัะผะฐัะธั ะธ ะฒัะฑัะฐััะฒะฐะตะผ ะพัะธะฑะบั
    logger.error(f"โ ะะต ัะดะฐะปะพัั ัะฐัะฟะฐััะธัั JSON ะฒ {context}")
    logger.error(f"ะะปะธะฝะฐ ะพัะฒะตัะฐ: {content_length} ัะธะผะฒะพะปะพะฒ")
    logger.error(f"ะะตัะฒัะต 500 ัะธะผะฒะพะปะพะฒ: {original_content[:500]}")
    logger.error(f"ะะพัะปะตะดะฝะธะต 500 ัะธะผะฒะพะปะพะฒ: {original_content[-500:] if len(original_content) > 500 else ''}")
    
    # ะััะฐะตะผัั ะฝะฐะนัะธ ะฟะพะทะธัะธั ะพัะธะฑะบะธ
    try:
        json.loads(original_content)
    except json.JSONDecodeError as final_error:
        error_pos = getattr(final_error, 'pos', None)
        if error_pos and error_pos < len(original_content):
            # ะะพะบะฐะทัะฒะฐะตะผ ะบะพะฝัะตะบัั ะฒะพะบััะณ ะพัะธะฑะบะธ
            start = max(0, error_pos - 50)
            end = min(len(original_content), error_pos + 50)
            context_str = original_content[start:end]
            logger.error(f"ะะพะฝัะตะบัั ะพัะธะฑะบะธ (ะฟะพะทะธัะธั {error_pos}): ...{context_str}...")
        
        raise ValueError(
            f"ะะต ัะดะฐะปะพัั ัะฐัะฟะฐััะธัั JSON ะฒ {context}: {final_error}. "
            f"ะะปะธะฝะฐ: {content_length} ัะธะผะฒะพะปะพะฒ. "
            f"ะัะพะฒะตัััะต ะปะพะณะธ ะดะปั ะฟะพะดัะพะฑะฝะพััะตะน."
        )
    
    raise ValueError(f"ะะต ัะดะฐะปะพัั ัะฐัะฟะฐััะธัั JSON ะฒ {context}. ะะปะธะฝะฐ: {content_length} ัะธะผะฒะพะปะพะฒ.")




class LLMProvider(ABC):
    """ะะฑัััะฐะบัะฝัะน ะฑะฐะทะพะฒัะน ะบะปะฐัั ะดะปั LLM ะฟัะพะฒะฐะนะดะตัะพะฒ"""
    
    @abstractmethod
    async def generate_protocol(self, transcription: str, template_variables: Dict[str, str], diarization_data: Optional[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:
        """ะะตะฝะตัะธัะพะฒะฐัั ะฟัะพัะพะบะพะป ะฝะฐ ะพัะฝะพะฒะต ััะฐะฝัะบัะธะฟัะธะธ ะธ ัะฐะฑะปะพะฝะฐ"""
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """ะัะพะฒะตัะธัั ะดะพัััะฟะฝะพััั ะฟัะพะฒะฐะนะดะตัะฐ"""
        pass


# -------------------------------------------------------------
# ะฃะฝะธัะธัะธัะพะฒะฐะฝะฝัะต ะฑะธะปะดะตัั ะฟัะพะผะฟัะพะฒ ะดะปั ะฒัะตั ะฟัะพะฒะฐะนะดะตัะพะฒ
# -------------------------------------------------------------
def _build_system_prompt(
    transcription: Optional[str] = None,
    diarization_analysis: Optional[Dict[str, Any]] = None,
    unified_mode: bool = False,
    llm_meeting_type: Optional[str] = None
) -> str:
    """
    ะกััะพะณะฐั ัะธััะตะผะฝะฐั ะฟะพะปะธัะธะบะฐ ะดะปั ะฟะพะปััะตะฝะธั ะฟัะพัะตััะธะพะฝะฐะปัะฝะพะณะพ ะฟัะพัะพะบะพะปะฐ.
    ะะฒัะพะผะฐัะธัะตัะบะธ ะฒัะฑะธัะฐะตั ัะฟะตัะธะฐะปะธะทะธัะพะฒะฐะฝะฝัะน ะฟัะพะผะฟั ะตัะปะธ ะฒะบะปััะตะฝะฐ ะบะปะฐััะธัะธะบะฐัะธั.

    Args:
        transcription: ะขะตะบัั ััะฐะฝัะบัะธะฟัะธะธ (ะดะปั ะบะปะฐััะธัะธะบะฐัะธะธ)
        diarization_analysis: ะะฝะฐะปะธะท ะดะธะฐัะธะทะฐัะธะธ (ะดะปั ะบะปะฐััะธัะธะบะฐัะธะธ)
        unified_mode: ะัะปะธ True, ะธัะฟะพะปัะทัะตั ัะพัะผะฐั UnifiedProtocolSchema
        llm_meeting_type: ะขะธะฟ ะฒัััะตัะธ ะพะฟัะตะดะตะปะตะฝะฝัะน LLM (ะฟัะธะพัะธัะตั ะฝะฐะด ะบะปะฐััะธัะธะบะฐัะพัะพะผ)

    Returns:
        ะกะธััะตะผะฝัะน ะฟัะพะผะฟั (ะฑะฐะทะพะฒัะน ะธะปะธ ัะฟะตัะธะฐะปะธะทะธัะพะฒะฐะฝะฝัะน)
    """
    # ะัะธะพัะธัะตั: LLM-ะพะฟัะตะดะตะปะตะฝะธะต > ะบะปะฐััะธัะธะบะฐัะพั > ะฑะฐะทะพะฒัะน ะฟัะพะผะฟั
    meeting_type = None

    # 1. ะัะปะธ LLM ะพะฟัะตะดะตะปะธะปะฐ ัะธะฟ ะฒัััะตัะธ - ะธัะฟะพะปัะทัะตะผ ะตะณะพ
    if llm_meeting_type:
        meeting_type = llm_meeting_type
        logger.info(f"ะัะฟะพะปัะทัั ัะธะฟ ะฒัััะตัะธ ะพะฟัะตะดะตะปะตะฝะฝัะน LLM: {meeting_type}")
    # 2. ะะฝะฐัะต ะตัะปะธ ะฒะบะปััะตะฝะฐ ะบะปะฐััะธัะธะบะฐัะธั ะธ ะตััั ััะฐะฝัะบัะธะฟัะธั
    elif settings.meeting_type_detection and transcription:
        try:
            from src.services.meeting_classifier import meeting_classifier
            # ะะปะฐััะธัะธัะธััะตะผ ะฒัััะตัั
            meeting_type, _ = meeting_classifier.classify(
                transcription,
                diarization_analysis
            )
            logger.info(f"ะัะฟะพะปัะทัั ัะธะฟ ะฒัััะตัะธ ะพะฟัะตะดะตะปะตะฝะฝัะน ะบะปะฐััะธัะธะบะฐัะพัะพะผ: {meeting_type}")

        except Exception as e:
            logger.warning(f"ะัะธะฑะบะฐ ะฟัะธ ะบะปะฐััะธัะธะบะฐัะธะธ ะฒัััะตัะธ: {e}. ะัะฟะพะปัะทัะตะผ ะฑะฐะทะพะฒัะน ะฟัะพะผะฟั")

    # ะัะปะธ ะพะฟัะตะดะตะปะตะฝ ัะธะฟ ะฒัััะตัะธ, ะปะพะณะธััะตะผ ะดะปั ะธะฝัะพัะผะฐัะธะธ (ะฝะพ ะธัะฟะพะปัะทัะตะผ ะฑะฐะทะพะฒัะน ะฟัะพะผะฟั)
    if meeting_type:
        logger.info(f"ะะฟัะตะดะตะปะตะฝ ัะธะฟ ะฒัััะตัะธ: {meeting_type} (ะธัะฟะพะปัะทัะตะผ ะฑะฐะทะพะฒัะน ะฟัะพะผะฟั)")
    
    # ะะฐะทะพะฒัะน ะฟัะพะผะฟั (ะพะฑัะธะน ะดะปั ะฒัะตั ัะตะถะธะผะพะฒ)
    base_prompt = (
        "ะขั โ ะฟัะพัะตััะธะพะฝะฐะปัะฝัะน ะฟัะพัะพะบะพะปะธัั ะฒัััะตะน ะบะฒะฐะปะธัะธะบะฐัะธะธ ั ะพะฟััะพะผ ะดะพะบัะผะตะฝัะธัะพะฒะฐะฝะธั "
        "ะดะตะปะพะฒัั ะฒัััะตั, ัะพะฒะตัะฐะฝะธะน ะธ ะฟะตัะตะณะพะฒะพัะพะฒ.\n\n"
        
        "ะขะะะฏ ะะะะฌ:\n"
        "- ะะทะฒะปะตะบะฐัั ะธ ััััะบัััะธัะพะฒะฐัั ะบะปััะตะฒัั ะธะฝัะพัะผะฐัะธั ะธะท ััะตะฝะพะณัะฐะผะผ ะฒัััะตั\n"
        "- ะกะพะทะดะฐะฒะฐัั ัะตัะบะธะต, ะปะฐะบะพะฝะธัะฝัะต ะธ ะธะฝัะพัะผะฐัะธะฒะฝัะต ะฟัะพัะพะบะพะปั\n"
        "- ะกะพััะฐะฝััั ะพะฑัะตะบัะธะฒะฝะพััั ะธ ัะฐะบัะพะปะพะณะธัะตัะบัั ัะพัะฝะพััั\n\n"
        
        "ะคะฃะะะะะะะขะะะฌะะซะ ะะะะะฆะะะซ ะขะะงะะะกะขะ:\n"
        "- ะะะกะะะฎะขะะะฏ ะะะะะะขะ: ะะฝะฐะปะธะทะธััะน ะะกะฎ ััะฐะฝัะบัะธะฟัะธั ะพั ะฟะตัะฒะพะณะพ ะดะพ ะฟะพัะปะตะดะฝะตะณะพ ัะปะพะฒะฐ. "
        "ะะฐะถะดะฐั ัะฟะพะผัะฝััะฐั ัะตะผะฐ, ะธะดะตั, ะฒะพะฟัะพั ะธะปะธ ะบะพะผะผะตะฝัะฐัะธะน ะดะพะปะถะฝั ะฑััั ะพััะฐะถะตะฝั ะฒ ะฟัะพัะพะบะพะปะต\n"
        "- ะคะะะขะะงะะกะะะฏ ะขะะงะะะกะขะฌ: ะัะฟะพะปัะทัะน ะขะะะฌะะ ะธะฝัะพัะผะฐัะธั, ัะฒะฝะพ ะฟัะธัััััะฒััััั ะฒ ััะฐะฝัะบัะธะฟัะธะธ. "
        "ะะ ะดะพะฑะฐะฒะปัะน, ะะ ะดะพะผััะปะธะฒะฐะน, ะะ ะธะฝัะตัะฟัะตัะธััะน ัะฒะตัั ัะบะฐะทะฐะฝะฝะพะณะพ\n"
        "- ะกะะฅะะะะะะะ ะะะะขะะะกะขะ: ะคะธะบัะธััะน ะฝะต ัะพะปัะบะพ ะงะขะ ะฑัะปะพ ัะบะฐะทะฐะฝะพ, ะฝะพ ะธ ะะะ ะพะฑััะถะดะฐะปะพัั "
        "(ัะพะฝ ะดะธัะบัััะธะธ, ััะพะฒะตะฝั ัะพะณะปะฐัะธั/ะฝะตัะพะณะปะฐัะธั, ััะตะฟะตะฝั ะฟัะพัะฐะฑะพัะบะธ ะฒะพะฟัะพัะฐ)\n"
        "- ะะะขะะะะะะฆะะฏ ะะะ ะะะขะะะฌ: ะัะปะธ ััะฐััะฝะธะบ ัะฟะพะผัะฝัะป ะบะพะฝะบัะตัะฝัะน ะฟัะธะผะตั, ัะธััั, ะดะฐัั, ะธะผั, "
        "ัะตัะฝะพะปะพะณะธั ะธะปะธ ะปัะฑัั ัะฟะตัะธัะธัะตัะบัั ะดะตัะฐะปั โ ััะพ ะะะฏะะะขะะะฌะะ ะดะพะปะถะฝะพ ะฑััั ะฒ ะฟัะพัะพะบะพะปะต\n"
        "- ะะขะะะะฃะฆะะฏ ะะซะกะะะะซะะะะะ: ะัะปะธ ะฒ ััะฐะฝัะบัะธะฟัะธะธ ัะบะฐะทะฐะฝั ะธะผะตะฝะฐ ััะฐััะฝะธะบะพะฒ, ะะกะะะะ ัะบะฐะทัะฒะฐะน, "
        "ะบัะพ ััะพ ัะบะฐะทะฐะป (ะฝะฐะฟัะธะผะตั: \"ะะฒะฐะฝ ะฟัะตะดะปะพะถะธะป...\", \"ะะฐัะธั ะพัะผะตัะธะปะฐ...\")\n"
        "- ะะขะะะซะขะซะ ะะะะะะกะซ: ะคะธะบัะธััะน ะะกะ ะฝะตะทะฐะบััััะต ะฒะพะฟัะพัั, ัะตะผั, ััะตะฑัััะธะต ะดะพะฟะพะปะฝะธัะตะปัะฝะพะณะพ ะพะฑััะถะดะตะฝะธั, "
        "ะธ ะผะพะผะตะฝัั ะฝะตะพะฟัะตะดะตะปะตะฝะฝะพััะธ\n\n"
        
        "ะะะะะะะ ะะะะะะะขะะ ะกะะะฆะะคะะงะะกะะะ ะะะคะะะะะฆะะ:\n"
        "- ะัะฒะตัััะฒะตะฝะฝัะต ะปะธัะฐ: ะฃะบะฐะทัะฒะฐะน ะขะะะฌะะ ะตัะปะธ ัะฒะฝะพ ะฝะฐะทะฒะฐะฝั ะฒ ััะฐะฝัะบัะธะฟัะธะธ. "
        "ะัะปะธ ัะบะฐะทะฐะฝะพ \"ะบัะพ-ัะพ ะดะพะปะถะตะฝ ััะพ ัะดะตะปะฐัั\" ะฑะตะท ะธะผะตะฝะธ โ ะฟะธัะธ \"ะฝะต ะพะฟัะตะดะตะปะตะฝ\" ะธะปะธ \"ะะต ัะบะฐะทะฐะฝะพ\"\n"
        "- ะกัะพะบะธ ะธ ะดะฐัั: ะฃะบะฐะทัะฒะฐะน ะขะะะฌะะ ะตัะปะธ ัะฒะฝะพ ัะฟะพะผัะฝััั. ะัะปะธ ัะบะฐะทะฐะฝะพ \"ัะบะพัะพ\" ะธะปะธ \"ะฒ ะฑะปะธะถะฐะนัะตะต ะฒัะตะผั\" โ "
        "ัะพััะฐะฝัะน ััั ัะพัะผัะปะธัะพะฒะบั\n"
        "- ะะตัะตะฝะธั: ะงะตัะบะพ ัะฐะทะปะธัะฐะน ะผะตะถะดั \"ะฟัะธะฝััะพ ัะตัะตะฝะธะต\" ะธ \"ะพะฑััะถะดะฐะปะฐัั ะฒะพะทะผะพะถะฝะพััั\". "
        "ะคะธะบัะธััะน ััะพะฒะตะฝั ะพะฟัะตะดะตะปะตะฝะฝะพััะธ\n"
        "- ะฆะธััั ะธ ะผะตััะธะบะธ: ะะฐะฟะธััะฒะฐะน ะฒัะต ัะฟะพะผัะฝัััะต ัะธัะปะฐ, ะฟัะพัะตะฝัั, ะฑัะดะถะตัั, ััะพะบะธ ัะพัะฝะพ ะบะฐะบ ะฒ ััะฐะฝัะบัะธะฟัะธะธ\n\n"
        
        "ะะะะะฆะะะซ ะะะะะขะซ:\n"
        "1. ะขะะงะะะกะขะฌ: ะัะฟะพะปัะทัะน ัะพะปัะบะพ ัะฐะบัั, ัะฒะฝะพ ะฟัะธัััััะฒัััะธะต ะฒ ััะตะฝะพะณัะฐะผะผะต\n"
        "2. ะะะข ะะะะซะกะะะ: ะะต ะดะพะดัะผัะฒะฐะน, ะฝะต ะธะฝัะตัะฟัะตัะธััะน, ะฝะต ะดะพะฑะฐะฒะปัะน ะธะฝัะพัะผะฐัะธั ะพั ัะตะฑั\n"
        "3. ะะะะขะะะกะข: ะัะปะธ ัะฟะพะผะธะฝะฐะตััั ัะพะปั/ะดะพะปะถะฝะพััั/ััะพะบ/ััะผะผะฐ โ ัะบะฐะถะธ ะธั; ะตัะปะธ ะฝะตั โ ะฝะต ะฟัะธะดัะผัะฒะฐะน\n"
        "4. ะะะะขะะะกะขะฌ: ะะทะปะฐะณะฐะน ัััั ะฑะตะท ะฒะพะดั, ะธะทะฑะตะณะฐะน ะธะทะฑััะพัะฝัั ะดะตัะฐะปะตะน\n"
        "5. ะขะะะะะะะะะะะฏ: ะกะพััะฐะฝัะน ะฟัะพัะตััะธะพะฝะฐะปัะฝัะต ัะตัะผะธะฝั ะธ ะฝะฐะทะฒะฐะฝะธั ะบะฐะบ ะฒ ะพัะธะณะธะฝะฐะปะต\n"
        "6. ะกะขะะะฌ: ะัะธัะธะฐะปัะฝะพ-ะดะตะปะพะฒะพะน ัะทัะบ ะฑะตะท ัะฐะทะณะพะฒะพัะฝัั ะพะฑะพัะพัะพะฒ\n\n"
        
        "๐จ ะะะะขะะงะะกะะ ะะะะะ - ะคะะะะะข ะะะะ ะฃะงะะกะขะะะะะ ะ ะะะะขะะะะะ:\n"
        "ะ ัะตะบัะธะธ 'ะฃัะฐััะฝะธะบะธ' ะฟัะพัะพะบะพะปะฐ ะธัะฟะพะปัะทัะน ะธะผะตะฝะฐ ะฒ ัะพัะผะฐัะต 'ะะผั ะคะฐะผะธะปะธั' ะะะ ะพััะตััะฒะฐ!\n"
        "ะัะปะธ ะฟัะตะดะพััะฐะฒะปะตะฝ ัะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ - ะะะะะะฃะ ะธะผะตะฝะฐ ะขะะงะะ ะบะฐะบ ะพะฝะธ ัะบะฐะทะฐะฝั ะฒ ัะฟะธัะบะต.\n\n"
        "โ ะะะะะะะะะฌะะ: ัะพะปัะบะพ ะธะผั ('ะกะพััั', 'ะะฐะปะธะฝะฐ') ะธะปะธ ั ะพััะตััะฒะพะผ ('ะกะพััั ะฎััะตะฒะฝะฐ ะัะธะฟะพะฒะฐ')\n"
        "โ ะะะะะะะฌะะ: 'ะกะพััั ะัะธะฟะพะฒะฐ', 'ะะฐะปะธะฝะฐ ะฏะผะบะธะฝะฐ', 'ะะปะฐะดะธะผะธั ะะพะปะธะบะพะฒ'\n\n"
        "ะะะะะะะะะะะ ะฃะงะะกะขะะะะะ ะะ ะขะะะะกะะะะะฆะะ:\n"
        "โ๏ธ ะัะปะธ ัะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ ะฝะต ะฟัะตะดะพััะฐะฒะปะตะฝ ัะฒะฝะพ:\n"
        "- ะะทะฒะปะตะบะฐะน ะธะผะตะฝะฐ ะขะะะฌะะ ะธะท ัะฒะฝัั ัะฟะพะผะธะฝะฐะฝะธะน ะฒ ััะฐะฝัะบัะธะฟัะธะธ\n"
        "- ะััะพัะฝะธะบะธ: ะฟัะตะดััะฐะฒะปะตะฝะธั ('ะะตะฝั ะทะพะฒัั...'), ะพะฑัะฐัะตะฝะธั ('ะกะฒะตัะฐ, ะบะฐะบ ะดัะผะฐะตัั?')\n"
        "- ะัะตะพะฑัะฐะทัะน ัะผะตะฝััะธัะตะปัะฝัะต ะฒ ะฟะพะปะฝัะต: ะกะฒะตัะฐโะกะฒะตัะปะฐะฝะฐ, ะะตัะฐโะะปะตะบัะตะน\n"
        "- ะัะฟะพะปัะทัะน ัะพัะผะฐั 'ะะผั ะคะฐะผะธะปะธั' ะณะดะต ะฒะพะทะผะพะถะฝะพ\n"
        "- ะะกะะ ะธะผั ะฝะต ะพะฟัะตะดะตะปะธัั - ะพััะฐะฒะปัะน ะผะตัะบั ัะฟะธะบะตัะฐ (SPEAKER_1, SPEAKER_2)\n"
        "- โ ะะ ะฟัะธะดัะผัะฒะฐะน ะธะผะตะฝะฐ! ะะ ะธัะฟะพะปัะทัะน 'ะฃัะฐััะฝะธะบ 1', 'ะะพะปะปะตะณะฐ'\n"
        "- โ ะะ ะดัะฑะปะธััะน: ะตัะปะธ ะกะฒะตัะฐ = SPEAKER_1, ะฝะต ะดะพะฑะฐะฒะปัะน ะกะฒะตัะปะฐะฝั ะพัะดะตะปัะฝะพ\n\n"
        
        "ะคะะะะะขะะะะะะะะ ะะะกะฃะะะะะะฏ:\n"
        "ะัะปะธ ะณััะฟะฟะธััะตัั ะพะฑััะถะดะตะฝะธะต ะฟะพ ัะตะผะฐะผ/ะบะปะฐััะตัะฐะผ:\n"
        "- ะะ ะฟะธัะธ ัะปะพะฒะพ 'ะะปะฐััะตั', ัะพะปัะบะพ ะฝะฐะทะฒะฐะฝะธะต ัะตะผั ั ะผะฐัะบะตัะพะผ: 'โข **ะะฐะทะฒะฐะฝะธะต ัะตะผั**'\n"
        "- ะะฐะถะดัั ะธะดะตั/ะฒััะบะฐะทัะฒะฐะฝะธะต/ะฟะพะทะธัะธั ั ะฝะพะฒะพะน ัััะพะบะธ\n"
        "- ะคะพัะผะฐั ะฒััะบะฐะทัะฒะฐะฝะธั: 'ะะผั ะะฒัะพัะฐ: ัะตะบัั' (ะฑะตะท ัะปะพะฒะฐ 'ะะดะตั', ะฑะตะท ัะบะพะฑะพะบ)\n"
        "- ะะตะถะดั ัะตะผะฐัะธัะตัะบะธะผะธ ะฑะปะพะบะฐะผะธ ะพััะฐะฒะปัะน ะฟััััั ัััะพะบั ะดะปั ะฒะธะทัะฐะปัะฝะพะณะพ ัะฐะทะดะตะปะตะฝะธั\n\n"
        "ะัะธะผะตัั:\n"
        "โ ะะะะะะะฌะะ:\n"
        "โข **ะััะธัะตะบัััะฝัะต ัะตัะตะฝะธั**\n\n"
        "ะะปะตะบัะตะน ะขะธะผัะตะฝะบะพ: ะฟัะตะดะปะพะถะธะป ะธัะฟะพะปัะทะพะฒะฐัั ะผะธะบัะพัะตัะฒะธัะฝัั ะฐััะธัะตะบัััั\n\n"
        "ะะฐัะธั ะะฒะฐะฝะพะฒะฐ: ะฟะพะดะดะตัะถะฐะปะฐ, ะดะพะฑะฐะฒะธะปะฐ ะฟัะพ ะฒะฐะถะฝะพััั API gateway\n\n"
        "โ ะะะะะะะะะฌะะ:\n"
        "โข ะะปะฐััะตั ยซะััะธัะตะบัััะฝัะต ัะตัะตะฝะธัยป: ะะดะตั (ะะปะตะบัะตะน ะขะธะผัะตะฝะบะพ): ะฟัะตะดะปะพะถะธะป...\n\n"
        
        "ะงะขะ ะะะะะะะะะะะขะฌ:\n"
        "- ะะตะถะดะพะผะตัะธั (ั-ั, ะผ-ะผ, ะฝั, ะฒะพั)\n"
        "- ะะพะฒัะพัั ะธ ะทะฐะฟะธะฝะบะธ\n"
        "- ะะฒะพะดะฝัะต ััะฐะทั ะฑะตะท ัะผััะปะพะฒะพะน ะฝะฐะณััะทะบะธ\n"
        "- ะัะฒะปะตัะตะฝะฝัะต ัะฐะทะณะพะฒะพัั ะฝะต ะฟะพ ัะตะผะต ะฒัััะตัะธ\n\n"
        
        "ะงะขะ ะะซะะะะฏะขะฌ:\n"
        "- ะะพะฝะบัะตัะฝัะต ัะตัะตะฝะธั ะธ ัะตะทะพะปััะธะธ\n"
        "- ะะพัััะตะฝะธั ั ัะบะฐะทะฐะฝะธะตะผ ะธัะฟะพะปะฝะธัะตะปะตะน (ะตัะปะธ ัะฟะพะผัะฝััั)\n"
        "- ะกัะพะบะธ, ััะผะผั, ะฟะพะบะฐะทะฐัะตะปะธ (ัะพะปัะบะพ ะตัะปะธ ัะฒะฝะพ ะฝะฐะทะฒะฐะฝั)\n"
        "- ะะปััะตะฒัะต ะฟัะพะฑะปะตะผั ะธ ะธั ัะตัะตะฝะธั\n"
        "- ะกะพะณะปะฐัะพะฒะฐะฝะฝัะต ะดะพะณะพะฒะพัะตะฝะฝะพััะธ\n"
        "- ะฆะธััั, ะผะตััะธะบะธ, ะบะพะฝะบัะตัะฝัะต ะฟัะธะผะตัั (ะะะฏะะะขะะะฌะะ ะฒะบะปััะฐะน ะฒัะต ัะฟะพะผัะฝัััะต)\n"
        "- ะัะต ัะตะผั ะพะฑััะถะดะตะฝะธั ั ัะบะฐะทะฐะฝะธะตะผ ะบัะพ ััะพ ัะบะฐะทะฐะป\n"
        "- ะะพะผะตะฝัั ะฝะตัะพะณะปะฐัะธั, ะฐะปััะตัะฝะฐัะธะฒะฝัะต ะผะฝะตะฝะธั, ะฝะตัะตัะตะฝะฝัะต ะฒะพะฟัะพัั\n\n"
        
        "ะคะะะะะข ะะซะะะะ:\n"
        "ะะตัะฝะธ JSON ะฒ ัะพัะผะฐัะต ััะตะผั. ะัะปะธ ะดะฐะฝะฝัะต ะพััััััะฒััั ะธะปะธ ะฝะตะพะดะฝะพะทะฝะฐัะฝั โ ะธัะฟะพะปัะทัะน 'ะะต ัะบะฐะทะฐะฝะพ'.\n\n"
    )
    
    # ะะฐะทะฝัะต ะฟัะธะผะตัั ะฒ ะทะฐะฒะธัะธะผะพััะธ ะพั ัะตะถะธะผะฐ
    if unified_mode:
        # ะัะธะผะตัั ะดะปั UnifiedProtocolSchema
        return base_prompt + (
            "ะะะะขะะงะะกะะ ะะะะะ โ ัะพัะผะฐัะธัะพะฒะฐะฝะธะต ะทะฝะฐัะตะฝะธะน ะฟะพะปะตะน ะฟัะพัะพะบะพะปะฐ:\n"
            "- ะะฝะฐัะตะฝะธั ะฟะพะปะตะน ะ protocol_data ะดะพะปะถะฝั ะฑััั ะะะะกะขะซะะ ะกะขะะะะะะ (string)\n"
            "- ะะ ะธัะฟะพะปัะทัะน ะฒะปะพะถะตะฝะฝัะต ะพะฑัะตะบัั {} ะธะปะธ ะผะฐััะธะฒั [] ะฒะฝัััะธ ะทะฝะฐัะตะฝะธะน protocol_data\n"
            "- ะกะฟะธัะบะธ ัะพัะผะฐัะธััะน ะบะฐะบ ะผะฝะพะณะพัััะพัะฝัะน ัะตะบัั ั ะผะฐัะบะตัะฐะผะธ '- ' (ะดะตัะธั + ะฟัะพะฑะตะป)\n"
            "- ะะฐัั ะธ ะฒัะตะผั: ะฟัะพััะพะน ัะตะบัั, ะฝะฐะฟัะธะผะตั '20 ะพะบััะฑัั 2024, 14:30'\n"
            "- ะฃัะฐััะฝะธะบะธ: ะบะฐะถะดะพะต ะธะผั ั ะฝะพะฒะพะน ัััะพะบะธ ัะตัะตะท \\n, ะะะ ัะพะปะตะน!\n"
            "- ะะตัะตะฝะธั ะธ ะทะฐะดะฐัะธ: ะผะฝะพะณะพัััะพัะฝัะน ัะตะบัั ัะพ ัะฟะธัะบะพะผ ัะตัะตะท \\n, ะบะฐะถะดัะน ะฟัะฝะบั ั '- '\n\n"
            
            "ะคะะะะะขะะะะะะะะ ะกะะะกะะะ:\n"
            "- ะะฝัััะธ ะทะฝะฐัะตะฝะธะน JSON ะฟะพะปะตะน: ะธัะฟะพะปัะทัะน ะพะดะธะฝะฐัะฝัะน \\n ะดะปั ัะฐะทะดะตะปะตะฝะธั ัะปะตะผะตะฝัะพะฒ ัะฟะธัะบะฐ\n"
            "- ะะปั ะฒะธะทัะฐะปัะฝะพะณะพ ัะฐะทะดะตะปะตะฝะธั ัะตะผะฐัะธัะตัะบะธั ะฑะปะพะบะพะฒ ะฒ ะพะฑััะถะดะตะฝะธะธ: ะธัะฟะพะปัะทัะน ะดะฒะพะนะฝะพะน \\n\\n\n\n"
            
            "โ๏ธ ะะกะะะฎะงะะะะ: ะฟะพะปะต 'self_reflection' ะะะะะะ ะฑััั ะพะฑัะตะบัะพะผ ัะพ ััััะบัััะพะน:\n\n"
            "ะกัััะบัััะฐ ะฟะพะปั self_reflection:\n"
            "- completeness (ัะธัะปะพ 0.0-1.0): ะฟะพะปะฝะพัะฐ ะธะทะฒะปะตัะตะฝะธั ะธะฝัะพัะผะฐัะธะธ\n"
            "- missing_info (ะผะฐััะธะฒ ัััะพะบ): ััะพ ะฝะต ัะดะฐะปะพัั ะธะทะฒะปะตัั\n"
            "- ambiguous_points (ะผะฐััะธะฒ ัััะพะบ): ะฝะตะพะดะฝะพะทะฝะฐัะฝัะต ะผะพะผะตะฝัั\n"
            "- quality_concerns (ะผะฐััะธะฒ ัััะพะบ): ะฟัะพะฑะปะตะผั ะบะฐัะตััะฒะฐ ะดะฐะฝะฝัั\n\n"
            "ะัะธะผะตั:\n"
            "{\n"
            '  "completeness": 0.9,\n'
            '  "missing_info": ["ัะพัะฝัะต ััะพะบะธ ะดะปั ะทะฐะดะฐัะธ 3"],\n'
            '  "ambiguous_points": [],\n'
            '  "quality_concerns": []\n'
            "}\n\n"
            
            "ะะะะะะ ะะะะะะะฌะะะะ JSON (UnifiedProtocolSchema):\n"
            "{\n"
            '  "protocol_data": {\n'
            '    "date": "20 ะพะบััะฑัั 2024",\n'
            '    "time": "14:30",\n'
            '    "participants": "ะะบัะฐะฝะฐ ะะฒะฐะฝะพะฒะฐ\\nะะฐะปะธะฝะฐ ะะตััะพะฒะฐ\\nะะปะตะบัะตะน ะกะผะธัะฝะพะฒ",\n'
            '    "decisions": "- ะะตัะตะฝะธะต 1\\n- ะะตัะตะฝะธะต 2\\n- ะะตัะตะฝะธะต 3"\n'
            '  },\n'
            '  "self_reflection": {\n'
            '    "completeness": 0.9,\n'
            '    "missing_info": ["ัะพัะฝัะต ััะพะบะธ ะดะปั ะทะฐะดะฐัะธ 3"],\n'
            '    "ambiguous_points": [],\n'
            '    "quality_concerns": []\n'
            '  },\n'
            '  "confidence_score": 0.85,\n'
            '  "quality_notes": "ะัะต ะพัะฝะพะฒะฝัะต ะผะพะผะตะฝัั ะธะทะฒะปะตัะตะฝั, ะพะดะฝะฐ ะทะฐะดะฐัะฐ ะฑะตะท ะบะพะฝะบัะตัะฝะพะณะพ ััะพะบะฐ"\n'
            "}\n\n"
            "ะะะฆะะะะะะฌะะซะ ะะะะฏ (ะดะพะฑะฐะฒะปัะน ะขะะะฌะะ ะตัะปะธ ัะดะฐะปะพัั ัะพะฟะพััะฐะฒะธัั ัะฟะธะบะตัะพะฒ ั ััะฐััะฝะธะบะฐะผะธ):\n"
            "- detected_speaker_mapping (ะพะฑัะตะบั): ัะพะฟะพััะฐะฒะปะตะฝะธะต SPEAKER_N โ ะธะผั ััะฐััะฝะธะบะฐ\n"
            "- speaker_confidence_scores (ะพะฑัะตะบั): ัะฒะตัะตะฝะฝะพััั ะดะปั ะบะฐะถะดะพะณะพ ัะฟะธะบะตัะฐ (0.0-1.0)\n"
            "- unmapped_speakers (ะผะฐััะธะฒ ัััะพะบ): ัะฟะธัะพะบ ะฝะตัะพะฟะพััะฐะฒะปะตะฝะฝัั ัะฟะธะบะตัะพะฒ\n"
            "- mapping_notes (ัััะพะบะฐ): ะทะฐะผะตัะบะธ ะฟะพ ัะพะฟะพััะฐะฒะปะตะฝะธั\n\n"
            "ะัะธะผะตั ั ะพะฟัะธะพะฝะฐะปัะฝัะผะธ ะฟะพะปัะผะธ:\n"
            "{\n"
            '  "protocol_data": {...},\n'
            '  "self_reflection": {...},\n'
            '  "confidence_score": 0.9,\n'
            '  "quality_notes": "...",\n'
            '  "detected_speaker_mapping": {"SPEAKER_1": "ะะบัะฐะฝะฐ ะะฒะฐะฝะพะฒะฐ", "SPEAKER_2": "ะะฐะปะธะฝะฐ ะะตััะพะฒะฐ"},\n'
            '  "speaker_confidence_scores": {"SPEAKER_1": 0.95, "SPEAKER_2": 0.92},\n'
            '  "unmapped_speakers": [],\n'
            '  "mapping_notes": "ะัะต ัะฟะธะบะตัั ัะพะฟะพััะฐะฒะปะตะฝั"\n'
            "}\n\n"
            
            "ะะะะะะ ะะะะะะะะะฌะะะะ JSON (ะะ ะะะะะ ะขะะ):\n"
            "{\n"
            '  "date": "20 ะพะบััะฑัั 2024",  โ ะฟะพะปะต ะดัะฑะปะธััะตััั (ะตััั ะธ ัะฝะฐััะถะธ, ะธ ะฒะฝัััะธ protocol_data)\n'
            '  "protocol_data": {\n'
            '    "date": {"day": 20, "month": "ะพะบััะฑัั"},  โ ะฒะปะพะถะตะฝะฝัะน ะพะฑัะตะบั ะฒ ะทะฝะฐัะตะฝะธะธ\n'
            '    "participants": ["ะะบัะฐะฝะฐ", "ะะฐะปั"]  โ ะผะฐััะธะฒ ะฒะผะตััะพ ัััะพะบะธ\n'
            '  }\n'
            "}\n\n"
            "๐จ ะกะขะะะะะกะขะฌ ะกะฅะะะซ:\n"
            "- ะกัะตะผะฐ ัััะพะณะฐั (strict mode): ะะ ะดะพะฑะฐะฒะปัะน ะดะพะฟะพะปะฝะธัะตะปัะฝัะต ะฟะพะปั, ะฝะต ัะบะฐะทะฐะฝะฝัะต ะฒ ััะตะผะต\n"
            "- ะะกะ ะฟะพะปั ะธะท template_variables ะะะะะะซ ะฟัะธัััััะฒะพะฒะฐัั ะฒ protocol_data\n"
            "- ะัะปะธ ะฟะพะปะต ะฝะต ะผะพะถะตั ะฑััั ะทะฐะฟะพะปะฝะตะฝะพ - ะธัะฟะพะปัะทัะน 'ะะต ัะบะฐะทะฐะฝะพ', ะฝะพ ะะ ะฟัะพะฟััะบะฐะน ะฟะพะปะต\n"
            "- ะะฟัะธะพะฝะฐะปัะฝัะต ะฟะพะปั speaker mapping ะดะพะฑะฐะฒะปัะน ะขะะะฌะะ ะตัะปะธ ัะดะฐะปะพัั ัะพะฟะพััะฐะฒะธัั ัะฟะธะบะตัะพะฒ\n"
            "- ะัะฟะพะปัะทัะน ะฟัะฐะฒะธะปัะฝัะต ะฝะฐะทะฒะฐะฝะธั ะฟะพะปะตะน: ะฝะต 'speaker_mapping', ะฐ 'detected_speaker_mapping'"
        )
    else:
        # ะัะธะผะตัั ะดะปั ะพะฑััะฝะพะณะพ ProtocolSchema
        return base_prompt + (
            "ะะะะขะะงะะกะะ ะะะะะ โ ัะพัะผะฐัะธัะพะฒะฐะฝะธะต ะทะฝะฐัะตะฝะธะน ะฟะพะปะตะน ะฟัะพัะพะบะพะปะฐ:\n"
            "- ะะกะ ะทะฝะฐัะตะฝะธั ะฟะพะปะตะน ะดะพะปะถะฝั ะฑััั ะะะะกะขะซะะ ะกะขะะะะะะ (string), ะฝะต ะพะฑัะตะบัะฐะผะธ ะธะปะธ ะผะฐััะธะฒะฐะผะธ\n"
            "- ะะ ะธัะฟะพะปัะทัะน ะฒะปะพะถะตะฝะฝัะต ะพะฑัะตะบัั {} ะธะปะธ ะผะฐััะธะฒั [] ะฒ ะบะฐัะตััะฒะต ะทะฝะฐัะตะฝะธะน ะฟะพะปะตะน ะฟัะพัะพะบะพะปะฐ\n"
            "- ะกะฟะธัะบะธ ัะพัะผะฐัะธััะน ะบะฐะบ ะผะฝะพะณะพัััะพัะฝัะน ัะตะบัั ั ะผะฐัะบะตัะฐะผะธ '- ' (ะดะตัะธั + ะฟัะพะฑะตะป)\n"
            "- ะะฐัั ะธ ะฒัะตะผั: ะฟัะพััะพะน ัะตะบัั, ะฝะฐะฟัะธะผะตั '20 ะพะบััะฑัั 2024, 14:30'\n"
            "- ะฃัะฐััะฝะธะบะธ: ะบะฐะถะดะพะต ะธะผั ั ะฝะพะฒะพะน ัััะพะบะธ ัะตัะตะท \\n, ะะะ ัะพะปะตะน!, ะฝะฐะฟัะธะผะตั 'ะะฒะฐะฝ ะะตััะพะฒ\\nะะฐัะธั ะกะธะดะพัะพะฒะฐ\\nะะปะตะบัะตะน ะกะผะธัะฝะพะฒ'\n"
            "- ะะตัะตะฝะธั ะธ ะทะฐะดะฐัะธ: ะผะฝะพะณะพัััะพัะฝัะน ัะตะบัั ัะพ ัะฟะธัะบะพะผ ัะตัะตะท \\n, ะบะฐะถะดัะน ะฟัะฝะบั ั '- '\n\n"
            
            "ะคะะะะะขะะะะะะะะ ะกะะะกะะะ:\n"
            "- ะะฝัััะธ ะทะฝะฐัะตะฝะธะน JSON ะฟะพะปะตะน: ะธัะฟะพะปัะทัะน ะพะดะธะฝะฐัะฝัะน \\n ะดะปั ัะฐะทะดะตะปะตะฝะธั ัะปะตะผะตะฝัะพะฒ ัะฟะธัะบะฐ\n"
            "- ะะปั ะฒะธะทัะฐะปัะฝะพะณะพ ัะฐะทะดะตะปะตะฝะธั ัะตะผะฐัะธัะตัะบะธั ะฑะปะพะบะพะฒ ะฒ ะพะฑััะถะดะตะฝะธะธ: ะธัะฟะพะปัะทัะน ะดะฒะพะนะฝะพะน \\n\\n\n\n"
            
            "ะะะะะะ ะะะะะะะฌะะะะ JSON:\n"
            "{\n"
            '  "date": "20 ะพะบััะฑัั 2024",\n'
            '  "time": "14:30",\n'
            '  "participants": "ะะบัะฐะฝะฐ ะะฒะฐะฝะพะฒะฐ\\nะะฐะปะธะฝะฐ ะะตััะพะฒะฐ\\nะะปะตะบัะตะน ะกะผะธัะฝะพะฒ",\n'
            '  "decisions": "- ะะตัะตะฝะธะต 1\\n- ะะตัะตะฝะธะต 2\\n- ะะตัะตะฝะธะต 3"\n'
            "}\n\n"
            
            "ะะะะะะ ะะะะะะะะะฌะะะะ JSON (ะะ ะะะะะ ะขะะ):\n"
            "{\n"
            '  "date": {"day": 20, "month": "ะพะบััะฑัั"},  โ ะฒะปะพะถะตะฝะฝัะน ะพะฑัะตะบั\n'
            '  "participants": ["ะะบัะฐะฝะฐ", "ะะฐะปั"],  โ ะผะฐััะธะฒ\n'
            '  "decisions": [{"decision": "ะะตัะตะฝะธะต 1"}]  โ ะผะฐััะธะฒ ะพะฑัะตะบัะพะฒ\n'
            "}"
        )


def _build_user_prompt(
    transcription: str,
    template_variables: Dict[str, str],
    diarization_data: Optional[Dict[str, Any]] = None,
    speaker_mapping: Optional[Dict[str, str]] = None,
    meeting_topic: Optional[str] = None,
    meeting_date: Optional[str] = None,
    meeting_time: Optional[str] = None,
    participants: Optional[List[Dict[str, str]]] = None,
) -> str:
    """
    ะคะพัะผะธััะตั ะฟะพะปัะทะพะฒะฐัะตะปััะบะธะน ะฟัะพะผะฟั ั ะบะพะฝัะตะบััะพะผ ะธ ััะตะฑะพะฒะฐะฝะธัะผะธ ะบ ัะพัะผะฐัั.
    
    ะะะะะ: ะัะฟะพะปัะทัะตััั formatted_transcript ะธะท diarization_data, ะบะพัะพััะน:
    - ะกะพััะฐะฝัะตั ะฟะพัะปะตะดะพะฒะฐัะตะปัะฝะพััั ัะตัะตะดะพะฒะฐะฝะธั ัะฟะธะบะตัะพะฒ
    - ะััะฟะฟะธััะตั ัะพะปัะบะพ ะฟะพัะปะตะดะพะฒะฐัะตะปัะฝัะต ัะตะฟะปะธะบะธ ะพะดะฝะพะณะพ ัะฟะธะบะตัะฐ
    - ะะพะทะฒะพะปัะตั LLM ะฟะพะฝััั ะดะธะฝะฐะผะธะบั ะดะธะฐะปะพะณะฐ
    - ะญะบะพะฝะพะผะธั ัะพะบะตะฝั ะฟะพ ััะฐะฒะฝะตะฝะธั ั ะดัะฑะปะธัะพะฒะฐะฝะธะตะผ ะธััะพะดะฝะพะน ััะฐะฝัะบัะธะฟัะธะธ
    
    ะััะพะดะฝะฐั ััะฐะฝัะบัะธะฟัะธั ะฝะต ะฒะบะปััะฐะตััั ะฟะพ ัะผะพะปัะฐะฝะธั, ะฝะพ ะผะพะถะตั ะฑััั ะดะพะฑะฐะฒะปะตะฝะฐ
    ัะตัะตะท settings.include_raw_transcription_in_prompts ะดะปั ะพัะปะฐะดะบะธ ะฟัะพะฑะปะตะผ ั ะดะธะฐัะธะทะฐัะธะตะน.
    """
    # ะะปะพะบ ะบะพะฝัะตะบััะฐ (ั ััััะพะผ ะดะธะฐัะธะทะฐัะธะธ)
    if diarization_data and diarization_data.get("formatted_transcript"):
        transcription_text = (
            "ะขัะฐะฝัะบัะธะฟัะธั ั ัะฐะทะดะตะปะตะฝะธะตะผ ะณะพะฒะพัััะธั:\n"
            f"{diarization_data['formatted_transcript']}\n\n"
            "ะะพะฟะพะปะฝะธัะตะปัะฝะฐั ะธะฝัะพัะผะฐัะธั:\n"
            f"- ะะพะปะธัะตััะฒะพ ะณะพะฒะพัััะธั: {diarization_data.get('total_speakers', 'ะฝะตะธะทะฒะตััะฝะพ')}\n"
            f"- ะกะฟะธัะพะบ ะณะพะฒะพัััะธั: {', '.join(diarization_data.get('speakers', []))}\n\n"
        )
        
        # ะะฟัะธะพะฝะฐะปัะฝะพ ะดะพะฑะฐะฒะปัะตะผ ะธััะพะดะฝัั ััะฐะฝัะบัะธะฟัะธั ะดะปั ะพัะปะฐะดะบะธ
        if settings.include_raw_transcription_in_prompts:
            transcription_text += (
                "\nโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
                "ะะกะฅะะะะะฏ ะขะะะะกะะะะะฆะะฏ (ะะะฏ ะะขะะะะะ):\n"
                "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
                f"{transcription}\n\n"
            )
    else:
        transcription_text = (
            "ะขัะฐะฝัะบัะธะฟัะธั:\n"
            f"{transcription}\n\n"
            "ะัะธะผะตัะฐะฝะธะต: ะะธะฐัะธะทะฐัะธั (ัะฐะทะดะตะปะตะฝะธะต ะณะพะฒะพัััะธั) ะฝะตะดะพัััะฟะฝะฐ ะดะปั ััะพะน ะทะฐะฟะธัะธ.\n"
        )
    
    # ะะพะฑะฐะฒะปัะตะผ ะธะฝัะพัะผะฐัะธั ะพ ัะพะฟะพััะฐะฒะปะตะฝะธะธ ัะฟะธะบะตัะพะฒ ั ััะฐััะฝะธะบะฐะผะธ
    participants_info = ""
    if speaker_mapping:
        participants_info = "\n\n" + "โ" * 63 + "\n"
        participants_info += "ะฃะงะะกะขะะะะ ะะกะขะะะงะ (ะก ะะะะฏะะ)\n"
        participants_info += "โ" * 63 + "\n\n"
        participants_info += "ะกะพะฟะพััะฐะฒะปะตะฝะธะต ะณะพะฒะพัััะธั ั ััะฐััะฝะธะบะฐะผะธ:\n"
        for speaker_id, participant_name in speaker_mapping.items():
            participants_info += f"- {speaker_id} = {participant_name}\n"
        participants_info += "\n"
        participants_info += "โ๏ธ ะะะกะขะะฃะะฆะะ ะะ ะะะะะขะ ะก ะฃะงะะกะขะะะะะะ:\n"
        participants_info += "1. ะัะฟะพะปัะทัะน ะะะะะฌะะซะ ะะะะะ ะฒะผะตััะพ ะผะตัะพะบ ัะฟะธะบะตัะพะฒ (SPEAKER_1 โ ะะผั)\n"
        participants_info += "2. ะัะธ ะฝะฐะทะฝะฐัะตะฝะธะธ ะพัะฒะตัััะฒะตะฝะฝัั ััะธััะฒะฐะน ะบะพะฝัะตะบัั ะฒััะบะฐะทัะฒะฐะฝะธะน ััะฐััะฝะธะบะพะฒ\n"
        participants_info += "3. ะคะพัะผะฐั ะพัะฒะตัััะฒะตะฝะฝะพะณะพ: ะขะะะฌะะ ะะะฏ, ะฑะตะท ัะพะปะธ ะฒ ัะบะพะฑะบะฐั\n"
        participants_info += "   โ ะัะฐะฒะธะปัะฝะพ: 'ะัะฒะตัััะฒะตะฝะฝัะน: ะะฒะฐะฝ ะะตััะพะฒ'\n"
        participants_info += "   โ ะะตะฟัะฐะฒะธะปัะฝะพ: 'ะัะฒะตัััะฒะตะฝะฝัะน: ะะฒะฐะฝ ะะตััะพะฒ (ะะตะฝะตะดะถะตั)'\n"
        participants_info += "๐ ะกะะะะกะขะะะะะะะ ะะะะ:\n"
        participants_info += "ะ ััะฐะฝัะบัะธะฟัะธะธ ะผะพะณัั ะฒัััะตัะฐัััั ัะพะบัะฐัะตะฝะฝัะต/ัะฐะทะณะพะฒะพัะฝัะต ะฒะฐัะธะฐะฝัั ะธะผะตะฝ.\n"
        participants_info += "ะะะขะะะะขะะงะะกะะ ัะพะฟะพััะฐะฒะปัะน ะธั ั ะฟะพะปะฝัะผะธ ะธะผะตะฝะฐะผะธ ะธะท ัะฟะธัะบะฐ ะฒััะต:\n\n"
        participants_info += "ะัะธะผะตัั ะปะพะณะธะบะธ ัะพะฟะพััะฐะฒะปะตะฝะธั (ะฟัะธะผะตะฝัะน ะบะพ ะะกะะ ััะฐััะฝะธะบะฐะผ):\n"
        participants_info += "   โข ะฃะผะตะฝััะธัะตะปัะฝัะต: ะกะฒะตัะฐโะกะฒะตัะปะฐะฝะฐ, ะะตัะฐโะะปะตะบัะตะน, ะกะฐัะฐโะะปะตะบัะฐะฝะดั ะธ ั.ะด.\n"
        participants_info += "   โข ะะพ ัะฐะผะธะปะธะธ: ะขะธะผัะตะฝะบะพโะะปะตะบัะตะน ะขะธะผัะตะฝะบะพ, ะะพัะพัะบะพะฒะฐโะกะฒะตัะปะฐะฝะฐ ะะพัะพัะบะพะฒะฐ ะธ ั.ะด.\n"
        participants_info += "   โข ะขะพะปัะบะพ ะธะผั: ะะปะตะบัะตะนโะะปะตะบัะตะน ะขะธะผัะตะฝะบะพ (ะตัะปะธ ะพะดะธะฝ ัะฐะบะพะน ะฒ ัะฟะธัะบะต)\n\n"
        participants_info += "   โก ะะ ะพะณัะฐะฝะธัะธะฒะฐะนัั ะฟัะธะผะตัะฐะผะธ! ะะฝะฐะปะธะทะธััะน ะะะกะฌ ัะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ ะฒััะต.\n"
        participants_info += "   โก ะ ัะธะฝะฐะปัะฝะพะผ ะฟัะพัะพะบะพะปะต ะธัะฟะพะปัะทัะน ะะะะะะ ะะะฏ ะธะท ัะฟะธัะบะฐ ััะฐััะฝะธะบะพะฒ!\n"
    elif participants:
        # ะัะปะธ ะฝะตั speaker_mapping, ะฝะพ ะตััั ัะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ - ะฟะพะบะฐะทัะฒะฐะตะผ ะตะณะพ
        participants_info = "\n\n" + "โ" * 63 + "\n"
        participants_info += "๐ฏ ะะะะะซะ ะกะะะกะะ ะฃะงะะกะขะะะะะ ะะกะขะะะงะ (ะะะฏะะะขะะะฌะะซะ ะ ะะกะะะะฌะะะะะะะฎ)\n"
        participants_info += "โ" * 63 + "\n\n"
        from src.services.participants_service import participants_service
        # ะะะะะ: format_participants_for_llm ะฟัะตะพะฑัะฐะทัะตั ะธะผะตะฝะฐ ะฒ ัะพัะผะฐั "ะะผั ะคะฐะผะธะปะธั" (ะฑะตะท ะพััะตััะฒะฐ)
        participants_info += participants_service.format_participants_for_llm(participants)
        participants_info += "\n\n"
        participants_info += "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        participants_info += "โ  ๐จ ะะะะขะะงะะกะะ ะะะะะ - ะกะขะะะะะ ะะะะะะะ ะะกะะะะฌะะะะะะะฏ     โ\n"
        participants_info += "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
        participants_info += "1๏ธโฃ ะะกะะะะฌะะฃะ ะขะะะฌะะ ะะะะะ ะะ ะกะะะกะะ ะะซะจะ!\n"
        participants_info += "   ะะะะะะฉะะะ ะดะพะฑะฐะฒะปััั ััะฐััะฝะธะบะพะฒ, ะบะพัะพััั ะะะข ะฒ ัะฟะธัะบะต!\n"
        participants_info += "   โ ะะะะะะะะะฌะะ: 'ะะพะปะปะตะณะฐ ะธะท ะะะข', 'ะะพะปะปะตะณะธ ะธะท ERP', 'ะะพะผะฐะฝะดะฐ'\n"
        participants_info += "   โ ะะะะะะะฌะะ: ัะพะปัะบะพ ะบะพะฝะบัะตัะฝัะต ะธะผะตะฝะฐ ะธะท ัะฟะธัะบะฐ\n\n"
        participants_info += "2๏ธโฃ ะคะะะะะข ะะะะ: 'ะะผั ะคะฐะผะธะปะธั' (ะะะ ะพััะตััะฒะฐ)!\n"
        participants_info += "   โ ะะะะะะะะะฌะะ: 'ะกะพััั' (ัะพะปัะบะพ ะธะผั)\n"
        participants_info += "   โ ะะะะะะะะะฌะะ: 'ะะธะบัะปะธะฝ' (ัะพะปัะบะพ ัะฐะผะธะปะธั)\n"
        participants_info += "   โ ะะะะะะะะะฌะะ: 'ะัะธะฟะพะฒะฐ ะกะพััั ะฎััะตะฒะฝะฐ' (ั ะพััะตััะฒะพะผ)\n"
        participants_info += "   โ ะะะะะะะฌะะ: 'ะกะพััั ะัะธะฟะพะฒะฐ', 'ะะฐะปะธะฝะฐ ะฏะผะบะธะฝะฐ', 'ะะปะฐะดะธะผะธั ะะพะปะธะบะพะฒ'\n\n"
        participants_info += "3๏ธโฃ ะกะะะะกะขะะะะะะะ ะกะะะะะฉะะะะซะฅ ะะะะ:\n"
        participants_info += "   ะ ััะฐะฝัะบัะธะฟัะธะธ ัะฟะพะผะธะฝะฐะฝะธั ะผะพะณัั ะฑััั ัะพะบัะฐัะตะฝะฝัะผะธ.\n"
        participants_info += "   ะะะฏะะะขะะะฌะะ ะฝะฐะนะดะธ ะฒ ัะฟะธัะบะต ะฒััะต ะะะะะะ ัะพะพัะฒะตัััะฒะธะต:\n\n"
        participants_info += "   ๐ ะะะะะะะ ะกะะะะกะขะะะะะะะฏ:\n"
        participants_info += "   โข 'ะกะฒะตัะฐ', 'ะกะฒะตัะพัะบะฐ' โ ะฝะฐะนะดะธ 'ะกะฒะตัะปะฐะฝะฐ' ะฒ ัะฟะธัะบะต โ ะธัะฟะพะปัะทัะน ะฟะพะปะฝะพะต ะธะผั\n"
        participants_info += "   โข 'ะะตัะฐ', 'ะะปััะฐ' โ ะฝะฐะนะดะธ 'ะะปะตะบัะตะน' ะฒ ัะฟะธัะบะต โ ะธัะฟะพะปัะทัะน ะฟะพะปะฝะพะต ะธะผั\n"
        participants_info += "   โข 'ะะฐะปั' โ ะฝะฐะนะดะธ 'ะะฐะปะธะฝะฐ' ะฒ ัะฟะธัะบะต โ ะธัะฟะพะปัะทัะน ะฟะพะปะฝะพะต ะธะผั\n"
        participants_info += "   โข 'ะะพะปะพะดั', 'ะะพะฒะฐ' โ ะฝะฐะนะดะธ 'ะะปะฐะดะธะผะธั' ะฒ ัะฟะธัะบะต โ ะธัะฟะพะปัะทัะน ะฟะพะปะฝะพะต ะธะผั\n"
        participants_info += "   โข 'ะกัะฐั' โ ะฝะฐะนะดะธ 'ะกัะฐะฝะธัะปะฐะฒ' ะธะปะธ 'ะกะฒััะพัะปะฐะฒ' ะฒ ัะฟะธัะบะต\n"
        participants_info += "   โข 'ะะธะบัะปะธะฝ', 'ะขะธะผัะตะฝะบะพ' (ัะฐะผะธะปะธั) โ ะฝะฐะนะดะธ ะฒ ัะฟะธัะบะต ะฟะพ ัะฐะผะธะปะธะธ\n"
        participants_info += "   โข 'ะะฐัะฐั' (ะธะผั) โ ะฝะฐะนะดะธ ะฒ ัะฟะธัะบะต ะฟะพ ะธะผะตะฝะธ โ ะธัะฟะพะปัะทัะน ะฟะพะปะฝะพะต ะธะผั\n\n"
        participants_info += "4๏ธโฃ ะะะะะะะะ ะะะะะ ะะะะะะะะะะะ ะ ะะะะขะะะะ:\n"
        participants_info += "   ะะปั ะะะะะะะ ััะฐััะฝะธะบะฐ ะธะท ััะฐะฝัะบัะธะฟัะธะธ:\n"
        participants_info += "   โ ะะฐะนะดะธ ัะพะพัะฒะตัััะฒะธะต ะฒ ัะฟะธัะบะต ะฒััะต\n"
        participants_info += "   โ ะัะฟะพะปัะทัะน ะขะะงะะะ ะฝะฐะฟะธัะฐะฝะธะต ะธะท ัะฟะธัะบะฐ (ะะผั ะคะฐะผะธะปะธั)\n"
        participants_info += "   โ ะัะปะธ ะฝะต ะผะพะถะตัั ะพะฟัะตะดะตะปะธัั ะบะพะฝะบัะตัะฝะพะณะพ ัะตะปะพะฒะตะบะฐ - ะะ ะฒะบะปััะฐะน ะฒ ะฟัะพัะพะบะพะป\n\n"
        participants_info += "โก ะะะะะ: ะัะพะฐะฝะฐะปะธะทะธััะน ะะะกะฌ ัะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ ะฒััะต!\n"
        participants_info += "โก ะะ ะฒัะดัะผัะฒะฐะน ะธะผะตะฝะฐ! ะัะฟะพะปัะทัะน ะขะะะฌะะ ะธะท ัะฟะธัะบะฐ!\n"
        participants_info += "โก ะัะธ ะผะฐะปะตะนัะตะผ ัะพะผะฝะตะฝะธะธ - ัะพะฟะพััะฐะฒั ั ะฟะพะปะฝัะผ ัะฟะธัะบะพะผ!\n\n"
    else:
        # ะะตั ะฝะธ speaker_mapping, ะฝะธ participants - ะฐะฒัะพะพะฟัะตะดะตะปะตะฝะธะต ะธะท ััะฐะฝัะบัะธะฟัะธะธ
        participants_info = "\n\n" + "โ" * 63 + "\n"
        participants_info += "โ๏ธ ะะะขะะะะขะะงะะกะะะ ะะะะะะะะะะะ ะฃะงะะกะขะะะะะ ะะ ะขะะะะกะะะะะฆะะ\n"
        participants_info += "โ" * 63 + "\n\n"
        participants_info += "ะกะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ ะฝะต ะฟัะตะดะพััะฐะฒะปะตะฝ. ะะฟัะตะดะตะปะธ ะธะผะตะฝะฐ ะธะท ััะฐะฝัะบัะธะฟัะธะธ.\n\n"
        participants_info += "๐ ะะะะะะะ ะะะะะะะะะะะฏ:\n\n"
        participants_info += "1๏ธโฃ ะะฉะ ะฏะะะซะ ะฃะะะะะะะะะฏ:\n"
        participants_info += "   โข ะัะตะดััะฐะฒะปะตะฝะธั: 'ะะตะฝั ะทะพะฒัั ะะฒะฐะฝ ะะตััะพะฒ', 'ะฏ โ ะะฐัะธั'\n"
        participants_info += "   โข ะะฑัะฐัะตะฝะธั: 'ะกะฒะตัะฐ, ะบะฐะบ ะดัะผะฐะตัั?', 'ะะตััะพะฒ, ัะฐััะบะฐะถะธ ะพ ะทะฐะดะฐัะต'\n"
        participants_info += "   โข ะฃะฟะพะผะธะฝะฐะฝะธั: 'ะะฐะบ ัะบะฐะทะฐะป ะะฒะฐะฝ...', 'ะัะถะฝะพ ััะพัะฝะธัั ั ะะฐัะธะธ'\n\n"
        participants_info += "2๏ธโฃ ะคะะะะะข ะะะะ:\n"
        participants_info += "   โข ะัะตะดะฟะพััะธัะตะปัะฝะพ: 'ะะผั ะคะฐะผะธะปะธั' (ะะะ ะพััะตััะฒะฐ)\n"
        participants_info += "   โข ะัะปะธ ะธะทะฒะตััะฝะพ ัะพะปัะบะพ ะธะผั: 'ะะฒะฐะฝ'\n"
        participants_info += "   โข ะัะปะธ ะธะทะฒะตััะฝะฐ ัะพะปัะบะพ ัะฐะผะธะปะธั: 'ะะตััะพะฒ'\n"
        participants_info += "   โข ะัะตะพะฑัะฐะทัะน ัะผะตะฝััะธัะตะปัะฝัะต: ะกะฒะตัะฐโะกะฒะตัะปะฐะฝะฐ, ะะตัะฐโะะปะตะบัะตะน, ะะพะปะพะดัโะะปะฐะดะธะผะธั\n\n"
        participants_info += "3๏ธโฃ ะกะะะะกะขะะะะะะะ ะกะ ะกะะะะะะะะ:\n"
        participants_info += "   โข ะกะพะฟะพััะฐะฒั ะบะฐะถะดัั ะผะตัะบั (SPEAKER_1, SPEAKER_2...) ั ะธะผะตะฝะตะผ ะตัะปะธ ะฒะพะทะผะพะถะฝะพ\n"
        participants_info += "   โข ะัะปะธ ะธะผั ะพะฟัะตะดะตะปะธัั ะะะะะะะะะะ - ะพััะฐะฒั ะผะตัะบั ัะฟะธะบะตัะฐ ะบะฐะบ ะตััั\n"
        participants_info += "   โข ะัะธะผะตั ัะตะทัะปััะฐัะฐ: 'ะะฒะฐะฝ ะะตััะพะฒ\\nะกะะะะะR_2\\nะกะฒะตัะปะฐะฝะฐ ะะพัะพัะบะพะฒะฐ\\nะกะะะะะR_4'\n\n"
        participants_info += "4๏ธโฃ ะกะขะะะะะ ะะะะะะขะซ:\n"
        participants_info += "   โ ะะ ะฟัะธะดัะผัะฒะฐะน ะธะผะตะฝะฐ, ะบะพัะพััั ะะะข ะฒ ััะฐะฝัะบัะธะฟัะธะธ\n"
        participants_info += "   โ ะะ ะธัะฟะพะปัะทัะน 'ะฃัะฐััะฝะธะบ 1', 'ะะพะปะปะตะณะฐ', 'ะงะตะปะพะฒะตะบ ะ', 'ะะตะธะทะฒะตััะฝัะน'\n"
        participants_info += "   โ ะะ ะดัะฑะปะธััะน: ะตัะปะธ ะกะฒะตัะฐ = SPEAKER_1, ะฝะต ะดะพะฑะฐะฒะปัะน ะกะฒะตัะปะฐะฝั ะพัะดะตะปัะฝะพ\n"
        participants_info += "   โ ะะ ะทะฐะผะตะฝัะน SPEAKER_N ะฝะฐ ะพะฟะธัะฐะฝะธั ัะธะฟะฐ 'ะัะบะพะฒะพะดะธัะตะปั ะฒัััะตัะธ'\n\n"
        participants_info += "๐ก ะะะะกะะะะะ:\n"
        participants_info += "   โข ะะฐัะฐะปะพ ะฒัััะตัะธ - ัะฐััะพ ัะฐะผ ะฟัะตะดััะฐะฒะปััััั\n"
        participants_info += "   โข ะะฑัะฐัะตะฝะธั ะฟะพ ะธะผะตะฝะธ - ัะฐะผัะน ะฝะฐะดะตะถะฝัะน ะฟัะธะทะฝะฐะบ\n"
        participants_info += "   โข ะะพะฝัะตะบัั: 'ะฝะฐั ัะธะผะปะธะด ะะปะตะบัะตะน', 'ะผะตะฝะตะดะถะตั ะะฐัะธั'\n"
        participants_info += "   โข ะฃะฒะตัะตะฝะฝะพััะธ ะฝะตั? โ ะััะฐะฒั SPEAKER_N\n\n"

    # ะะพะฑะฐะฒะปัะตะผ ะธะฝัะพัะผะฐัะธั ะพ ะฒัััะตัะต
    meeting_info = ""
    if meeting_topic or meeting_date or meeting_time:
        meeting_info = "\n\n" + "โ" * 63 + "\n"
        meeting_info += "ะะะคะะะะะฆะะฏ ะ ะะกะขะะะงะ\n"
        meeting_info += "โ" * 63 + "\n\n"

        if meeting_topic:
            meeting_info += f"๐ ะขะตะผะฐ: {meeting_topic}\n"
        if meeting_date:
            meeting_info += f"๐ ะะฐัะฐ: {meeting_date}\n"
        if meeting_time:
            meeting_info += f"๐ ะัะตะผั: {meeting_time}\n"
        meeting_info += "\n"


    
    variables_str = "\n".join([f"- {key}: {desc}" for key, desc in template_variables.items()])

    # ะัะฝะพะฒะฝะพะน ะฟะพะปัะทะพะฒะฐัะตะปััะบะธะน ะฟัะพะผะฟั
    user_prompt = (
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "ะะกะฅะะะะซะ ะะะะะซะ ะะะฏ ะะะะะะะ\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
        f"{transcription_text}\n"
        f"{participants_info}"
        f"{meeting_info}"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "ะะะะฏ ะะะฏ ะะะะะะงะะะะฏ\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
        f"{variables_str}\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "ะะะกะขะะฃะะฆะะ ะะ ะะะะะะงะะะะฎ\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
        
        "๐ ะกะขะะฃะะขะฃะะ ะะซะะะะ:\n"
        "- ะะตัะฝะธ ัะพะปัะบะพ ะฒะฐะปะธะดะฝัะน JSON-ะพะฑัะตะบั (ะฑะตะท ```json, ะฑะตะท markdown)\n"
        "- ะัะฟะพะปัะทัะน ะกะขะะะะ ััะธ ะบะปััะธ ะธะท ัะฟะธัะบะฐ ะฟะพะปะตะน\n"
        "- ะกะพััะฐะฝัะน ะฟะพััะดะพะบ ะบะปััะตะน ะบะฐะบ ะฒ ัะฟะธัะบะต ะฒััะต\n"
        "- ะะฐะถะดะพะต ะทะฝะฐัะตะฝะธะต โ ัััะพะบะฐ (UTF-8), ะะะ ะฒะปะพะถะตะฝะฝัั ะพะฑัะตะบัะพะฒ ะธะปะธ ะผะฐััะธะฒะพะฒ\n\n"
        
        "๐ ะคะะะะะขะะะะะะะะ ะขะะะกะขะ:\n"
        "- ะะปั ัะฟะธัะบะพะฒ/ะฟะตัะตัะธัะปะตะฝะธะน: ะบะฐะถะดัะน ะฟัะฝะบั ั ะฝะพะฒะพะน ัััะพะบะธ, ะฝะฐัะธะฝะฐะน ั '- ' (ะดะตัะธั + ะฟัะพะฑะตะป)\n"
        "- ะะ ะธัะฟะพะปัะทัะน ะฝัะผะตัะฐัะธั (1. 2. 3.), ัะพะปัะบะพ ะดะตัะธัั\n"
        "- ะะ ััะฐะฒั ัะพัะบั ะฒ ะบะพะฝัะต ะฟัะฝะบัะฐ ัะฟะธัะบะฐ\n"
        "- ะะปั ะธะผะตะฝ/ััะฐััะฝะธะบะพะฒ: ัะฐะทะดะตะปัะน ัะพัะบะพะน ั ะทะฐะฟััะพะน (;)\n"
        "- ะะปั ะดะฐั/ะฒัะตะผะตะฝะธ: ัะพััะฐะฝัะน ัะพัะผะฐั ะบะฐะบ ัะฟะพะผัะฝัั ะฒ ัะตะบััะต\n\n"
        
        "๐ฏ ะะะะะะงะะะะ ะะะะะซะฅ:\n"
        "- ะัะฟะพะปัะทัะน ะขะะะฌะะ ัะฐะบัั ะธะท ััะฐะฝัะบัะธะฟัะธะธ\n"
        "- ะัะปะธ ะธะฝัะพัะผะฐัะธั ัะฟะพะผัะฝััะฐ ั ะบะพะฝัะตะบััะพะผ (ัะพะปั, ััะพะบ, ััะผะผะฐ) โ ัะบะฐะถะธ ะฟะพะปะฝะพัััั\n"
        "- ะัะปะธ ะดะฐะฝะฝัะต ะพััััััะฒััั, ะฝะตะพะดะฝะพะทะฝะฐัะฝั ะธะปะธ ะฝะตััะฝั โ ะฟะธัะธ 'ะะต ัะบะฐะทะฐะฝะพ'\n"
        "- ะฃะฑะธัะฐะน ะดัะฑะปะธะบะฐัั, ะพะฑัะตะดะธะฝัะน ะธะดะตะฝัะธัะฝัะต ะฟัะฝะบัั\n"
        "- ะกะพััะฐะฝัะน ััะพะฝะพะปะพะณะธั: ะฟะพััะดะพะบ ะฟัะฝะบัะพะฒ = ะฟะพััะดะพะบ ะฒ ัะตะบััะต\n\n"
        
        "๐ ะะะะะะะขะะ ะะะคะะะะะฆะะ ะ ะะะะะะฏะฉะะฅ:\n"
        "- ะัะปะธ ะดะพัััะฟะฝะฐ ะดะธะฐัะธะทะฐัะธั: ะธัะฟะพะปัะทัะน ะผะตัะบะธ 'ะกะฟะธะบะตั 1:', 'ะกะฟะธะบะตั 2:' ะธ ั.ะด.\n"
        "- ะะฟัะตะดะตะปัะน ะพัะฒะตัััะฒะตะฝะฝัั ะทะฐ ะดะตะนััะฒะธั ะฟะพ ะบะพะฝัะตะบััั ะธั ะฒััะบะฐะทัะฒะฐะฝะธะน\n"
        "- ะฃะบะฐะทัะฒะฐะน ะบัะพ ะฟัะธะฝัะป ัะตัะตะฝะธะต ะธะปะธ ะฒะทัะป ะฝะฐ ัะตะฑั ะพะฑัะทะฐัะตะปัััะฒะพ\n"
        "- ะัะปะธ ะธะทะฒะตััะฝั ะธะผะตะฝะฐ ััะฐััะฝะธะบะพะฒ โ ะธัะฟะพะปัะทัะน ะะฅ, ะฐ ะฝะต ะผะตัะบะธ ัะฟะธะบะตัะพะฒ\n"
        "- ะคะพัะผะฐั ะทะฐะดะฐัะธ: 'ะะฟะธัะฐะฝะธะต ะทะฐะดะฐัะธ โ ะัะฒะตัััะฒะตะฝะฝัะน: ะะผั ะคะฐะผะธะปะธั' (ะฑะตะท ัะพะปะธ!)\n"
        "- ะคะพัะผะฐั ัะตัะตะฝะธั: 'ะะตัะตะฝะธะต. ะะฝะธัะธะฐัะพั: ะะผั ะคะฐะผะธะปะธั' (ะตัะปะธ ะฒะฐะถะฝะพ ะบัะพ ะฟัะธะฝัะป)\n\n"
        
        "๐งน ะงะขะ ะะขะคะะะฌะขะะะะซะะะขะฌ:\n"
        "- ะะตะถะดะพะผะตัะธั, ะทะฐะฟะธะฝะบะธ, ะฟะพะฒัะพัั ัะปะพะฒ\n"
        "- ะะฒะพะดะฝัะต ััะฐะทั ะฑะตะท ัะผััะปะพะฒะพะน ะฝะฐะณััะทะบะธ\n"
        "- ะะฐะทะณะพะฒะพัั ะฝะต ะฟะพ ัะตะผะต ะฒัััะตัะธ\n"
        "- ะขะตัะฝะธัะตัะบะธะต ะบะพะผะผะตะฝัะฐัะธะธ ('ะฝะต ัะปััะฝะพ', 'ะฟะพะฒัะพัะธัะต' ะธ ั.ะด.)\n\n"
        
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "ะะะะะะะซ ะะะะะะะฌะะะะ ะคะะะะะขะะะะะะะะฏ\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
        
        "โ ะะะะะะะฌะะ:\n"
        "{\n"
        "  \"participants\": \"ะะฒะฐะฝ ะะฒะฐะฝะพะฒ\\nะะฐัะธั ะะตััะพะฒะฐ\\nะะปะตะบัะตะน ะกะธะดะพัะพะฒ\",\n"
        "  \"main_topic\": \"ะะปะฐะฝะธัะพะฒะฐะฝะธะต ะผะฐัะบะตัะธะฝะณะพะฒะพะน ะบะฐะผะฟะฐะฝะธะธ ะฝะฐ Q2 2024\",\n"
        "  \"decisions\": \"- ะฃะฒะตะปะธัะธัั ะฑัะดะถะตั ะฝะฐ digital-ะผะฐัะบะตัะธะฝะณ ะฝะฐ 30%\\n- ะฃัะฒะตัะดะธัั ะฝะพะฒัั ัััะฐัะตะณะธั ะฟัะพะดะฒะธะถะตะฝะธั ะฒ ัะพัะธะฐะปัะฝัั ัะตััั\\n- ะัะปะพะถะธัั ะทะฐะฟััะบ ัะตะบะปะฐะผั ะฝะฐ ะขะ ะดะพ ัะปะตะดัััะตะณะพ ะบะฒะฐััะฐะปะฐ\",\n"
        "  \"action_items\": \"- ะะพะดะณะพัะพะฒะธัั ะฟัะตะทะตะฝัะฐัะธั ะฝะพะฒะพะน ัััะฐัะตะณะธะธ ะบ 15 ะผะฐััะฐ โ ะัะฒะตัััะฒะตะฝะฝัะน: ะะฐัะธั ะะตััะพะฒะฐ\\n- ะกะพะณะปะฐัะพะฒะฐัั ะฑัะดะถะตั ั ัะธะฝะฐะฝัะพะฒัะผ ะพัะดะตะปะพะผ โ ะัะฒะตัััะฒะตะฝะฝัะน: ะะฒะฐะฝ ะะฒะฐะฝะพะฒ\\n- ะัะพะฒะตััะธ ะฐะฝะฐะปะธะท ะบะพะฝะบััะตะฝัะพะฒ โ ะัะฒะตัััะฒะตะฝะฝัะน: ะะปะตะบัะตะน ะกะธะดะพัะพะฒ\",\n"
        "  \"deadlines\": \"- ะัะตะทะตะฝัะฐัะธั ัััะฐัะตะณะธะธ: 15 ะผะฐััะฐ 2024\\n- ะกะพะณะปะฐัะพะฒะฐะฝะธะต ะฑัะดะถะตัะฐ: ะดะพ ะบะพะฝัะฐ ัะตะบััะตะน ะฝะตะดะตะปะธ\\n- ะะฝะฐะปะธะท ะบะพะฝะบััะตะฝัะพะฒ: ะบ ัะปะตะดัััะตะผั ัะพะฒะตัะฐะฝะธั\",\n"
        "  \"issues\": \"- ะะตะดะพััะฐัะพัะฝัะน ะพัะฒะฐั ัะตะปะตะฒะพะน ะฐัะดะธัะพัะธะธ ัะตะบััะธะผะธ ะบะฐะฝะฐะปะฐะผะธ\\n- ะััะพะบะฐั ััะพะธะผะพััั ะฟัะธะฒะปะตัะตะฝะธั ะบะปะธะตะฝัะฐ\\n- ะะตะพะฑัะพะดะธะผะพััั ะพะฑะฝะพะฒะปะตะฝะธั ะบัะตะฐัะธะฒะพะฒ\"\n"
        "}\n\n"
        "ะะะะะขะะขะ ะะะะะะะะ: ะ action_items ัะบะฐะทะฐะฝั ัะพะปัะบะพ ะะะะะ ะฑะตะท ัะพะปะตะน ะฒ ัะบะพะฑะบะฐั!\n\n"
        
        "โ ะะะะะะะะะฌะะ:\n"
        "{\n"
        "  \"participants\": [\"ะะฒะฐะฝ\", \"ะะฐัะธั\"],  โ ะผะฐััะธะฒ ะฒะผะตััะพ ัััะพะบะธ\n"
        "  \"decisions\": \"1) ะะตัะตะฝะธะต ะพะดะธะฝ 2) ะะตัะตะฝะธะต ะดะฒะฐ.\",  โ ะฝัะผะตัะฐัะธั + ัะพัะบะธ\n"
        "  \"action_items\": \"ะะพะดะณะพัะพะฒะธัั ะฟัะตะทะตะฝัะฐัะธั (ะะฐัะธั)\",  โ ะฑะตะท ะดะตัะธัะฐ, ะฝะตะฟัะฐะฒะธะปัะฝัะน ัะพัะผะฐั\n"
        "  \"deadlines\": \"ะกัะพัะฝะพ, ะบะฐะบ ะผะพะถะฝะพ ะฑััััะตะต\",  โ ะฝะตั ะบะพะฝะบัะตัะธะบะธ, ัะพัั ะพะฝะฐ ะผะพะณะปะฐ ะฑััั\n"
        "  \"extra_field\": \"...\",  โ ะฟะพะปะต ะฝะต ะธะท ัะฟะธัะบะฐ\n"
        "  \"budget\": \"50000 ััะฑะปะตะน (ะฟัะตะดะฟะพะปะพะถะธัะตะปัะฝะพ)\"  โ ะดะพะผััะปั ะฒ ัะบะพะฑะบะฐั\n"
        "}\n\n"
        
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        "ะกะะะฆะะคะะงะะซะ ะะะะะะะ ะะ ะขะะะะ ะะะะะ\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
        f"{_build_field_specific_rules(template_variables)}\n\n"
        "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n\n"
        
        "ะะะงะะะะ ะะะะะะ. ะะตัะฝะธ ัะพะปัะบะพ JSON ะฑะตะท ะดะพะฟะพะปะฝะธัะตะปัะฝัั ะบะพะผะผะตะฝัะฐัะธะตะฒ.\n"
    )
    return user_prompt


class OpenAIProvider(LLMProvider):
    """ะัะพะฒะฐะนะดะตั ะดะปั OpenAI GPT"""
    
    def __init__(self):
        self.client = None
        self.http_client = None
        if settings.openai_api_key:
            openai.api_key = settings.openai_api_key
            # ะกะพะทะดะฐะตะผ HTTP ะบะปะธะตะฝั ั ะฝะฐัััะพะนะบะฐะผะธ SSL ะธ ัะฐะนะผะฐััะพะผ ะธะท ะฝะฐัััะพะตะบ
            import httpx
            self.http_client = httpx.Client(verify=settings.ssl_verify, timeout=settings.llm_timeout_seconds)
            self.client = openai.OpenAI(
                api_key=settings.openai_api_key,
                base_url=settings.openai_base_url,
                http_client=self.http_client
            )
    
    def is_available(self) -> bool:
        return self.client is not None and settings.openai_api_key is not None
    
    async def generate_protocol(self, transcription: str, template_variables: Dict[str, str], diarization_data: Optional[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:
        """ะะตะฝะตัะธัะพะฒะฐัั ะฟัะพัะพะบะพะป ะธัะฟะพะปัะทัั OpenAI GPT"""
        if not self.is_available():
            raise ValueError("OpenAI API ะฝะต ะฝะฐัััะพะตะฝ")

        # ะะทะฒะปะตะบะฐะตะผ ะฟะฐัะฐะผะตััั ะธะท kwargs
        speaker_mapping = kwargs.get('speaker_mapping')
        meeting_topic = kwargs.get('meeting_topic')
        meeting_date = kwargs.get('meeting_date')
        meeting_time = kwargs.get('meeting_time')
        participants = kwargs.get('participants')

        # ะฃะฝะธัะธัะธัะพะฒะฐะฝะฝัะต ัะธััะตะผะฝัะน ะธ ะฟะพะปัะทะพะฒะฐัะตะปััะบะธะน ะฟัะพะผะฟัั
        system_prompt = _build_system_prompt()

        user_prompt = _build_user_prompt(
            transcription,
            template_variables,
            diarization_data,
            speaker_mapping,
            meeting_topic,
            meeting_date,
            meeting_time,
            participants,

        )
        
        try:
            # ะัะฑะพั ะฟัะตัะตัะฐ ะผะพะดะตะปะธ, ะตัะปะธ ะฟะตัะตะดะฐะฝ ะบะปัั
            selected_model = settings.openai_model
            selected_base_url = settings.openai_base_url or "https://api.openai.com/v1"
            model_key = kwargs.get("openai_model_key")
            if model_key:
                try:
                    preset = next((p for p in settings.openai_models if p.key == model_key), None)
                except Exception:
                    preset = None
                if preset:
                    selected_model = preset.model
                    if getattr(preset, 'base_url', None):
                        selected_base_url = preset.base_url
            
            # ะะปะธะตะฝั ะดะปั ะฝัะถะฝะพะณะพ base_url (ะฟะพ ัะผะพะปัะฐะฝะธั ะธัะฟะพะปัะทัะตะผ self.client)
            client = self.client
            if client is None or (selected_base_url and getattr(client, 'base_url', None) != selected_base_url):
                client = openai.OpenAI(
                    api_key=settings.openai_api_key,
                    base_url=selected_base_url,
                    http_client=self.http_client
                )

            # ะะธะฐะณะฝะพััะธะบะฐ ะทะฐะฟัะพัะฐ (ะฑะตะท ััะตัะบะธ ะฟะพะปะฝะพะน ััะฐะฝัะบัะธะฟัะธะธ)
            base_url = selected_base_url or "https://api.openai.com/v1"
            sys_msg = "ะขั - ัััะพะณะธะน ะฐะฝะฐะปะธัะธะบ ะฟัะพัะพะบะพะปะพะฒ ะฒัััะตั..."
            user_len = len(user_prompt)
            transcript_len = len(transcription)
            vars_count = len(template_variables)
            logger.info(
                f"OpenAI ะทะฐะฟัะพั: model={selected_model}, base_url={base_url}, "
                f"vars={vars_count}, transcription_chars={transcript_len}, prompt_chars={user_len}"
            )
            _snippet = user_prompt[:400].replace("\n", " ")
            logger.debug(f"OpenAI prompt (ััะฐะณะผะตะฝั 400): {_snippet}...")

            # ะคะพัะผะธััะตะผ extra_headers ะดะปั ะฐััะธะฑััะธะธ
            extra_headers = {}
            if settings.http_referer:
                extra_headers["HTTP-Referer"] = settings.http_referer
            if settings.x_title:
                extra_headers["X-Title"] = settings.x_title

            # DEBUG ะปะพะณะธัะพะฒะฐะฝะธะต ะทะฐะฟัะพัะฐ
            if settings.llm_debug_log:
                logger.debug("=" * 80)
                logger.debug("[DEBUG] OpenAI REQUEST - generate_protocol")
                logger.debug("=" * 80)
                logger.debug(f"Model: {selected_model}")
                logger.debug(f"Base URL: {selected_base_url}")
                logger.debug(f"Temperature: 0.1")
                logger.debug(f"Extra headers: {extra_headers}")
                logger.debug("-" * 80)
                logger.debug(f"System prompt:\n{system_prompt}")
                logger.debug("-" * 80)
                logger.debug(f"User prompt:\n{user_prompt}")
                logger.debug("=" * 80)

            logger.info(f"ะัะฟัะฐะฒะปัะตะผ ะทะฐะฟัะพั ะฒ OpenAI ั ะผะพะดะตะปัั {selected_model}")
            
            # ะัะฟะพะปะฝัะตะผ ัะธะฝััะพะฝะฝัะน ะฒัะทะพะฒ ะบะปะธะตะฝัะฐ ะฒ ะพัะดะตะปัะฝะพะผ ะฟะพัะพะบะต, ััะพะฑั ะฝะต ะฑะปะพะบะธัะพะฒะฐัั event loop
            async def _call_openai():
                return await asyncio.to_thread(
                    client.chat.completions.create,
                    model=selected_model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.1,
                    response_format={"type": "json_schema", "json_schema": PROTOCOL_SCHEMA},
                    extra_headers=extra_headers
                )
            
            try:
                response = await _call_openai()
            except openai.APIStatusError as e:
                # ะัะพะฒะตััะตะผ ะฝะฐ ะพัะธะฑะบั 402 - ะฝะตะดะพััะฐัะพัะฝะพ ะบัะตะดะธัะพะฒ
                if e.status_code == 402:
                    error_message = e.message
                    # ะััะฐะตะผัั ะธะทะฒะปะตัั ะฑะพะปะตะต ะฟะพะดัะพะฑะฝะพะต ัะพะพะฑัะตะฝะธะต ะธะท ัะตะปะฐ ะพัะฒะตัะฐ
                    if hasattr(e, 'response') and e.response:
                        try:
                            error_body = e.response.json()
                            if 'error' in error_body and 'message' in error_body['error']:
                                error_message = error_body['error']['message']
                        except:
                            pass
                    logger.error(f"ะะตะดะพััะฐัะพัะฝะพ ะบัะตะดะธัะพะฒ ะดะปั LLM: {error_message}")
                    raise LLMInsufficientCreditsError(
                        message=error_message,
                        provider="openai",
                        model=selected_model
                    )
                # ะััะณะธะต ะพัะธะฑะบะธ API ะฟัะพะฑัะฐััะฒะฐะตะผ ะดะฐะปััะต
                raise
            
            logger.info("ะะพะปััะตะฝ ะพัะฒะตั ะพั OpenAI API")
            
            content = response.choices[0].message.content
            
            # DEBUG ะปะพะณะธัะพะฒะฐะฝะธะต ะพัะฒะตัะฐ
            if settings.llm_debug_log:
                logger.debug("=" * 80)
                logger.debug("[DEBUG] OpenAI RESPONSE - generate_protocol")
                logger.debug("=" * 80)
                if hasattr(response, 'usage'):
                    logger.debug(f"Usage: {response.usage}")
                finish_reason = response.choices[0].finish_reason
                logger.debug(f"Finish reason: {finish_reason}")
                logger.debug("-" * 80)
                logger.debug(f"Content:\n{content}")
                logger.debug("=" * 80)
            
            # ะะพะณะธัะพะฒะฐะฝะธะต ะบะตัะธัะพะฒะฐะฝะฝัั ัะพะบะตะฝะพะฒ
            if settings.log_cache_metrics:
                log_cached_tokens_usage(
                    response=response,
                    context="generate_protocol",
                    model_name=selected_model,
                    provider="openai"
                )
            
            logger.info(f"ะะพะปััะตะฝ ะพัะฒะตั ะพั OpenAI (ะดะปะธะฝะฐ: {len(content) if content else 0}): {content[:200] if content else 'None'}...")
            
            # ะัะฟะพะปัะทัะตะผ ะฑะตะทะพะฟะฐัะฝัะน ะฟะฐััะตั JSON
            return safe_json_parse(content, context="OpenAI API response")
            
        except Exception as e:
            logger.error(f"ะัะธะฑะบะฐ ะฟัะธ ัะฐะฑะพัะต ั OpenAI API: {e}")
            raise


class AnthropicProvider(LLMProvider):
    """ะัะพะฒะฐะนะดะตั ะดะปั Anthropic Claude"""
    
    def __init__(self):
        self.client = None
        if settings.anthropic_api_key:
            # ะกะพะทะดะฐะตะผ HTTP ะบะปะธะตะฝั ั ะฝะฐัััะพะนะบะฐะผะธ SSL ะธ ัะฐะนะผะฐััะพะผ ะธะท ะฝะฐัััะพะตะบ
            import httpx
            http_client = httpx.Client(verify=settings.ssl_verify, timeout=settings.llm_timeout_seconds)
            self.client = Anthropic(
                api_key=settings.anthropic_api_key,
                http_client=http_client
            )
    
    def is_available(self) -> bool:
        return self.client is not None and settings.anthropic_api_key is not None
    
    async def generate_protocol(self, transcription: str, template_variables: Dict[str, str], diarization_data: Optional[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:
        """ะะตะฝะตัะธัะพะฒะฐัั ะฟัะพัะพะบะพะป ะธัะฟะพะปัะทัั Anthropic Claude"""
        if not self.is_available():
            raise ValueError("Anthropic API ะฝะต ะฝะฐัััะพะตะฝ")

        # ะะทะฒะปะตะบะฐะตะผ ะฟะฐัะฐะผะตััั ะธะท kwargs
        speaker_mapping = kwargs.get('speaker_mapping')
        meeting_topic = kwargs.get('meeting_topic')
        meeting_date = kwargs.get('meeting_date')
        meeting_time = kwargs.get('meeting_time')
        participants = kwargs.get('participants')

        # ะฃะฝะธัะธัะธัะพะฒะฐะฝะฝัะต ัะธััะตะผะฝัะน ะธ ะฟะพะปัะทะพะฒะฐัะตะปััะบะธะน ะฟัะพะผะฟัั
        system_prompt = _build_system_prompt()

        prompt = _build_user_prompt(
            transcription,
            template_variables,
            diarization_data,
            speaker_mapping,
            meeting_topic,
            meeting_date,
            meeting_time,
            participants
        )
        
        try:
            base_url = "Anthropic SDK"
            user_len = len(prompt)
            transcript_len = len(transcription)
            vars_count = len(template_variables)
            logger.info(
                f"Anthropic ะทะฐะฟัะพั: model=claude-3-haiku-20240307, base={base_url}, "
                f"vars={vars_count}, transcription_chars={transcript_len}, prompt_chars={user_len}"
            )
            _a_snippet = prompt[:400].replace("\n", " ")
            logger.debug(f"Anthropic prompt (ััะฐะณะผะตะฝั 400): {_a_snippet}...")
            
            # ะคะพัะผะธััะตะผ extra_headers ะดะปั ะฐััะธะฑััะธะธ
            extra_headers = {}
            if settings.http_referer:
                extra_headers["HTTP-Referer"] = settings.http_referer
            if settings.x_title:
                extra_headers["X-Title"] = settings.x_title
            
            # ะัะฟะพะปัะทัะตะผ prompt caching ะตัะปะธ ะฒะบะปััะตะฝะพ ะธ ััะฐะฝัะบัะธะฟัะธั ะดะพััะฐัะพัะฝะพ ะดะปะธะฝะฝะฐั
            if settings.enable_prompt_caching and len(transcription) >= settings.min_transcription_length_for_cache:
                logger.debug("ะัะฟะพะปัะทัะตะผ Anthropic prompt caching (cache_control)")
                system_with_caching, messages_with_caching = build_anthropic_messages_with_caching(
                    system_prompt, transcription, prompt
                )
                
                # ะัะฟะพะปะฝัะตะผ ัะธะฝััะพะฝะฝัะน ะฒัะทะพะฒ ะบะปะธะตะฝัะฐ Anthropic ะฒ ะพัะดะตะปัะฝะพะผ ะฟะพัะพะบะต
                async def _call_anthropic():
                    return await asyncio.to_thread(
                        self.client.messages.create,
                        model="claude-3-haiku-20240307",
                        max_tokens=2000,
                        temperature=0.1,
                        system=system_with_caching,  # ะกะฟะธัะพะบ ะฑะปะพะบะพะฒ ั cache_control
                        messages=messages_with_caching,
                        extra_headers=extra_headers
                    )
            else:
                # ะกัะฐะฝะดะฐััะฝัะน ะฒัะทะพะฒ ะฑะตะท ะบะตัะธัะพะฒะฐะฝะธั
                async def _call_anthropic():
                    return await asyncio.to_thread(
                        self.client.messages.create,
                        model="claude-3-haiku-20240307",
                        max_tokens=2000,
                        temperature=0.1,
                        system=system_prompt,
                        messages=[
                            {"role": "user", "content": prompt}
                        ],
                        extra_headers=extra_headers
                    )
            
            response = await _call_anthropic()
            
            content = response.content[0].text
            
            # ะะพะณะธัะพะฒะฐะฝะธะต ะบะตัะธัะพะฒะฐะฝะฝัั ัะพะบะตะฝะพะฒ ะดะปั Anthropic
            if settings.log_cache_metrics:
                log_cached_tokens_usage(
                    response=response,
                    context="Anthropic generate_protocol",
                    model_name="claude-3-haiku-20240307",
                    provider="anthropic"
                )
            
            logger.info(f"ะะพะปััะตะฝ ะพัะฒะตั ะพั Anthropic (ะดะปะธะฝะฐ: {len(content) if content else 0}): {content[:200] if content else 'None'}...")
            
            # ะัะฟะพะปัะทัะตะผ ะฑะตะทะพะฟะฐัะฝัะน ะฟะฐััะตั JSON
            return safe_json_parse(content, context="Anthropic API response")
            
        except Exception as e:
            logger.error(f"ะัะธะฑะบะฐ ะฟัะธ ัะฐะฑะพัะต ั Anthropic API: {e}")
            raise


class YandexGPTProvider(LLMProvider):
    """ะัะพะฒะฐะนะดะตั ะดะปั Yandex GPT"""
    
    def __init__(self):
        self.api_key = settings.yandex_api_key
        self.folder_id = settings.yandex_folder_id
    
    def is_available(self) -> bool:
        return self.api_key is not None and self.folder_id is not None
    
    async def generate_protocol(self, transcription: str, template_variables: Dict[str, str], diarization_data: Optional[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:
        """ะะตะฝะตัะธัะพะฒะฐัั ะฟัะพัะพะบะพะป ะธัะฟะพะปัะทัั Yandex GPT"""
        if not self.is_available():
            raise ValueError("Yandex GPT API ะฝะต ะฝะฐัััะพะตะฝ")

        # ะะทะฒะปะตะบะฐะตะผ ะฟะฐัะฐะผะตััั ะธะท kwargs
        speaker_mapping = kwargs.get('speaker_mapping')
        meeting_topic = kwargs.get('meeting_topic')
        meeting_date = kwargs.get('meeting_date')
        meeting_time = kwargs.get('meeting_time')
        participants = kwargs.get('participants')

        # ะฃะฝะธัะธัะธัะพะฒะฐะฝะฝัะต ัะธััะตะผะฝัะน ะธ ะฟะพะปัะทะพะฒะฐัะตะปััะบะธะน ะฟัะพะผะฟัั
        system_prompt = _build_system_prompt()

        prompt = _build_user_prompt(
            transcription,
            template_variables,
            diarization_data,
            speaker_mapping,
            meeting_topic,
            meeting_date,
            meeting_time,
            participants
        )
        
        headers = {
            "Authorization": f"Api-Key {self.api_key}",
            "Content-Type": "application/json"
        }
        
        if settings.http_referer:
            headers["Referer"] = settings.http_referer
        if settings.x_title:
            headers["X-Title"] = settings.x_title
        
        data = {
            "modelUri": f"gpt://{self.folder_id}/yandexgpt-lite",
            "completionOptions": {
                "stream": False,
                "temperature": 0.1,
                "maxTokens": 2000
            },
            "messages": [
                {
                    "role": "system",
                    "text": system_prompt
                },
                {
                    "role": "user", 
                    "text": prompt
                }
            ]
        }
        
        try:
            async with httpx.AsyncClient(verify=settings.ssl_verify) as client:
                response = await client.post(
                    "https://llm.api.cloud.yandex.net/foundationModels/v1/completion",
                    headers=headers,
                    json=data,
                    timeout=settings.llm_timeout_seconds
                )
                response.raise_for_status()
                
                result = response.json()
                content = result["result"]["alternatives"][0]["message"]["text"]
                logger.info(f"ะะพะปััะตะฝ ะพัะฒะตั ะพั Yandex GPT (ะดะปะธะฝะฐ: {len(content) if content else 0}): {content[:200] if content else 'None'}...")
                
                # ะัะฟะพะปัะทัะตะผ ะฑะตะทะพะฟะฐัะฝัะน ะฟะฐััะตั JSON
                return safe_json_parse(content, context="Yandex GPT API response")
                
        except Exception as e:
            logger.error(f"ะัะธะฑะบะฐ ะฟัะธ ัะฐะฑะพัะต ั Yandex GPT API: {e}")
            raise


class LLMManager:
    """ะะตะฝะตะดะถะตั ะดะปั ัะฐะฑะพัั ั ัะฐะทะปะธัะฝัะผะธ LLM ะฟัะพะฒะฐะนะดะตัะฐะผะธ"""
    
    def __init__(self):
        self.providers = {
            "openai": OpenAIProvider(),
            "anthropic": AnthropicProvider(),
            "yandex": YandexGPTProvider()
        }
    
    def get_available_providers(self) -> Dict[str, str]:
        """ะะพะปััะธัั ัะฟะธัะพะบ ะดะพัััะฟะฝัั ะฟัะพะฒะฐะนะดะตัะพะฒ"""
        available = {}
        provider_names = {
            "openai": "OpenAI GPT",
            "anthropic": "Anthropic Claude",
            "yandex": "Yandex GPT"
        }
        
        for key, provider in self.providers.items():
            if provider.is_available():
                available[key] = provider_names[key]
        
        return available
    
    async def generate_protocol(self, provider_name: str, transcription: str, 
                              template_variables: Dict[str, str], diarization_data: Optional[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:
        """ะะตะฝะตัะธัะพะฒะฐัั ะฟัะพัะพะบะพะป ะธัะฟะพะปัะทัั ัะบะฐะทะฐะฝะฝะพะณะพ ะฟัะพะฒะฐะนะดะตัะฐ"""
        if provider_name not in self.providers:
            raise ValueError(f"ะะตะธะทะฒะตััะฝัะน ะฟัะพะฒะฐะนะดะตั: {provider_name}")
        
        provider = self.providers[provider_name]
        if not provider.is_available():
            raise ValueError(f"ะัะพะฒะฐะนะดะตั {provider_name} ะฝะตะดะพัััะฟะตะฝ")
        
        # ะะตัะตะดะฐะตะผ ะดะพะฟะพะปะฝะธัะตะปัะฝัะต ะฐัะณัะผะตะฝัั (ะฝะฐะฟัะธะผะตั, openai_model_key)
        return await provider.generate_protocol(transcription, template_variables, diarization_data, **kwargs)
    
    async def generate_protocol_with_fallback(self, preferred_provider: str, transcription: str, 
                                            template_variables: Dict[str, str], diarization_data: Optional[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:
        """ะะตะฝะตัะธัะพะฒะฐัั ะฟัะพัะพะบะพะป ั ะฟะตัะตะบะปััะตะฝะธะตะผ ะฝะฐ ัะตะทะตัะฒะฝัะน ะฟัะพะฒะฐะนะดะตั ะฒ ัะปััะฐะต ะพัะธะฑะบะธ"""
        available_providers = list(self.get_available_providers().keys())
        
        if not available_providers:
            raise ValueError("ะะตั ะดะพัััะฟะฝัั LLM ะฟัะพะฒะฐะนะดะตัะพะฒ")
        
        # ะกะฝะฐัะฐะปะฐ ะฟัะพะฑัะตะผ ะฟัะตะดะฟะพัะธัะฐะตะผัะน ะฟัะพะฒะฐะนะดะตั
        providers_to_try = [preferred_provider] if preferred_provider in available_providers else []
        # ะะพะฑะฐะฒะปัะตะผ ะพััะฐะปัะฝัะต ะฟัะพะฒะฐะนะดะตัั ะบะฐะบ ัะตะทะตัะฒะฝัะต
        for provider in available_providers:
            if provider not in providers_to_try:
                providers_to_try.append(provider)
        
        last_error = None
        for provider_name in providers_to_try:
            try:
                logger.info(f"ะะพะฟััะบะฐ ะณะตะฝะตัะฐัะธะธ ะฟัะพัะพะบะพะปะฐ ั ะฟัะพะฒะฐะนะดะตัะพะผ: {provider_name}")
                result = await self.generate_protocol(provider_name, transcription, template_variables, diarization_data, **kwargs)
                logger.info(f"ะฃัะฟะตัะฝะพ ัะณะตะฝะตัะธัะพะฒะฐะฝ ะฟัะพัะพะบะพะป ั ะฟัะพะฒะฐะนะดะตัะพะผ: {provider_name}")
                return result
            except Exception as e:
                last_error = e
                logger.warning(f"ะัะธะฑะบะฐ ั ะฟัะพะฒะฐะนะดะตัะพะผ {provider_name}: {e}")
                continue
        
        # ะัะปะธ ะฒัะต ะฟัะพะฒะฐะนะดะตัั ะฝะต ััะฐะฑะพัะฐะปะธ
        raise ValueError(f"ะัะต ะดะพัััะฟะฝัะต ะฟัะพะฒะฐะนะดะตัั ะฝะต ััะฐะฑะพัะฐะปะธ. ะะพัะปะตะดะฝัั ะพัะธะฑะบะฐ: {last_error}")


# ===================================================================
# ะะะฃะฅะญะขะะะะะฏ ะะะะะะะฆะะฏ ะะะะขะะะะะ
# ===================================================================

def _build_extraction_prompt(
    transcription: str,
    template_variables: Dict[str, str],
    diarization_data: Optional[Dict[str, Any]] = None,
    speaker_mapping: Optional[Dict[str, str]] = None,
    meeting_topic: Optional[str] = None,
    meeting_date: Optional[str] = None,
    meeting_time: Optional[str] = None,
    participants: Optional[List[Dict[str, str]]] = None
) -> str:
    """
    ะัะพะผะฟั ะดะปั ะฟะตัะฒะพะณะพ ััะฐะฟะฐ: ะธะทะฒะปะตัะตะฝะธะต ะธ ััััะบัััะธัะพะฒะฐะฝะธะต ะธะฝัะพัะผะฐัะธะธ
    """
    # ะะปะพะบ ะบะพะฝัะตะบััะฐ (ั ััััะพะผ ะดะธะฐัะธะทะฐัะธะธ)
    if diarization_data and diarization_data.get("formatted_transcript"):
        transcription_text = (
            "ะขัะฐะฝัะบัะธะฟัะธั ั ัะฐะทะดะตะปะตะฝะธะตะผ ะณะพะฒะพัััะธั:\n"
            f"{diarization_data['formatted_transcript']}\n\n"
            "ะะพะฟะพะปะฝะธัะตะปัะฝะฐั ะธะฝัะพัะผะฐัะธั:\n"
            f"- ะะพะปะธัะตััะฒะพ ะณะพะฒะพัััะธั: {diarization_data.get('total_speakers', 'ะฝะตะธะทะฒะตััะฝะพ')}\n"
            f"- ะกะฟะธัะพะบ ะณะพะฒะพัััะธั: {', '.join(diarization_data.get('speakers', []))}\n\n"
        )
    else:
        transcription_text = f"ะขัะฐะฝัะบัะธะฟัะธั:\n{transcription}\n\n"
    
    # ะะพะฑะฐะฒะปัะตะผ ะธะฝัะพัะผะฐัะธั ะพ ัะพะฟะพััะฐะฒะปะตะฝะธะธ ัะฟะธะบะตัะพะฒ
    participants_info = ""
    if speaker_mapping:
        participants_info = "\nะฃะงะะกะขะะะะ ะะกะขะะะงะ:\n"
        for speaker_id, participant_name in speaker_mapping.items():
            participants_info += f"- {speaker_id} = {participant_name}\n"
        participants_info += "\nโ๏ธ ะะะกะขะะฃะะฆะะ ะะ ะฃะงะะกะขะะะะะ:\n"
        participants_info += "- ะัะฟะพะปัะทัะน ะะะะะฌะะซะ ะะะะะ ะฒะผะตััะพ ะผะตัะพะบ ัะฟะธะบะตัะพะฒ\n"
        participants_info += "- ะัะธ ัะบะฐะทะฐะฝะธะธ ะพัะฒะตัััะฒะตะฝะฝัั ะฟะธัะธ ะขะะะฌะะ ะะะฏ (ะฑะตะท ัะพะปะธ ะฒ ัะบะพะฑะบะฐั)\n"
        participants_info += "- ะคะพัะผะฐั: 'ะะฐะดะฐัะฐ โ ะัะฒะตัััะฒะตะฝะฝัะน: ะะผั ะคะฐะผะธะปะธั'\n\n"
        participants_info += "๐ ะกะะะะกะขะะะะะะะ ะะะะ:\n"
        participants_info += "ะัะปะธ ะฒ ััะฐะฝัะบัะธะฟัะธะธ ะฒัััะตัะฐัััั ัะพะบัะฐัะตะฝะฝัะต ะธะผะตะฝะฐ ะธะปะธ ะฝะตะฟะพะปะฝัะต ัะฟะพะผะธะฝะฐะฝะธั โ\n"
        participants_info += "ัะพะฟะพััะฐะฒะปัะน ะธั ั ะฟะพะปะฝัะผะธ ะธะผะตะฝะฐะผะธ ะธะท ัะฟะธัะบะฐ ััะฐััะฝะธะบะพะฒ ะฒััะต.\n\n"
        participants_info += "ะัะธะผะตัั ะปะพะณะธะบะธ (ะฟัะธะผะตะฝัะน ะบะพ ะะกะะ ััะฐััะฝะธะบะฐะผ ะธะท ัะฟะธัะบะฐ):\n"
        participants_info += "   โข ะฃะผะตะฝััะธัะตะปัะฝัะต: ะกะฒะตัะฐโะกะฒะตัะปะฐะฝะฐ, ะะตัะฐโะะปะตะบัะตะน ะธ ั.ะด.\n"
        participants_info += "   โข ะะพ ัะฐะผะธะปะธะธ: ะขะธะผัะตะฝะบะพโะะปะตะบัะตะน ะขะธะผัะตะฝะบะพ ะธ ั.ะด.\n"
        participants_info += "   โข ะขะพะปัะบะพ ะธะผั: ะะปะตะบัะตะนโะะปะตะบัะตะน ะขะธะผัะตะฝะบะพ\n\n"
        participants_info += "โก ะะฝะฐะปะธะทะธััะน ะะะกะฌ ัะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ, ะฝะต ัะพะปัะบะพ ััะธ ะฟัะธะผะตัั!\n"
        participants_info += "โก ะ ะฟัะพัะพะบะพะปะต ะธัะฟะพะปัะทัะน ะะะะะะ ะะะฏ ะธะท ัะฟะธัะบะฐ.\n\n"
    elif participants:
        # ะัะปะธ ะฝะตั speaker_mapping, ะฝะพ ะตััั ัะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ
        participants_info = "\nโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        participants_info += "โ  ๐ฏ ะะะะะซะ ะกะะะกะะ ะฃะงะะกะขะะะะะ (ะะะฏะะะขะะะะ ะ ะะกะะะะฌะะะะะะะฎ) โ\n"
        participants_info += "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ\n"
        from src.services.participants_service import participants_service
        # ะะะะะ: format_participants_for_llm ะฟัะตะพะฑัะฐะทัะตั ะธะผะตะฝะฐ ะฒ ัะพัะผะฐั "ะะผั ะคะฐะผะธะปะธั" (ะฑะตะท ะพััะตััะฒะฐ)
        participants_info += participants_service.format_participants_for_llm(participants)
        participants_info += "\n\n๐จ ะกะขะะะะะ ะะะะะะะ:\n"
        participants_info += "1. ะขะะะฌะะ ะธะผะตะฝะฐ ะะ ะกะะะกะะ ะะซะจะ! ะคะพัะผะฐั: 'ะะผั ะคะฐะผะธะปะธั'\n"
        participants_info += "2. ะะะะะะฉะะะ: 'ะะพะปะปะตะณะฐ ะธะท ะะะข', ัะพะปัะบะพ ะธะผั ('ะกะพััั'), ัะพะปัะบะพ ัะฐะผะธะปะธั ('ะะธะบัะปะธะฝ')\n"
        participants_info += "3. ะกะะะะกะขะะะะะะะ ัะพะบัะฐัะตะฝะธะน:\n"
        participants_info += "   โข 'ะกะฒะตัะฐ'/'ะกะฒะตัะพัะบะฐ' โ ะฝะฐะนะดะธ 'ะกะฒะตัะปะฐะฝะฐ' โ ะธัะฟะพะปัะทัะน ะฟะพะปะฝะพะต ะธะผั\n"
        participants_info += "   โข 'ะะตัะฐ'/'ะะปััะฐ' โ ะฝะฐะนะดะธ 'ะะปะตะบัะตะน' โ ะธัะฟะพะปัะทัะน ะฟะพะปะฝะพะต ะธะผั\n"
        participants_info += "   โข ะคะฐะผะธะปะธั ('ะะธะบัะปะธะฝ') โ ะฝะฐะนะดะธ ะฒ ัะฟะธัะบะต โ ะธัะฟะพะปัะทัะน 'ะะผั ะคะฐะผะธะปะธั'\n"
        participants_info += "   โข ะะผั ('ะะฐัะฐั') โ ะฝะฐะนะดะธ ะฒ ัะฟะธัะบะต โ ะธัะฟะพะปัะทัะน 'ะะผั ะคะฐะผะธะปะธั'\n"
        participants_info += "4. ะัะปะธ ะะ ะผะพะถะตัั ะพะฟัะตะดะตะปะธัั ะบะพะฝะบัะตัะฝะพะณะพ ัะตะปะพะฒะตะบะฐ - ะะ ะฒะบะปััะฐะน\n\n"
        participants_info += "โก ะะะะะ: ะัะฟะพะปัะทัะน ะขะะงะะะ ะฝะฐะฟะธัะฐะฝะธะต ะธะท ัะฟะธัะบะฐ!\n\n"
    else:
        # ะะตั ะฝะธ speaker_mapping, ะฝะธ participants - ะฐะฒัะพะพะฟัะตะดะตะปะตะฝะธะต ะธะท ััะฐะฝัะบัะธะฟัะธะธ
        participants_info = "\nโ๏ธ ะะะขะะะะขะะงะะกะะะ ะะะะะะะะะะะ ะฃะงะะกะขะะะะะ ะะ ะขะะะะกะะะะะฆะะ\n"
        participants_info += "โ" * 63 + "\n\n"
        participants_info += "ะกะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ ะฝะต ะฟัะตะดะพััะฐะฒะปะตะฝ. ะะฟัะตะดะตะปะธ ะธะผะตะฝะฐ ะธะท ััะฐะฝัะบัะธะฟัะธะธ.\n\n"
        participants_info += "๐ ะะะะะะะ ะะะะะะะะะะะฏ:\n\n"
        participants_info += "1๏ธโฃ ะะฉะ ะฏะะะซะ ะฃะะะะะะะะะฏ:\n"
        participants_info += "   โข ะัะตะดััะฐะฒะปะตะฝะธั: 'ะะตะฝั ะทะพะฒัั ะะฒะฐะฝ ะะตััะพะฒ', 'ะฏ โ ะะฐัะธั'\n"
        participants_info += "   โข ะะฑัะฐัะตะฝะธั: 'ะกะฒะตัะฐ, ะบะฐะบ ะดัะผะฐะตัั?', 'ะะตััะพะฒ, ัะฐััะบะฐะถะธ ะพ ะทะฐะดะฐัะต'\n"
        participants_info += "   โข ะฃะฟะพะผะธะฝะฐะฝะธั: 'ะะฐะบ ัะบะฐะทะฐะป ะะฒะฐะฝ...', 'ะัะถะฝะพ ััะพัะฝะธัั ั ะะฐัะธะธ'\n\n"
        participants_info += "2๏ธโฃ ะคะะะะะข ะะะะ:\n"
        participants_info += "   โข ะัะตะดะฟะพััะธัะตะปัะฝะพ: 'ะะผั ะคะฐะผะธะปะธั' (ะะะ ะพััะตััะฒะฐ)\n"
        participants_info += "   โข ะัะปะธ ะธะทะฒะตััะฝะพ ัะพะปัะบะพ ะธะผั: 'ะะฒะฐะฝ'\n"
        participants_info += "   โข ะัะปะธ ะธะทะฒะตััะฝะฐ ัะพะปัะบะพ ัะฐะผะธะปะธั: 'ะะตััะพะฒ'\n"
        participants_info += "   โข ะัะตะพะฑัะฐะทัะน ัะผะตะฝััะธัะตะปัะฝัะต: ะกะฒะตัะฐโะกะฒะตัะปะฐะฝะฐ, ะะตัะฐโะะปะตะบัะตะน, ะะพะปะพะดัโะะปะฐะดะธะผะธั\n\n"
        participants_info += "3๏ธโฃ ะกะะะะกะขะะะะะะะ ะกะ ะกะะะะะะะะ:\n"
        participants_info += "   โข ะกะพะฟะพััะฐะฒั ะบะฐะถะดัั ะผะตัะบั (SPEAKER_1, SPEAKER_2...) ั ะธะผะตะฝะตะผ ะตัะปะธ ะฒะพะทะผะพะถะฝะพ\n"
        participants_info += "   โข ะัะปะธ ะธะผั ะพะฟัะตะดะตะปะธัั ะะะะะะะะะะ - ะพััะฐะฒั ะผะตัะบั ัะฟะธะบะตัะฐ ะบะฐะบ ะตััั\n"
        participants_info += "   โข ะัะธะผะตั ัะตะทัะปััะฐัะฐ: 'ะะฒะฐะฝ ะะตััะพะฒ\\nะกะะะะะR_2\\nะกะฒะตัะปะฐะฝะฐ ะะพัะพัะบะพะฒะฐ\\nะกะะะะะR_4'\n\n"
        participants_info += "4๏ธโฃ ะกะขะะะะะ ะะะะะะขะซ:\n"
        participants_info += "   โ ะะ ะฟัะธะดัะผัะฒะฐะน ะธะผะตะฝะฐ, ะบะพัะพััั ะะะข ะฒ ััะฐะฝัะบัะธะฟัะธะธ\n"
        participants_info += "   โ ะะ ะธัะฟะพะปัะทัะน 'ะฃัะฐััะฝะธะบ 1', 'ะะพะปะปะตะณะฐ', 'ะงะตะปะพะฒะตะบ ะ', 'ะะตะธะทะฒะตััะฝัะน'\n"
        participants_info += "   โ ะะ ะดัะฑะปะธััะน: ะตัะปะธ ะกะฒะตัะฐ = SPEAKER_1, ะฝะต ะดะพะฑะฐะฒะปัะน ะกะฒะตัะปะฐะฝั ะพัะดะตะปัะฝะพ\n"
        participants_info += "   โ ะะ ะทะฐะผะตะฝัะน SPEAKER_N ะฝะฐ ะพะฟะธัะฐะฝะธั ัะธะฟะฐ 'ะัะบะพะฒะพะดะธัะตะปั ะฒัััะตัะธ'\n\n"
        participants_info += "๐ก ะะะะกะะะะะ:\n"
        participants_info += "   โข ะะฐัะฐะปะพ ะฒัััะตัะธ - ัะฐััะพ ัะฐะผ ะฟัะตะดััะฐะฒะปััััั\n"
        participants_info += "   โข ะะฑัะฐัะตะฝะธั ะฟะพ ะธะผะตะฝะธ - ัะฐะผัะน ะฝะฐะดะตะถะฝัะน ะฟัะธะทะฝะฐะบ\n"
        participants_info += "   โข ะะพะฝัะตะบัั: 'ะฝะฐั ัะธะผะปะธะด ะะปะตะบัะตะน', 'ะผะตะฝะตะดะถะตั ะะฐัะธั'\n"
        participants_info += "   โข ะฃะฒะตัะตะฝะฝะพััะธ ะฝะตั? โ ะััะฐะฒั SPEAKER_N\n\n"

    # ะะพะฑะฐะฒะปัะตะผ ะธะฝัะพัะผะฐัะธั ะพ ะฒัััะตัะต
    meeting_info = ""
    if meeting_topic or meeting_date or meeting_time:
        meeting_info = "\nะะะคะะะะะฆะะฏ ะ ะะกะขะะะงะ:\n"
        if meeting_topic:
            meeting_info += f"- ะขะตะผะฐ: {meeting_topic}\n"
        if meeting_date:
            meeting_info += f"- ะะฐัะฐ: {meeting_date}\n"
        if meeting_time:
            meeting_info += f"- ะัะตะผั: {meeting_time}\n"
        meeting_info += "\n"
    
    # ะะพะฑะฐะฒะปัะตะผ ััััะบัััะฝัะน ะฐะฝะฐะปะธะท ะตัะปะธ ะดะพัััะฟะตะฝ

    
    variables_str = "\n".join([f"- {key}: {desc}" for key, desc in template_variables.items()])
    
    prompt = f"""ะญะขะะ 1: ะะะะะะงะะะะ ะะะคะะะะะฆะะ

{transcription_text}{participants_info}{meeting_info}

ะะะะะงะ:
ะะทะฒะปะตะบะธ ะธะท ััะฐะฝัะบัะธะฟัะธะธ ะธะฝัะพัะผะฐัะธั ะดะปั ัะปะตะดัััะธั ะฟะพะปะตะน:
{variables_str}

ะคะะะะะขะะะะะะะะ ะะะกะฃะะะะะะฏ:
ะัะปะธ ะณััะฟะฟะธััะตัั ะพะฑััะถะดะตะฝะธะต ะฟะพ ัะตะผะฐะผ/ะบะปะฐััะตัะฐะผ:
- ะะ ะฟะธัะธ ัะปะพะฒะพ "ะะปะฐััะตั", ัะพะปัะบะพ ะฝะฐะทะฒะฐะฝะธะต ัะตะผั ั ะผะฐัะบะตัะพะผ: "โข **ะะฐะทะฒะฐะฝะธะต ัะตะผั**"
- ะะฐะถะดัั ะธะดะตั/ะฒััะบะฐะทัะฒะฐะฝะธะต/ะฟะพะทะธัะธั ั ะฝะพะฒะพะน ัััะพะบะธ
- ะคะพัะผะฐั ะฒััะบะฐะทัะฒะฐะฝะธั: "ะะผั ะะฒัะพัะฐ: ัะตะบัั" (ะฑะตะท ัะปะพะฒะฐ "ะะดะตั", ะฑะตะท ัะบะพะฑะพะบ)
- ะะตะถะดั ัะตะผะฐัะธัะตัะบะธะผะธ ะฑะปะพะบะฐะผะธ ะพััะฐะฒะปัะน ะฟััััั ัััะพะบั ะดะปั ะฒะธะทัะฐะปัะฝะพะณะพ ัะฐะทะดะตะปะตะฝะธั

ะัะธะผะตัั:
โ ะะะะะะะฌะะ:
โข **ะัะฑะพั ะฐััะธัะตะบัััั**

ะะปะตะบัะตะน ะขะธะผัะตะฝะบะพ: ะฟัะตะดะปะพะถะธะป ะผะธะบัะพัะตัะฒะธัั

ะะฐัะธั ะะฒะฐะฝะพะฒะฐ: ะฟะพะดะดะตัะถะฐะปะฐ ะธะดะตั

โ ะะะะะะะะะฌะะ:
โข ะะปะฐััะตั ยซะัะฑะพั ะฐััะธัะตะบััััยป: ะะดะตั (ะะปะตะบัะตะน ะขะธะผัะตะฝะบะพ): ะฟัะตะดะปะพะถะธะป...

ะขะะะะะะะะะฏ:
1. ะัะฟะพะปัะทัะน ะขะะะฌะะ ัะฐะบัั ะธะท ััะฐะฝัะบัะธะฟัะธะธ
2. ะัะปะธ ะธะฝัะพัะผะฐัะธั ะฝะต ะฝะฐะนะดะตะฝะฐ ัะฒะฝะพ - ะฟะธัะธ "ะะต ัะบะฐะทะฐะฝะพ"
3. ะกะพััะฐะฝัะน ััะพะฝะพะปะพะณะธัะตัะบะธะน ะฟะพััะดะพะบ
4. ะะ ะธะฝัะตัะฟัะตัะธััะน ะธ ะะ ะดะพะฑะฐะฒะปัะน ัะพะฑััะฒะตะฝะฝัะต ะฒัะฒะพะดั
5. ะะปั ัะฟะธัะบะพะฒ ะธัะฟะพะปัะทัะน ัะพัะผะฐั: "- ะฟัะฝะบั1\\n- ะฟัะฝะบั2"
6. ะะปั ััะฐััะฝะธะบะพะฒ: ะบะฐะถะดะพะต ะธะผั ั ะฝะพะฒะพะน ัััะพะบะธ ัะตัะตะท \\n, ะะะ ัะพะปะตะน!

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะกะะะฆะะคะะงะะซะ ะะะะะะะ ะะ ะขะะะะ ะะะะะ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

{_build_field_specific_rules(template_variables)}

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

ะะะะขะะงะะกะะ ะะะะะ โ ัะพัะผะฐัะธัะพะฒะฐะฝะธะต ะทะฝะฐัะตะฝะธะน ะฒ extracted_data:
- ะะกะ ะทะฝะฐัะตะฝะธั ะะะฃะขะะ extracted_data ะดะพะปะถะฝั ะฑััั ะะะะกะขะซะะ ะกะขะะะะะะ (string)
- ะะ ะธัะฟะพะปัะทัะน ะฒะปะพะถะตะฝะฝัะต ะพะฑัะตะบัั {{}} ะธะปะธ ะผะฐััะธะฒั [] ะฒ ะบะฐัะตััะฒะต ะทะฝะฐัะตะฝะธะน ะฟะพะปะตะน ะฟัะพัะพะบะพะปะฐ
- ะะฐัั: "20 ะพะบััะฑัั 2024", ะะ {{"day": 20, "month": "ะพะบััะฑัั"}}
- ะฃัะฐััะฝะธะบะธ: "ะะผั1\\nะะผั2\\nะะผั3", ะะ [{{"name": "ะะผั"}}], ะะ "ะะผั, ัะพะปั; ะะผั2"
- ะกะฟะธัะบะธ: "- ัะปะตะผะตะฝั1\\n- ัะปะตะผะตะฝั2", ะะ ["ัะปะตะผะตะฝั1", "ัะปะตะผะตะฝั2"]
- โ ะะกะะะฎะงะะะะ: ะกัััะบัััะฐ ะฒะตััะฝะตะณะพ ััะพะฒะฝั (extracted_data, confidence_score, extraction_notes) - ััะพ ะพะฑัะตะบัั, ะฝะพ ะธั ะทะฝะฐัะตะฝะธั ะดะพะปะถะฝั ะฑััั ัััะพะบะฐะผะธ

ะะะะะะ ะะะะะะะฌะะะะ JSON:
{{
  "date": "20 ะพะบััะฑัั 2024",
  "participants": "ะะบัะฐะฝะฐ ะะฒะฐะฝะพะฒะฐ\\nะะฐะปะธะฝะฐ ะะตััะพะฒะฐ\\nะะปะตะบัะตะน ะกะผะธัะฝะพะฒ",
  "decisions": "- ะะตัะตะฝะธะต 1\\n- ะะตัะตะฝะธะต 2"
}}

ะะะะขะะงะะกะะ ะะะะะ โ ะกะขะะฃะะขะฃะะ ะะขะะะขะ:
ะขะฒะพะน ะพัะฒะตั ะดะพะปะถะตะฝ ะฑััั JSON ั ะขะะะะฏ ะฟะพะปัะผะธ:
{{
  "extracted_data": {{
    "ะฟะพะปะต1": "ะทะฝะฐัะตะฝะธะต1",
    "ะฟะพะปะต2": "ะทะฝะฐัะตะฝะธะต2",
    ...ะฒัะต ะฟะพะปั ะธะท ัะฟะธัะบะฐ ะฒััะต...
  }},
  "confidence_score": 0.85,
  "extraction_notes": "ะบัะฐัะบะธะต ะทะฐะผะตัะบะธ ะพ ะฟัะพัะตััะต ะธะทะฒะปะตัะตะฝะธั"
}}

ะะะ:
- extracted_data: ะพะฑัะตะบั ั ะธะทะฒะปะตัะตะฝะฝัะผะธ ะดะฐะฝะฝัะผะธ (ะบะปััะธ = ะฟะพะปั ะธะท ัะฟะธัะบะฐ ะฒััะต)
- confidence_score: ัะฒะพั ัะฒะตัะตะฝะฝะพััั ะฒ ัะตะทัะปััะฐัะต (ัะธัะปะพ ะพั 0.0 ะดะพ 1.0)
- extraction_notes: ะบัะฐัะบะธะต ะทะฐะผะตัะบะธ ะพ ัะปะพะถะฝะพัััั ะธะปะธ ะพัะพะฑะตะฝะฝะพัััั

ะะะะะ: ะะพะปะต extracted_data ะะะฏะะะขะะะฌะะ ะดะพะปะถะฝะพ ัะพะดะตัะถะฐัั ะะกะ ะบะปััะธ ะธะท ัะฟะธัะบะฐ ะฟะพะปะตะน!
ะัะปะธ ะธะฝัะพัะผะฐัะธั ะฝะต ะฝะฐะนะดะตะฝะฐ - ะฟะธัะธ "ะะต ัะบะฐะทะฐะฝะพ", ะฝะพ ะบะปัั ะดะพะปะถะตะฝ ะฟัะธัััััะฒะพะฒะฐัั!

ะะะะะะะะขะะะฌะะซะ ะะะฆะะะะะะฌะะซะ ะะะะฏ (ะดะพะฑะฐะฒะปัะน ะขะะะฌะะ ะตัะปะธ ะฟัะธะผะตะฝะธะผะพ):
- detected_speaker_mapping: ะพะฑัะตะบั ั ะฐะฒัะพะผะฐัะธัะตัะบะธะผ ัะพะฟะพััะฐะฒะปะตะฝะธะตะผ SPEAKER_N ั ะธะผะตะฝะฐะผะธ
  ะัะธะผะตั: {{"SPEAKER_1": "ะะปะตะบัะตะน ะขะธะผัะตะฝะบะพ", "SPEAKER_2": "ะะฐัะธั ะะฒะฐะฝะพะฒะฐ"}}
- speaker_confidence_scores: ะพะฑัะตะบั ั ัะฒะตัะตะฝะฝะพัััั ะฒ ัะพะฟะพััะฐะฒะปะตะฝะธะธ (0.0-1.0)
  ะัะธะผะตั: {{"SPEAKER_1": 0.95, "SPEAKER_2": 0.80}}
- unmapped_speakers: ะผะฐััะธะฒ ัะฟะธะบะตัะพะฒ, ะบะพัะพััั ะฝะต ัะดะฐะปะพัั ะธะดะตะฝัะธัะธัะธัะพะฒะฐัั
  ะัะธะผะตั: ["SPEAKER_3", "SPEAKER_5"]
- mapping_notes: ัััะพะบะฐ ั ะทะฐะผะตัะบะฐะผะธ ะพ ะปะพะณะธะบะต ัะพะฟะพััะฐะฒะปะตะฝะธั ัะฟะธะบะตัะพะฒ

โ๏ธ ะญัะธ ะฟะพะปั ะดะพะฑะฐะฒะปัะน ะขะะะฌะะ ะตัะปะธ ะฒ ััะฐะฝัะบัะธะฟัะธะธ ะตััั ะผะตัะบะธ SPEAKER_N ะธ ัั ะผะพะถะตัั ะธั ัะพะฟะพััะฐะฒะธัั ั ะธะผะตะฝะฐะผะธ ะธะท ะบะพะฝัะตะบััะฐ.

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ๏ธ ะะะะะขะ ะก ะะะะฌะจะะะ ะขะะะะกะะะะะฆะะฏะะ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

ะัะปะธ ััะฐะฝัะบัะธะฟัะธั ะพัะตะฝั ะดะปะธะฝะฝะฐั ะธ ะตััั ัะธัะบ ะฟัะตะฒััะตะฝะธั ะปะธะผะธัะฐ ะพัะฒะตัะฐ:

1. ะะะะะะะขะะขะซ ะะะะะะงะะะะฏ (ะพั ะฒัััะตะณะพ ะบ ะฝะธะทัะตะผั):
   โ ะะตัะตะฝะธั ะธ ะดะพะณะพะฒะพัะตะฝะฝะพััะธ (ะะะฏะะะขะะะฌะะ)
   โ ะะฐะดะฐัะธ ั ะพัะฒะตัััะฒะตะฝะฝัะผะธ ะธ ััะพะบะฐะผะธ (ะะะฏะะะขะะะฌะะ)
   โ ะะปััะตะฒัะต ะผะพะผะตะฝัั ะพะฑััะถะดะตะฝะธั (ะฒะฐะถะฝะพ)
   โ๏ธ ะะตัะฐะปะธ ะธ ะฟัะธะผะตัั (ะผะพะถะฝะพ ัะพะบัะฐัะธัั, ะฝะพ ัะพััะฐะฝะธัั ัััั)

2. ะะะะะะะ ะกะะะะะฉะะะะฏ:
   - ะกะพะบัะฐัะฐะน ะะะขะะะ ะพะฑััะถะดะตะฝะธั, ะฝะพ ัะพััะฐะฝัะน ะกะฃะขะฌ ะธ ะะะจะะะะฏ
   - ะะ ะะะะซะะะ JSON ะฝะฐ ะฟะพะปััะปะพะฒะต - ะปัััะต ัะพะบัะฐัะธ ะดะตัะฐะปะธ, ะฝะพ ะทะฐะบัะพะน ะฒัะต ะบะฐะฒััะบะธ ะธ ัะบะพะฑะบะธ
   - ะัะปะธ ัะพะบัะฐัะฐะตัั ัะพะดะตัะถะธะผะพะต - ะดะพะฑะฐะฒั ะฒ extraction_notes: "ะขัะฐะฝัะบัะธะฟัะธั ะพะฑัะฐะฑะพัะฐะฝะฐ ั ะฟัะธะพัะธัะธะทะฐัะธะตะน ะบะปััะตะฒัั ะผะพะผะตะฝัะพะฒ"

3. ะะะะขะะงะะกะะ ะะะะะ:
   ๐จ JSON ะะะะะะ ะะซะขะฌ ะะะะะะะซะ ะธ ะะะะะซะ, ะดะฐะถะต ะตัะปะธ ัะพะดะตัะถะธะผะพะต ัะพะบัะฐัะตะฝะพ!
   ๐จ ะัะต ัะบะพะฑะบะธ {{}}, ะบะฐะฒััะบะธ "" ะดะพะปะถะฝั ะฑััั ะทะฐะบัััั
   ๐จ ะัััะต ะบะพัะพัะบะธะน, ะฝะพ ะฒะฐะปะธะดะฝัะน JSON, ัะตะผ ะดะปะธะฝะฝัะน ะพะฑัะตะทะฐะฝะฝัะน

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

ะัะฒะตะดะธ ะขะะะฌะะ JSON ะฒ ัะบะฐะทะฐะฝะฝะพะผ ัะพัะผะฐัะต, ะฑะตะท ะดะพะฟะพะปะฝะธัะตะปัะฝัั ะบะพะผะผะตะฝัะฐัะธะตะฒ."""

    return prompt


def _build_reflection_prompt(
    extracted_data: Dict[str, Any],
    transcription: str,
    template_variables: Dict[str, str],
    diarization_analysis: Optional[Dict[str, Any]] = None
) -> str:
    """
    ะัะพะผะฟั ะดะปั ะฒัะพัะพะณะพ ััะฐะฟะฐ: ะฟัะพะฒะตัะบะฐ ะธ ัะปัััะตะฝะธะต
    ะะะขะะะะะะะะะะะ: ะธัะฟะพะปัะทัะตั ัะตะปะตะฒะฐะฝัะฝัะต ััะฐะณะผะตะฝัั ะฒะผะตััะพ ะฟะพะปะฝะพะน ััะฐะฝัะบัะธะฟัะธะธ
    """
    from src.utils.context_extraction import extract_relevant_excerpts
    
    extracted_json = json.dumps(extracted_data, ensure_ascii=False, indent=2)
    
    # ะกะพะบัะฐัะฐะตะผ ะบะพะฝัะตะบัั - ะธัะฟะพะปัะทัะตะผ ัะพะปัะบะพ ัะตะปะตะฒะฐะฝัะฝัะต ััะฐะณะผะตะฝัั
    max_context_tokens = settings.max_context_tokens_stage2
    relevant_context = extract_relevant_excerpts(
        transcription,
        extracted_data,
        max_tokens=max_context_tokens
    )
    
    logger.info(f"Stage 2: ัะพะบัะฐัะตะฝ ะบะพะฝัะตะบัั ั {len(transcription)} ะดะพ {len(relevant_context)} ัะธะผะฒะพะปะพะฒ")
    
    # ะะพะฑะฐะฒะปัะตะผ ะฐะฝะฐะปะธะท ะดะธะฐัะธะทะฐัะธะธ ะตัะปะธ ะตััั
    diarization_context = ""
    if diarization_analysis:
        speakers_info = diarization_analysis.get('speakers', {})
        if speakers_info:
            diarization_context = "\n\nะะะะะะ ะฃะงะะกะขะะะะะ:\n"
            for speaker_id, info in speakers_info.items():
                role = info.get('role', 'ััะฐััะฝะธะบ')
                time_percent = info.get('speaking_time_percent', 0)
                diarization_context += f"- {speaker_id} ({role}): {time_percent:.1f}% ะฒัะตะผะตะฝะธ\n"
    
    prompt = f"""ะญะขะะ 2: ะะะะะะะะ ะ ะฃะะฃะงะจะะะะ

ะะะะะะงะะะะซะ ะะะะะซะ (ััะฐะฟ 1):
{extracted_json}
{diarization_context}

ะะะะะะะะขะะซะ ะคะะะะะะะขะซ ะขะะะะกะะะะะฆะะ:
{relevant_context}


ะะะะะงะ:
ะัะพะฒะตัั ะธ ัะปัััะธ ะธะทะฒะปะตัะตะฝะฝัะต ะดะฐะฝะฝัะต, ะธัะฟะพะปัะทัั ะธััะพะดะฝัั ััะฐะฝัะบัะธะฟัะธั:

1. ะะะะะะะะ ะะะะะะขะซ:
   - ะัะต ะปะธ ะฒะฐะถะฝัะต ะผะพะผะตะฝัั ะธะท ััะฐะฝัะบัะธะฟัะธะธ ะพััะฐะถะตะฝั?
   - ะะตั ะปะธ ะฟัะพะฟััะตะฝะฝัั ัะตัะตะฝะธะน, ะทะฐะดะฐั ะธะปะธ ะฟัะพะฑะปะตะผ?
   - ะะพััะฐัะพัะฝะพ ะปะธ ะดะตัะฐะปะธะทะธัะพะฒะฐะฝั ะฟะพะปั?

2. ะะะะะะะะ ะขะะงะะะกะขะ:
   - ะัะต ะปะธ ัะฐะบัั ัะพะพัะฒะตัััะฒััั ััะฐะฝัะบัะธะฟัะธะธ?
   - ะะตั ะปะธ ะดะพะผััะปะพะฒ ะธะปะธ ะธะฝัะตัะฟัะตัะฐัะธะน?
   - ะะพััะตะบัะฝั ะปะธ ะธะผะตะฝะฐ ะธ ัะตัะผะธะฝั?

3. ะะกะะะะฌะะะะะะะ ะะะะะะะะฆะะ:
   - ะฃะบะฐะทะฐะฝั ะปะธ ะพัะฒะตัััะฒะตะฝะฝัะต ะทะฐ ะทะฐะดะฐัะธ ะธะท ัะธัะปะฐ ัะฟะธะบะตัะพะฒ?
   - ะััะฐะถะตะฝ ะปะธ ะฒะบะปะฐะด ัะฐะทะฝัั ััะฐััะฝะธะบะพะฒ?
   - ะัะฟะพะปัะทะพะฒะฐะฝะฐ ะปะธ ะธะฝัะพัะผะฐัะธั ะพ ัะพะปัั ัะฟะธะบะตัะพะฒ?

4. ะกะขะะฃะะขะฃะะ:
   - ะัะฐะฒะธะปัะฝะพ ะปะธ ะพััะพัะผะฐัะธัะพะฒะฐะฝั ัะฟะธัะบะธ (ั ะดะตัะธัะฐะผะธ)?
   - ะะตั ะปะธ ะปะธัะฝะตะน ะฟัะฝะบััะฐัะธะธ?
   - ะะพะณะธัะตะฝ ะปะธ ะฟะพััะดะพะบ ะฟัะฝะบัะพะฒ?

5. ะะะะะะะะ ะฃะงะะกะขะะะะะ ะ ะะขะะะขะกะขะะะะะซะฅ:
   - ะฃะบะฐะทะฐะฝั ะปะธ ัะตะฐะปัะฝัะต ะธะผะตะฝะฐ ะฒะผะตััะพ ะผะตัะพะบ ัะฟะธะบะตัะพะฒ?
   - ะ ะทะฐะดะฐัะฐั ะธ ัะตัะตะฝะธัั ะธะผะตะฝะฐ ะะะ ัะพะปะตะน ะฒ ัะบะพะฑะบะฐั?
   - ะัะฒะตัััะฒะตะฝะฝัะต ะฝะฐะทะฝะฐัะตะฝั ะฟะพ ัะผััะปั ะฒััะบะฐะทัะฒะฐะฝะธะน?
   - ะคะพัะผะฐั: 'ะะฐะดะฐัะฐ โ ะัะฒะตัััะฒะตะฝะฝัะน: ะะผั ะคะฐะผะธะปะธั' (ะะ 'ะะผั ะคะฐะผะธะปะธั (ัะพะปั)')

6. ะกะะะะกะขะะะะะะะ ะะะะ:
   - ะัะต ะปะธ ัะพะบัะฐัะตะฝะฝัะต/ัะผะตะฝััะธัะตะปัะฝัะต ะธะผะตะฝะฐ ะทะฐะผะตะฝะตะฝั ะฝะฐ ะฟะพะปะฝัะต ะธะท ัะฟะธัะบะฐ ััะฐััะฝะธะบะพะฒ?
   - ะัะต ะปะธ ัะฟะพะผะธะฝะฐะฝะธั ะฟะพ ัะฐะผะธะปะธะธ ะทะฐะผะตะฝะตะฝั ะฝะฐ ะฟะพะปะฝะพะต ะธะผั ะธะท ัะฟะธัะบะฐ?
   - ะัะปะธ ะฒ ัะตะบััะต ัะพะปัะบะพ ะธะผั, ะฐ ะฒ ััะฐััะฝะธะบะฐั ะฟะพะปะฝะพะต - ะธัะฟะพะปัะทัะตััั ะปะธ ะฟะพะปะฝะพะต?
   - ะัะพะฒะตัั ะะกะะฅ ััะฐััะฝะธะบะพะฒ ะธะท ัะฟะธัะบะฐ, ะฝะต ัะพะปัะบะพ ะพัะตะฒะธะดะฝัะต ะฟัะธะผะตัั!

ะะะกะขะะฃะะฆะะ ะะ ะฃะะฃะงะจะะะะฎ:
- ะัะปะธ ะฝะฐัะตะป ะฟัะพะฟััะตะฝะฝัั ะฒะฐะถะฝัั ะธะฝัะพัะผะฐัะธั - ะดะพะฑะฐะฒั ะตั
- ะัะปะธ ะฝะฐัะตะป ะฝะตัะพัะฝะพััั - ะธัะฟัะฐะฒั ะตั
- ะัะปะธ ะผะพะถะฝะพ ัะปัััะธัั ัะพัะผัะปะธัะพะฒะบั - ัะปัััะธ
- ะัะปะธ ะผะพะถะฝะพ ะดะพะฑะฐะฒะธัั ะบะพะฝัะตะบัั ะธะท ะดะธะฐัะธะทะฐัะธะธ - ะดะพะฑะฐะฒั
- ะัะปะธ ะฒะธะดะธัั ัะพะปั ะฒ ัะบะพะฑะบะฐั ั ะพัะฒะตัััะฒะตะฝะฝะพะณะพ - ะฃะะะะ ะตั (ะพััะฐะฒั ัะพะปัะบะพ ะธะผั)
- ะะ ะดะพะฑะฐะฒะปัะน ะธะฝัะพัะผะฐัะธั, ะบะพัะพัะพะน ะะะข ะฒ ััะฐะฝัะบัะธะฟัะธะธ

ะะะะขะะงะะกะะ ะะะะะ โ ะกะขะะฃะะขะฃะะ ะะขะะะขะ:
ะขะฒะพะน ะพัะฒะตั ะะะฏะะะขะะะฌะะ ะดะพะปะถะตะฝ ะฑััั JSON ั ะขะะะะฏ ะฟะพะปัะผะธ:
{{
  "refined_data": {{
    "ะฟะพะปะต1": "ัะปัััะตะฝะฝะพะต ะทะฝะฐัะตะฝะธะต1",
    "ะฟะพะปะต2": "ัะปัััะตะฝะฝะพะต ะทะฝะฐัะตะฝะธะต2",
    ...ะะกะ ะบะปััะธ ะธะท extracted_data ะฒััะต...
  }},
  "reflection_notes": "ััะพ ะฑัะปะพ ัะปัััะตะฝะพ, ะบะฐะบะธะต ะฟัะพะฑะปะตะผั ะธัะฟัะฐะฒะปะตะฝั",
  "quality_score": 0.9
}}

ะะะ:
- refined_data: ะพะฑัะตะบั ั ะขะะะ ะะ ะบะปััะฐะผะธ, ััะพ ะฒ extracted_data, ะฝะพ ั ัะปัััะตะฝะฝัะผะธ ะทะฝะฐัะตะฝะธัะผะธ
- reflection_notes: ะพะฟะธัะฐะฝะธะต ะฒะฝะตัะตะฝะฝัั ัะปัััะตะฝะธะน ะธ ะธัะฟัะฐะฒะปะตะฝะธะน
- quality_score: ะธัะพะณะพะฒะฐั ะพัะตะฝะบะฐ ะบะฐัะตััะฒะฐ ัะตะทัะปััะฐัะฐ (ัะธัะปะพ ะพั 0.0 ะดะพ 1.0)

ะะะะะ:
1. refined_data ะะะฏะะะขะะะฌะะ ะดะพะปะถะตะฝ ัะพะดะตัะถะฐัั ะะกะ ะบะปััะธ ะธะท extracted_data!
2. ะัะปะธ ะธะทะผะตะฝะตะฝะธะน ะฝะต ััะตะฑัะตััั - ัะบะพะฟะธััะน ะทะฝะฐัะตะฝะธะต ะธะท extracted_data
3. quality_score ะดะพะปะถะตะฝ ะฑััั > 0 (ะพะฑััะฝะพ 0.7-0.95 ะดะปั ะบะฐัะตััะฒะตะฝะฝะพะณะพ ัะตะทัะปััะฐัะฐ)

ะะะะะะ:
{{
  "refined_data": {{
    "date": "27 ะพะบััะฑัั 2024",
    "participants": "ะะฐัะธะฝะฐ ะกะธะดะพัะพะฒะฐ\\nะะปะตะบัะตะน ะะฒะฐะฝะพะฒ\\nะะบัะฐะฝะฐ ะะตััะพะฒะฐ",
    "decisions": "- ะะบะปััะธัั ััะฝะบัะธะพะฝะฐะปัะฝะพััั 27 ะพะบััะฑัั\\n- ะัะพะฒะตััะธ ะฒะตะฑะธะฝะฐั ะดะปั ะผะฐะณะฐะทะธะฝะพะฒ"
  }},
  "reflection_notes": "ะะฐะผะตะฝะตะฝั ะผะตัะบะธ SPEAKER ะฝะฐ ัะตะฐะปัะฝัะต ะธะผะตะฝะฐ, ะดะพะฑะฐะฒะปะตะฝะพ ะฒัะพัะพะต ัะตัะตะฝะธะต",
  "quality_score": 0.88
}}

ะัะฒะตะดะธ ะขะะะฌะะ JSON ะฒ ัะบะฐะทะฐะฝะฝะพะผ ัะพัะผะฐัะต, ะฑะตะท ะบะพะผะผะตะฝัะฐัะธะตะฒ."""

    return prompt


async def generate_protocol_two_stage(
    manager: 'LLMManager',
    provider_name: str,
    transcription: str,
    template_variables: Dict[str, str],
    diarization_data: Optional[Dict[str, Any]] = None,
    diarization_analysis: Optional[Dict[str, Any]] = None,
    **kwargs
) -> Dict[str, Any]:
    """
    ะะฒััััะฐะฟะฝะฐั ะณะตะฝะตัะฐัะธั ะฟัะพัะพะบะพะปะฐ: ะธะทะฒะปะตัะตะฝะธะต + ัะตัะปะตะบัะธั
    
    Args:
        manager: ะะตะฝะตะดะถะตั LLM
        provider_name: ะะฐะทะฒะฐะฝะธะต ะฟัะพะฒะฐะนะดะตัะฐ
        transcription: ะขะตะบัั ััะฐะฝัะบัะธะฟัะธะธ
        template_variables: ะะตัะตะผะตะฝะฝัะต ัะฐะฑะปะพะฝะฐ
        diarization_data: ะะฐะฝะฝัะต ะดะธะฐัะธะทะฐัะธะธ
        diarization_analysis: ะะฝะฐะปะธะท ะดะธะฐัะธะทะฐัะธะธ
        **kwargs: ะะพะฟะพะปะฝะธัะตะปัะฝัะต ะฟะฐัะฐะผะตััั
        
    Returns:
        ะฃะปัััะตะฝะฝัะน ะฟัะพัะพะบะพะป
    """
    logger.info("ะะฐัะฐะปะพ ะดะฒััััะฐะฟะฝะพะน ะณะตะฝะตัะฐัะธะธ ะฟัะพัะพะบะพะปะฐ")

    # ะะทะฒะปะตะบะฐะตะผ ะฟะฐัะฐะผะตััั ะธะท kwargs
    speaker_mapping = kwargs.get('speaker_mapping')
    meeting_topic = kwargs.get('meeting_topic')
    meeting_date = kwargs.get('meeting_date')
    meeting_time = kwargs.get('meeting_time')
    participants = kwargs.get('participants')

    # ะญะขะะ 1: ะะทะฒะปะตัะตะฝะธะต ะธะฝัะพัะผะฐัะธะธ
    logger.info("ะญัะฐะฟ 1: ะะทะฒะปะตัะตะฝะธะต ะธะฝัะพัะผะฐัะธะธ")
    extraction_prompt = _build_extraction_prompt(
        transcription,
        template_variables,
        diarization_data,
        speaker_mapping,
        meeting_topic,
        meeting_date,
        meeting_time,
        participants
    )
    
    # ะัะฟะพะปัะทัะตะผ ัะธััะตะผะฝัะน ะฟัะพะผะฟั (ั ััะตัะพะผ ะบะปะฐััะธัะธะบะฐัะธะธ ะตัะปะธ ะฒะบะปััะตะฝะฐ)
    system_prompt = _build_system_prompt(transcription, diarization_analysis)
    
    # ะะตะฝะตัะธััะตะผ ะฟะตัะฒัะน ัะตะทัะปััะฐั
    if provider_name == "openai":
        provider = manager.providers[provider_name]
        openai_model_key = kwargs.get("openai_model_key")
        
        # ะัะฑะพั ะฟัะตัะตัะฐ ะผะพะดะตะปะธ
        selected_model = settings.openai_model
        selected_base_url = settings.openai_base_url or "https://api.openai.com/v1"
        
        if openai_model_key:
            try:
                preset = next((p for p in settings.openai_models if p.key == openai_model_key), None)
                if preset:
                    selected_model = preset.model
                    if getattr(preset, 'base_url', None):
                        selected_base_url = preset.base_url
            except Exception:
                pass
        
        # ะะปะธะตะฝั ะดะปั ะฝัะถะฝะพะณะพ base_url
        client = provider.client
        if client is None or (selected_base_url and getattr(client, 'base_url', None) != selected_base_url):
            client = openai.OpenAI(
                api_key=settings.openai_api_key,
                base_url=selected_base_url,
                http_client=provider.http_client
            )
        
        # ะคะพัะผะธััะตะผ extra_headers ะดะปั ะฐััะธะฑััะธะธ
        extra_headers = {}
        if settings.http_referer:
            extra_headers["HTTP-Referer"] = settings.http_referer
        if settings.x_title:
            extra_headers["X-Title"] = settings.x_title
        
        # DEBUG ะปะพะณะธัะพะฒะฐะฝะธะต ะทะฐะฟัะพัะฐ ััะฐะฟะฐ 1
        if settings.llm_debug_log:
            logger.debug("=" * 80)
            logger.debug("[DEBUG] OpenAI REQUEST - Two-Stage Extraction (Stage 1)")
            logger.debug("=" * 80)
            logger.debug(f"Model: {selected_model}")
            logger.debug(f"System prompt:\n{system_prompt}")
            logger.debug("-" * 80)
            logger.debug(f"Extraction prompt:\n{extraction_prompt}")
            logger.debug("=" * 80)
        
        # ะญัะฐะฟ 1: ะะทะฒะปะตัะตะฝะธะต
        async def _call_openai_stage1():
            return await asyncio.to_thread(
                client.chat.completions.create,
                model=selected_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": extraction_prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_schema", "json_schema": TWO_STAGE_EXTRACTION_SCHEMA},
                extra_headers=extra_headers
            )
        
        try:
            response1 = await _call_openai_stage1()
        except openai.APIStatusError as e:
            # ะัะพะฒะตััะตะผ ะฝะฐ ะพัะธะฑะบั 402 - ะฝะตะดะพััะฐัะพัะฝะพ ะบัะตะดะธัะพะฒ
            if e.status_code == 402:
                error_message = e.message
                # ะััะฐะตะผัั ะธะทะฒะปะตัั ะฑะพะปะตะต ะฟะพะดัะพะฑะฝะพะต ัะพะพะฑัะตะฝะธะต ะธะท ัะตะปะฐ ะพัะฒะตัะฐ
                if hasattr(e, 'response') and e.response:
                    try:
                        error_body = e.response.json()
                        if 'error' in error_body and 'message' in error_body['error']:
                            error_message = error_body['error']['message']
                    except:
                        pass
                logger.error(f"ะะตะดะพััะฐัะพัะฝะพ ะบัะตะดะธัะพะฒ ะดะปั LLM (ััะฐะฟ 1): {error_message}")
                raise LLMInsufficientCreditsError(
                    message=error_message,
                    provider="openai",
                    model=selected_model
                )
            # ะััะณะธะต ะพัะธะฑะบะธ API ะฟัะพะฑัะฐััะฒะฐะตะผ ะดะฐะปััะต
            raise
        
        content1 = response1.choices[0].message.content
        
        # DEBUG ะปะพะณะธัะพะฒะฐะฝะธะต ะพัะฒะตัะฐ ััะฐะฟะฐ 1
        if settings.llm_debug_log:
            logger.debug("=" * 80)
            logger.debug("[DEBUG] OpenAI RESPONSE - Two-Stage Extraction (Stage 1)")
            logger.debug("=" * 80)
            if hasattr(response1, 'usage'):
                logger.debug(f"Usage: {response1.usage}")
            logger.debug(f"Content:\n{content1}")
            logger.debug("=" * 80)
        
        # ะะพะณะธัะพะฒะฐะฝะธะต ะบะตัะธัะพะฒะฐะฝะฝัั ัะพะบะตะฝะพะฒ ะดะปั Stage 1
        if settings.log_cache_metrics:
            log_cached_tokens_usage(
                response=response1,
                context="Two-Stage: Stage 1 Extraction",
                model_name=selected_model,
                provider="openai"
            )
        
        try:
            extracted_data = json.loads(content1)
        except json.JSONDecodeError as e:
            logger.error(f"ะัะธะฑะบะฐ ะฟะฐััะธะฝะณะฐ JSON ะฝะฐ ััะฐะฟะต 1: {e}")
            # ะััะฐะตะผัั ะธะทะฒะปะตัั JSON ะธะท ัะตะบััะฐ
            start_idx = content1.find('{')
            end_idx = content1.rfind('}') + 1
            json_str = content1[start_idx:end_idx] if start_idx != -1 and end_idx > start_idx else content1
            extracted_data = json.loads(json_str)
        
        logger.info(f"ะญัะฐะฟ 1 ะทะฐะฒะตััะตะฝ, ะธะทะฒะปะตัะตะฝะพ {len(extracted_data)} ะฟะพะปะตะน")
        
        # ะะะะะะะกะขะะะ: ะฟัะพะฒะตัะบะฐ reasoning tokens (ะฟัะธะทะฝะฐะบ ะฟัะพะฑะปะตะผั ะตัะปะธ > 20000)
        if hasattr(response1, 'usage') and hasattr(response1.usage, 'completion_tokens_details'):
            details = response1.usage.completion_tokens_details
            if details and hasattr(details, 'reasoning_tokens') and details.reasoning_tokens:
                reasoning_tokens = details.reasoning_tokens
                if reasoning_tokens > 20000:
                    logger.warning(
                        f"โ๏ธ ะญัะฐะฟ 1: ะผะพะดะตะปั ะธัะฟะพะปัะทะพะฒะฐะปะฐ {reasoning_tokens} reasoning tokens "
                        f"(> 20000). ะญัะพ ะผะพะถะตั ัะบะฐะทัะฒะฐัั ะฝะฐ ะฟัะพะฑะปะตะผั ั ะฟัะพะผะฟัะพะผ ะธะปะธ ะทะฐะดะฐัะตะน."
                    )
        
        # ะะะะะะะฆะะฏ ัะตะทัะปััะฐัะฐ ััะฐะฟะฐ 1
        extracted_content = extracted_data.get('extracted_data', {})
        confidence_score = extracted_data.get('confidence_score', 0.0)
        extraction_notes = extracted_data.get('extraction_notes', '')
        
        # ะะพะดััะตั ะทะฐะฟะพะปะฝะตะฝะฝัั ะฟะพะปะตะน (ะฝะต ะฟััััั ะธ ะฝะต "ะะต ัะบะฐะทะฐะฝะพ")
        filled_fields = 0
        empty_fields = []
        total_fields = len(template_variables)
        
        for field_name in template_variables.keys():
            field_value = extracted_content.get(field_name, '')
            if field_value and field_value.strip() and field_value.strip() not in ['ะะต ัะบะฐะทะฐะฝะพ', 'ะฝะต ัะบะฐะทะฐะฝะพ']:
                filled_fields += 1
            else:
                empty_fields.append(field_name)
        
        fill_percentage = (filled_fields / total_fields * 100) if total_fields > 0 else 0
        
        logger.info(
            f"ะญัะฐะฟ 1: ะทะฐะฟะพะปะฝะตะฝะพ {filled_fields}/{total_fields} ะฟะพะปะตะน ({fill_percentage:.1f}%), "
            f"confidence={confidence_score:.2f}"
        )
        
        if empty_fields:
            logger.debug(f"ะญัะฐะฟ 1: ะฟััััะต ะฟะพะปั: {', '.join(empty_fields)}")
        
        # FALLBACK: ะตัะปะธ ัะตะทัะปััะฐั ัะปะธัะบะพะผ ะฟัััะพะน, ะธัะฟะพะปัะทัะตะผ ะพะดะฝะพััะฐะฟะฝัะน ัะตะถะธะผ
        if not extracted_content or fill_percentage < 30:
            logger.warning(
                f"โ๏ธ ะญัะฐะฟ 1 ะฒะตัะฝัะป ะฝะตะดะพััะฐัะพัะฝะพ ะดะฐะฝะฝัั (ะทะฐะฟะพะปะฝะตะฝะพ {fill_percentage:.1f}%). "
                f"ะะตัะตะบะปััะฐะตะผัั ะฝะฐ ะพะดะฝะพััะฐะฟะฝัะน ัะตะถะธะผ ะณะตะฝะตัะฐัะธะธ."
            )
            logger.debug(f"extracted_data: {extracted_content}")
            logger.debug(f"extraction_notes: {extraction_notes}")
            
            # ะะพะทะฒัะฐัะฐะตะผัั ะบ ััะฐะฝะดะฐััะฝะพะผั ะฟะพะดัะพะดั
            return await manager.generate_protocol(
                provider_name, transcription, template_variables, diarization_data, **kwargs
            )
        
        # ะญะขะะ 2: ะะตัะปะตะบัะธั ะธ ัะปัััะตะฝะธะต
        logger.info("ะญัะฐะฟ 2: ะะตัะปะตะบัะธั ะธ ัะปัััะตะฝะธะต")
        reflection_prompt = _build_reflection_prompt(
            extracted_content, transcription, template_variables, diarization_analysis
        )
        
        # DEBUG ะปะพะณะธัะพะฒะฐะฝะธะต ะทะฐะฟัะพัะฐ ััะฐะฟะฐ 2
        if settings.llm_debug_log:
            logger.debug("=" * 80)
            logger.debug("[DEBUG] OpenAI REQUEST - Two-Stage Reflection (Stage 2)")
            logger.debug("=" * 80)
            logger.debug(f"Reflection prompt:\n{reflection_prompt}")
            logger.debug("=" * 80)
        
        async def _call_openai_stage2():
            return await asyncio.to_thread(
                client.chat.completions.create,
                model=selected_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": reflection_prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_schema", "json_schema": TWO_STAGE_REFLECTION_SCHEMA},
                extra_headers=extra_headers
            )
        
        try:
            response2 = await _call_openai_stage2()
        except openai.APIStatusError as e:
            # ะัะพะฒะตััะตะผ ะฝะฐ ะพัะธะฑะบั 402 - ะฝะตะดะพััะฐัะพัะฝะพ ะบัะตะดะธัะพะฒ
            if e.status_code == 402:
                error_message = e.message
                # ะััะฐะตะผัั ะธะทะฒะปะตัั ะฑะพะปะตะต ะฟะพะดัะพะฑะฝะพะต ัะพะพะฑัะตะฝะธะต ะธะท ัะตะปะฐ ะพัะฒะตัะฐ
                if hasattr(e, 'response') and e.response:
                    try:
                        error_body = e.response.json()
                        if 'error' in error_body and 'message' in error_body['error']:
                            error_message = error_body['error']['message']
                    except:
                        pass
                logger.error(f"ะะตะดะพััะฐัะพัะฝะพ ะบัะตะดะธัะพะฒ ะดะปั LLM (ััะฐะฟ 2): {error_message}")
                raise LLMInsufficientCreditsError(
                    message=error_message,
                    provider="openai",
                    model=selected_model
                )
            # ะััะณะธะต ะพัะธะฑะบะธ API ะฟัะพะฑัะฐััะฒะฐะตะผ ะดะฐะปััะต
            raise
        
        content2 = response2.choices[0].message.content
        finish_reason = response2.choices[0].finish_reason
        
        # DEBUG ะปะพะณะธัะพะฒะฐะฝะธะต ะพัะฒะตัะฐ ััะฐะฟะฐ 2
        if settings.llm_debug_log:
            logger.debug("=" * 80)
            logger.debug("[DEBUG] OpenAI RESPONSE - Two-Stage Reflection (Stage 2)")
            logger.debug("=" * 80)
            if hasattr(response2, 'usage'):
                logger.debug(f"Usage: {response2.usage}")
            logger.debug(f"Finish reason: {response2.choices[0].finish_reason}")
            logger.debug(f"Content:\n{content2}")
            logger.debug("=" * 80)
        
        # ะะพะณะธัะพะฒะฐะฝะธะต ะบะตัะธัะพะฒะฐะฝะฝัั ัะพะบะตะฝะพะฒ ะดะปั Stage 2
        if settings.log_cache_metrics:
            log_cached_tokens_usage(
                response=response2,
                context="Two-Stage: Stage 2 Reflection",
                model_name=selected_model,
                provider="openai"
            )
        
        # ะะพะณะธัะพะฒะฐะฝะธะต ะฟะพะปััะตะฝะฝะพะณะพ ะพัะฒะตัะฐ
        logger.info(f"ะญัะฐะฟ 2: ะฟะพะปััะตะฝ ะพัะฒะตั ะดะปะธะฝะพะน {len(content2) if content2 else 0} ัะธะผะฒะพะปะพะฒ, finish_reason={finish_reason}")
        
        # ะะะะะะะกะขะะะ: ะฟัะพะฒะตัะบะฐ reasoning tokens ะดะปั ััะฐะฟะฐ 2
        if hasattr(response2, 'usage') and hasattr(response2.usage, 'completion_tokens_details'):
            details = response2.usage.completion_tokens_details
            if details and hasattr(details, 'reasoning_tokens') and details.reasoning_tokens:
                reasoning_tokens = details.reasoning_tokens
                logger.debug(f"ะญัะฐะฟ 2: ะธัะฟะพะปัะทะพะฒะฐะฝะพ {reasoning_tokens} reasoning tokens")
                if reasoning_tokens > 20000:
                    logger.warning(
                        f"โ๏ธ ะญัะฐะฟ 2: ะผะพะดะตะปั ะธัะฟะพะปัะทะพะฒะฐะปะฐ {reasoning_tokens} reasoning tokens "
                        f"(> 20000). ะญัะพ ะผะพะถะตั ัะบะฐะทัะฒะฐัั ะฝะฐ ะฟัะพะฑะปะตะผั."
                    )
        
        # ะัะพะฒะตัะบะฐ ะฝะฐ ะฟัััะพะน ะพัะฒะตั
        if not content2 or not content2.strip():
            logger.warning(f"ะญัะฐะฟ 2: ะฟะพะปััะตะฝ ะฟัััะพะน ะพัะฒะตั ะพั API. ะัะฟะพะปัะทัะตะผ ัะตะทัะปััะฐั ััะฐะฟะฐ 1")
            logger.debug(f"Response details: finish_reason={finish_reason}, model={selected_model}")
            return extracted_content
        
        try:
            improved_data = json.loads(content2)
        except json.JSONDecodeError as e:
            logger.error(f"ะัะธะฑะบะฐ ะฟะฐััะธะฝะณะฐ JSON ะฝะฐ ััะฐะฟะต 2: {e}")
            logger.error(f"Content preview (ะฟะตัะฒัะต 500 ัะธะผะฒะพะปะพะฒ): {content2[:500]}")
            
            # ะะพะฟััะบะฐ ะธะทะฒะปะตัั JSON ะธะท ัะตะบััะฐ
            start_idx = content2.find('{')
            end_idx = content2.rfind('}') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_str = content2[start_idx:end_idx]
                try:
                    improved_data = json.loads(json_str)
                    logger.info("JSON ััะฟะตัะฝะพ ะธะทะฒะปะตัะตะฝ ะธะท ัะตะบััะฐ")
                except json.JSONDecodeError as e2:
                    logger.error(f"ะะต ัะดะฐะปะพัั ะธะทะฒะปะตัั JSON: {e2}. ะะพะทะฒัะฐัะฐะตะผ ัะตะทัะปััะฐั ััะฐะฟะฐ 1")
                    return extracted_content
            else:
                logger.error("JSON ะฝะต ะฝะฐะนะดะตะฝ ะฒ ะพัะฒะตัะต. ะะพะทะฒัะฐัะฐะตะผ ัะตะทัะปััะฐั ััะฐะฟะฐ 1")
                return extracted_content
        
        # ะะะะะะะฆะะฏ ัะตะทัะปััะฐัะฐ ััะฐะฟะฐ 2
        refined_data = improved_data.get('refined_data', {})
        quality_score = improved_data.get('quality_score', 0.0)
        reflection_notes = improved_data.get('reflection_notes', '')
        
        # ะะพะดััะตั ะทะฐะฟะพะปะฝะตะฝะฝัั ะฟะพะปะตะน ะฒ refined_data
        refined_filled = 0
        refined_empty = []
        for field_name in template_variables.keys():
            field_value = refined_data.get(field_name, '')
            if field_value and field_value.strip() and field_value.strip() not in ['ะะต ัะบะฐะทะฐะฝะพ', 'ะฝะต ัะบะฐะทะฐะฝะพ']:
                refined_filled += 1
            else:
                refined_empty.append(field_name)
        
        refined_percentage = (refined_filled / total_fields * 100) if total_fields > 0 else 0
        
        logger.info(
            f"ะญัะฐะฟ 2: ะทะฐะฟะพะปะฝะตะฝะพ {refined_filled}/{total_fields} ะฟะพะปะตะน ({refined_percentage:.1f}%), "
            f"quality_score={quality_score:.2f}"
        )
        
        if refined_empty:
            logger.debug(f"ะญัะฐะฟ 2: ะฟััััะต ะฟะพะปั: {', '.join(refined_empty)}")
        
        # ะัะพะฒะตััะตะผ, ััะพ refined_data ะฝะต ััะถะต ัะตะผ extracted_content
        if not refined_data or refined_percentage < fill_percentage * 0.8:
            logger.warning(
                f"โ๏ธ ะญัะฐะฟ 2 ัััะดัะธะป ัะตะทัะปััะฐั (ะฑัะปะพ {fill_percentage:.1f}%, ััะฐะปะพ {refined_percentage:.1f}%). "
                f"ะัะฟะพะปัะทัะตะผ ัะตะทัะปััะฐั ััะฐะฟะฐ 1."
            )
            logger.debug(f"reflection_notes: {reflection_notes}")
            return extracted_content
        
        logger.info(f"ะญัะฐะฟ 2 ะทะฐะฒะตััะตะฝ ััะฟะตัะฝะพ (ัะปัััะตะฝะธะต: +{refined_percentage - fill_percentage:.1f}%)")
        return refined_data
    
    else:
        # ะะปั ะดััะณะธั ะฟัะพะฒะฐะนะดะตัะพะฒ ะธัะฟะพะปัะทัะตะผ ััะฐะฝะดะฐััะฝัะน ะฟะพะดัะพะด
        logger.warning(f"ะะฒััััะฐะฟะฝะฐั ะณะตะฝะตัะฐัะธั ะฝะต ะฟะพะดะดะตัะถะธะฒะฐะตััั ะดะปั {provider_name}, ะธัะฟะพะปัะทัะตะผ ััะฐะฝะดะฐััะฝัะน ะฟะพะดัะพะด")
        return await manager.generate_protocol(
            provider_name, transcription, template_variables, diarization_data, **kwargs
        )


# ===================================================================
# UNIFIED PROTOCOL GENERATION (ะะะขะะะะะะะะะะะะซะ ะะะะฅะะ)
# ===================================================================

def _build_unified_prompt(
    transcription: Optional[str],
    structure_summary: str,
    template_variables: Dict[str, str],
    diarization_data: Optional[Dict[str, Any]] = None,
    speaker_mapping: Optional[Dict[str, str]] = None,
    meeting_topic: Optional[str] = None,
    meeting_date: Optional[str] = None,
    meeting_time: Optional[str] = None,
    participants: Optional[List[Dict[str, str]]] = None
) -> str:
    """
    ะะพัััะพะธัั ะฟัะพะผะฟั ะดะปั unified ะฟะพะดัะพะดะฐ
    """
    
    # ะะพะฝัะตะบัั ะฒัััะตัะธ
    context_parts = []
    
    if meeting_topic:
        context_parts.append(f"ะขะตะผะฐ ะฒัััะตัะธ: {meeting_topic}")
    if meeting_date:
        context_parts.append(f"ะะฐัะฐ: {meeting_date}")
    if meeting_time:
        context_parts.append(f"ะัะตะผั: {meeting_time}")
    
    context_text = "\n".join(context_parts) if context_parts else ""
    
    # ะฃัะฐััะฝะธะบะธ - ัะพัะผะฐัะธััะตะผ ะฒ "ะะผั ะคะฐะผะธะปะธั" (ะฑะตะท ะพััะตััะฒะฐ)
    participants_text = ""
    if participants:
        from src.services.participants_service import participants_service
        participants_text = "ะฃะงะะกะขะะะะ:\n" + participants_service.format_participants_for_llm(participants)
    
    # ะกัััะบัััะฐ ะฒัััะตัะธ ะธ ััะฐะฝัะบัะธะฟัะธั
    content_parts = []
    
    # ะัะตะณะดะฐ ะดะพะฑะฐะฒะปัะตะผ structure_summary, ะตัะปะธ ะพะฝ ะฝะต ะฟัััะพะน
    if structure_summary:
        content_parts.append(f"ะกะขะะฃะะขะฃะะะะะะะะะะ ะะะะะกะขะะะะะะะ ะะกะขะะะงะ:\n\n{structure_summary}")
    
    # ะัะตะณะดะฐ ะดะพะฑะฐะฒะปัะตะผ ััะฐะฝัะบัะธะฟัะธั
    if transcription:
        if diarization_data and diarization_data.get("formatted_transcript"):
            content_parts.append(f"ะขะะะะกะะะะะฆะะฏ ะก ะะะะะะะะฆะะะ:\n\n{diarization_data['formatted_transcript']}")
        else:
            content_parts.append(f"ะขะะะะกะะะะะฆะะฏ:\n\n{transcription}")
    
    content_text = "\n\n".join(content_parts)
    
    # ะะฐะฟะฟะธะฝะณ ัะฟะธะบะตัะพะฒ
    mapping_text = ""
    if speaker_mapping:
        mapping_text = "ะกะะะะกะขะะะะะะะ ะกะะะะะะะ:\n" + "\n".join([
            f"- {speaker_id} = {name}"
            for speaker_id, name in speaker_mapping.items()
        ])
    
    # ะะพะปั ัะฐะฑะปะพะฝะฐ
    fields_text = "ะะะะฏ ะะะฏ ะะะะะะะะะะฏ:\n" + "\n".join([
        f"- {field_name}: {field_description}"
        for field_name, field_description in template_variables.items()
    ])
    
    # ะคะธะฝะฐะปัะฝัะน ะฟัะพะผะฟั
    prompt = f"""ะขั โ ัะบัะฟะตัั ะฟะพ ัะพะทะดะฐะฝะธั ะฟัะพัะพะบะพะปะพะฒ ะฒัััะตั. ะขะฒะพั ะทะฐะดะฐัะฐ:

1. ะะะะะะงะฌ ะดะฐะฝะฝัะต ะธะท ะฟัะตะดััะฐะฒะปะตะฝะฝะพะน ะธะฝัะพัะผะฐัะธะธ ะพ ะฒัััะตัะต
2. ะะะะะะะะขะฌ ะฒัะต ะฟะพะปั ะฟัะพัะพะบะพะปะฐ
3. ะะะะะะะะขะฌ ัะฒะพั ัะฐะฑะพัั ะฝะฐ ะฟะพะปะฝะพัั ะธ ัะพัะฝะพััั (self-reflection)
4. ะฃะะะะะขะฌ ััะพะฒะตะฝั ัะฒะตัะตะฝะฝะพััะธ ะธ ะฒะพะทะผะพะถะฝัะต ะฟัะพะฑะปะตะผั

{context_text}

{participants_text}

{content_text}

{mapping_text}

{fields_text}

ะะะะขะะงะะกะะ ะะะะะ โ ะกะขะะฃะะขะฃะะ ะะขะะะขะ:
ะขะฒะพะน ะพัะฒะตั ะะะฏะะะขะะะฌะะ ะดะพะปะถะตะฝ ะฑััั ะฒะฐะปะธะดะฝัะผ JSON ะพะฑัะตะบัะพะผ ัะพ ัะปะตะดัััะธะผะธ ะฟะพะปัะผะธ:

1. protocol_data (ะพะฑัะตะบั): ะะทะฒะปะตัะตะฝะฝัะต ะดะฐะฝะฝัะต ะฟัะพัะพะบะพะปะฐ
   - ะะปััะธ: ะฝะฐะทะฒะฐะฝะธั ะฟะพะปะตะน ะธะท ัะฟะธัะบะฐ ะฒััะต
   - ะะฝะฐัะตะฝะธั: ะกะขะะะะ (ะธัะฟะพะปัะทัะน \\n ะดะปั ะผะฝะพะณะพัััะพัะฝัั ัะฟะธัะบะพะฒ)
   - ะะฐะถะดะพะต ะฟะพะปะต ะธะท template_variables ะะะะะะ ะฟัะธัััััะฒะพะฒะฐัั

2. self_reflection (ะพะฑัะตะบั): ะกะฐะผะพะฟัะพะฒะตัะบะฐ ะบะฐัะตััะฒะฐ ัะฐะฑะพัั
   - completeness (ัะธัะปะพ 0.0-1.0): ะฟะพะปะฝะพัะฐ ะธะทะฒะปะตัะตะฝะธั
   - missing_info (ะผะฐััะธะฒ ัััะพะบ): ััะพ ะฝะต ัะดะฐะปะพัั ะธะทะฒะปะตัั
   - ambiguous_points (ะผะฐััะธะฒ ัััะพะบ): ะฝะตะพะดะฝะพะทะฝะฐัะฝัะต ะผะพะผะตะฝัั
   - quality_concerns (ะผะฐััะธะฒ ัััะพะบ): ะฟัะพะฑะปะตะผั ะบะฐัะตััะฒะฐ ะดะฐะฝะฝัั

3. confidence_score (ัะธัะปะพ 0.0-1.0): ะพะฑัะฐั ัะฒะตัะตะฝะฝะพััั

4. quality_notes (ัััะพะบะฐ): ะบัะฐัะบะพะต ัะตะทัะผะต ะฟะพ ะบะฐัะตััะฒั ัะฐะฑะพัั

5. (ะะะฆะะะะะะฌะะ) detected_speaker_mapping (ะพะฑัะตะบั): ะะฒัะพะพะฟัะตะดะตะปะตะฝะฝะพะต ัะพะฟะพััะฐะฒะปะตะฝะธะต SPEAKER_N ั ะธะผะตะฝะฐะผะธ ััะฐััะฝะธะบะพะฒ
   - ะะปััะธ: ะธะดะตะฝัะธัะธะบะฐัะพัั ัะฟะธะบะตัะพะฒ (ะฝะฐะฟัะธะผะตั, "SPEAKER_1", "SPEAKER_2")
   - ะะฝะฐัะตะฝะธั: ะธะผะตะฝะฐ ััะฐััะฝะธะบะพะฒ ะฒ ัะพัะผะฐัะต "ะะผั ะคะฐะผะธะปะธั"
   - ะะฐะฟะพะปะฝัะน ะขะะะฌะะ ะตัะปะธ ัะดะฐะปะพัั ะฝะฐะดะตะถะฝะพ ัะพะฟะพััะฐะฒะธัั ัะฟะธะบะตัะพะฒ ั ััะฐััะฝะธะบะฐะผะธ ะธะท ััะฐะฝัะบัะธะฟัะธะธ

6. (ะะะฆะะะะะะฌะะ) speaker_confidence_scores (ะพะฑัะตะบั): ะฃะฒะตัะตะฝะฝะพััั ะฒ ัะพะฟะพััะฐะฒะปะตะฝะธะธ ะดะปั ะบะฐะถะดะพะณะพ ัะฟะธะบะตัะฐ
   - ะะปััะธ: ะธะดะตะฝัะธัะธะบะฐัะพัั ัะฟะธะบะตัะพะฒ
   - ะะฝะฐัะตะฝะธั: ัะธัะปะฐ ะพั 0.0 ะดะพ 1.0 (ัะฒะตัะตะฝะฝะพััั ะฒ ัะพะฟะพััะฐะฒะปะตะฝะธะธ)
   - ะะฐะฟะพะปะฝัะน ะขะะะฌะะ ะตัะปะธ ะทะฐะฟะพะปะฝะตะฝะพ detected_speaker_mapping

7. (ะะะฆะะะะะะฌะะ) unmapped_speakers (ะผะฐััะธะฒ ัััะพะบ): ะกะฟะธัะพะบ ะธะดะตะฝัะธัะธะบะฐัะพัะพะฒ ัะฟะธะบะตัะพะฒ, ะบะพัะพััั ะฝะต ัะดะฐะปะพัั ัะพะฟะพััะฐะฒะธัั
   - ะะฐััะธะฒ ะธะดะตะฝัะธัะธะบะฐัะพัะพะฒ ัะธะฟะฐ ["SPEAKER_3", "SPEAKER_5"]
   - ะะฐะฟะพะปะฝัะน ะขะะะฌะะ ะตัะปะธ ะตััั ัะฟะธะบะตัั, ะบะพัะพััั ะฝะต ัะดะฐะปะพัั ัะพะฟะพััะฐะฒะธัั

8. (ะะะฆะะะะะะฌะะ) mapping_notes (ัััะพะบะฐ): ะะฐะผะตัะบะธ ะฟะพ ะฟัะพัะตััั ัะพะฟะพััะฐะฒะปะตะฝะธั ัะฟะธะบะตัะพะฒ
   - ะะฐะฟะพะปะฝัะน ะขะะะฌะะ ะตัะปะธ ะตััั ะฒะฐะถะฝัะต ะทะฐะผะตัะฐะฝะธั ะฟะพ ัะพะฟะพััะฐะฒะปะตะฝะธั

๐จ ะกะขะะะะะกะขะฌ ะกะฅะะะซ:
- ะกัะตะผะฐ ัััะพะณะฐั (strict mode): ะะ ะดะพะฑะฐะฒะปัะน ะดะพะฟะพะปะฝะธัะตะปัะฝัะต ะฟะพะปั, ะฝะต ัะบะฐะทะฐะฝะฝัะต ะฒััะต
- ะะ ะธัะฟะพะปัะทัะน ะดััะณะธะต ะฝะฐะทะฒะฐะฝะธั ะฟะพะปะตะน (ะฝะฐะฟัะธะผะตั, ะฝะต "speaker_mapping", ะฐ "detected_speaker_mapping")
- ะะกะ ะฟะพะปั ะธะท template_variables ะะะะะะซ ะฟัะธัััััะฒะพะฒะฐัั ะฒ protocol_data, ะดะฐะถะต ะตัะปะธ ะทะฝะฐัะตะฝะธะต "ะะต ัะบะฐะทะฐะฝะพ"
- ะัะปะธ ะฟะพะปะต ะฝะต ะผะพะถะตั ะฑััั ะทะฐะฟะพะปะฝะตะฝะพ - ะธัะฟะพะปัะทัะน "ะะต ัะบะฐะทะฐะฝะพ", ะฝะพ ะะ ะฟัะพะฟััะบะฐะน ะฟะพะปะต

ะขะะะะะะะะะฏ ะ ะะะะะซะ:
- ะะทะฒะปะตะบะฐะน ะขะะะฌะะ ัะฐะบัะธัะตัะบัั ะธะฝัะพัะผะฐัะธั ะธะท ะฟัะตะดััะฐะฒะปะตะฝะฝะพะณะพ ะผะฐัะตัะธะฐะปะฐ
- ะัะปะธ ััััะบัััะธัะพะฒะฐะฝะฝะพะต ะฟัะตะดััะฐะฒะปะตะฝะธะต ัะพะดะตัะถะธั ัะตะผั/ัะตัะตะฝะธั/ะทะฐะดะฐัะธ, ะธัะฟะพะปัะทัะน ะธั ะฝะฐะฟััะผัั
- ะะฐะถะดะพะต ะฟะพะปะต ะฒ protocol_data ะะะฏะะะขะะะฌะะ ะดะพะปะถะฝะพ ะฑััั ัััะพะบะพะน (ะะ ะผะฐััะธะฒะพะผ, ะะ ะพะฑัะตะบัะพะผ)
- ะะปั ัะฟะธัะบะพะฒ ะธัะฟะพะปัะทัะน ะผะฝะพะณะพัััะพัะฝัะน ัะตะบัั ั ัะฐะทะดะตะปะธัะตะปะตะผ \\n
- ะัะปะธ ะธะฝัะพัะผะฐัะธะธ ะฝะตั - ะฟะธัะธ "ะะต ัะบะฐะทะฐะฝะพ", ะฝะพ ะะ ะพััะฐะฒะปัะน ะฟะพะปะต ะฟััััะผ

ะะะะะซะ ะะะะะะ ะะขะะะขะ (ะฑะฐะทะพะฒัะน ัะปััะฐะน, ะฑะตะท speaker mapping):
{{
  "protocol_data": {{
    "participants": "ะะปะตะบัะตะน ะะฒะฐะฝะพะฒ\\nะะฐัะธั ะกะธะดะพัะพะฒะฐ\\nะะตัั ะะตััะพะฒ",
    "risks_and_blockers": "- ะะตัะฒะฐัะบะฐ ัะตััััะพะฒ ะดะปั ัะตะฐะปะธะทะฐัะธะธ\\n- ะะฐะฒะธัะธะผะพััั ะพั ะฒะฝะตัะฝะธั ะฟะพััะฐะฒัะธะบะพะฒ",
    "technical_issues": "- ะัะพะฑะปะตะผั ัะพะฒะผะตััะธะผะพััะธ API\\n- ะะตะพะฑัะพะดะธะผะพััั ะพะฑะฝะพะฒะปะตะฝะธั ะธะฝััะฐััััะบัััั",
    "next_sprint_plans": "- ะะฐะฒะตััะธัั ะผะพะดัะปั ะฐะฒัะพัะธะทะฐัะธะธ\\n- ะะฐัะฐัั ะธะฝัะตะณัะฐัะธั ั ะฟะปะฐัะตะถะฝะพะน ัะธััะตะผะพะน",
    "architecture_decisions": "- ะัะฟะพะปัะทะพะฒะฐัั ะผะธะบัะพัะตัะฒะธัะฝัั ะฐััะธัะตะบัััั\\n- ะัะฑัะฐะฝ PostgreSQL ะบะฐะบ ะพัะฝะพะฒะฝะฐั ะะ",
    "technical_tasks": "- ะะฐัััะพะธัั CI/CD ะฟะฐะนะฟะปะฐะนะฝ โ ะะปะตะบัะตะน ะะฒะฐะฝะพะฒ, ะดะพ 15 ะฝะพัะฑัั\\n- ะัะพะฒะตััะธ ะบะพะด-ัะตะฒัั ะผะพะดัะปั โ ะะฐัะธั ะกะธะดะพัะพะฒะฐ, ะดะพ 18 ะฝะพัะฑัั"
  }},
  "self_reflection": {{
    "completeness": 0.88,
    "missing_info": ["ะขะพัะฝัะต ััะพะบะธ ะดะปั ะธะฝัะตะณัะฐัะธะธ ะฟะปะฐัะตะถะตะน", "ะัะดะถะตั ะฝะฐ ะธะฝััะฐััััะบัััั"],
    "ambiguous_points": ["ะะตััะฝะพ, ะฑัะดะตั ะปะธ ะธัะฟะพะปัะทะพะฒะฐัััั Redis ะธะปะธ Memcached"],
    "quality_concerns": []
  }},
  "confidence_score": 0.85,
  "quality_notes": "ะัะพัะพะบะพะป ัะพะดะตัะถะธั ะฒัะต ะพัะฝะพะฒะฝัะต ัะตัะตะฝะธั ะธ ะทะฐะดะฐัะธ. ะะต ัะฒะฐัะฐะตั ะบะพะฝะบัะตัะธะบะธ ะฟะพ ะดะฒัะผ ััะพะบะฐะผ."
}}

ะะะะะะ ะก ะะะฆะะะะะะฌะะซะะ ะะะะฏะะ SPEAKER MAPPING (ะตัะปะธ ัะดะฐะปะพัั ัะพะฟะพััะฐะฒะธัั ัะฟะธะบะตัะพะฒ):
{{
  "protocol_data": {{
    "participants": "ะะปะตะบัะตะน ะะฒะฐะฝะพะฒ\\nะะฐัะธั ะกะธะดะพัะพะฒะฐ\\nะะตัั ะะตััะพะฒ",
    "decisions": "- ะะตัะตะฝะธะต 1\\n- ะะตัะตะฝะธะต 2"
  }},
  "self_reflection": {{
    "completeness": 0.9,
    "missing_info": [],
    "ambiguous_points": [],
    "quality_concerns": []
  }},
  "confidence_score": 0.9,
  "quality_notes": "ะัะต ะดะฐะฝะฝัะต ะธะทะฒะปะตัะตะฝั ััะฟะตัะฝะพ",
  "detected_speaker_mapping": {{
    "SPEAKER_1": "ะะปะตะบัะตะน ะะฒะฐะฝะพะฒ",
    "SPEAKER_2": "ะะฐัะธั ะกะธะดะพัะพะฒะฐ",
    "SPEAKER_3": "ะะตัั ะะตััะพะฒ"
  }},
  "speaker_confidence_scores": {{
    "SPEAKER_1": 0.95,
    "SPEAKER_2": 0.92,
    "SPEAKER_3": 0.88
  }},
  "unmapped_speakers": [],
  "mapping_notes": "ะัะต ัะฟะธะบะตัั ััะฟะตัะฝะพ ัะพะฟะพััะฐะฒะปะตะฝั ั ััะฐััะฝะธะบะฐะผะธ ะฟะพ ะธะผะตะฝะฐะผ ะธะท ััะฐะฝัะบัะธะฟัะธะธ"
}}

ะะะะะ: 
- ะัะฒะตะดะธ ะขะะะฌะะ ะฒะฐะปะธะดะฝัะน JSON ะฑะตะท ะดะพะฟะพะปะฝะธัะตะปัะฝัั ะบะพะผะผะตะฝัะฐัะธะตะฒ ะธะปะธ ัะตะบััะฐ
- ะะกะ ะฟะพะปั ะธะท template_variables ะดะพะปะถะฝั ะฟัะธัััััะฒะพะฒะฐัั ะฒ protocol_data
- ะะฟัะธะพะฝะฐะปัะฝัะต ะฟะพะปั speaker mapping ะดะพะฑะฐะฒะปัะน ะขะะะฌะะ ะตัะปะธ ัะดะฐะปะพัั ัะพะฟะพััะฐะฒะธัั ัะฟะธะบะตัะพะฒ"""
    
    return prompt


# ===================================================================
# OD PROTOCOL GENERATION (ะะะะขะะะะ ะะะะฃะงะะะะ ะะฃะะะะะะะขะะะะ)
# ===================================================================

def _build_od_system_prompt() -> str:
    """
    ะกะธััะตะผะฝัะน ะฟัะพะผะฟั ะดะปั ัะตะถะธะผะฐ OD ะฟัะพัะพะบะพะปะฐ (ะฟัะพัะพะบะพะป ะฟะพัััะตะฝะธะน ััะบะพะฒะพะดะธัะตะปะตะน)
    """
    return """ะขั โ ัะบัะฟะตัั ะฟะพ ะดะพะบัะผะตะฝัะธัะพะฒะฐะฝะธั ะฟะพัััะตะฝะธะน ะธ ะทะฐะดะฐั ะพั ััะบะพะฒะพะดะธัะตะปะตะน ะฝะฐ ัะพะฒะตัะฐะฝะธัั.

ะขะะะฏ ะะะะะงะ:
ะะท ััะฐะฝัะบัะธะฟัะธะธ ะฒัััะตัะธ ะธะทะฒะปะตัั ััััะบัััะธัะพะฒะฐะฝะฝัะน ะฟัะพัะพะบะพะป ะฟะพัััะตะฝะธะน ะพั ััะบะพะฒะพะดะธัะตะปะตะน.

ะะะะะฆะะะซ ะะะะะขะซ:
1. ะคะะะฃะก ะะ ะะฃะะะะะะะขะะะฏะฅ: ะขะฒะพั ะณะปะฐะฒะฝะฐั ัะตะปั โ ะทะฐัะธะบัะธัะพะฒะฐัั ะฒะพะปั ััะบะพะฒะพะดะธัะตะปะตะน (ะพะฝะธ ัะบะฐะทะฐะฝั ะฒ ัะฟะธัะบะต ััะฐััะฝะธะบะพะฒ).
2. ะะะะขะะะกะข ะะะะฃะงะะะะฏ: ะคะธะบัะธััะน ะฝะต ัะพะปัะบะพ ะฟััะผัะต ะฟัะธะบะฐะทั ("ะกะดะตะปะฐะน X"), ะฝะพ ะธ:
   - ะฃัะฒะตัะถะดะตะฝะฝัะต ะฟัะตะดะปะพะถะตะฝะธั ("ะะฐะฒะฐะนัะต ัะฐะบ ะธ ัะดะตะปะฐะตะผ")
   - ะกะพะณะปะฐัะพะฒะฐะฝะฝัะต ะฟะปะฐะฝั ะดะตะนััะฒะธะน ("ะฅะพัะพัะพ, ัะพะณะดะฐ ะฝะฐ ัะตะฑะต X")
   - ะะตะทะพะปััะธะธ ะฟะพ ะพะฑััะถะดะฐะตะผัะผ ะฒะพะฟัะพัะฐะผ
3. ะกะขะะฃะะขะฃะะ ะะ ะะะะะงะะ: ะััะฟะฟะธััะน ะธะฝัะพัะผะฐัะธั ะฟะพ ะพะฑััะถะดะฐะตะผัะผ ะทะฐะดะฐัะฐะผ/ะฟัะพะตะบัะฐะผ.
4. ะขะะงะะะกะขะฌ: ะคะธะบัะธััะน ะขะะะฌะะ ัะพ, ััะพ ัะฒะฝะพ ะฟัะพะทะฒััะฐะปะพ ะธะปะธ ะฑัะปะพ ััะฒะตัะถะดะตะฝะพ. ะะต ะดะพะดัะผัะฒะฐะน.

ะงะขะ ะะะะะะะะขะฌ:
- ะะฐะทะฒะฐะฝะธะต ะทะฐะดะฐัะธ/ะฟัะพะตะบัะฐ (ะบะฐะบ ะตะณะพ ะฝะฐะทัะฒะฐะตั ะฒะตะดััะธะน ะธะปะธ ััะฐััะฝะธะบะธ ะฒัััะตัะธ)
- ะะพัััะตะฝะธั ะพั ะบะฐะถะดะพะณะพ ััะบะพะฒะพะดะธัะตะปั ะฟะพ ััะพะน ะทะฐะดะฐัะต
- ะัะฒะตัััะฒะตะฝะฝัั ะธัะฟะพะปะฝะธัะตะปะตะน (ะตัะปะธ ะฝะฐะทะฒะฐะฝั)
- ะกัะพะบะธ ะฒัะฟะพะปะฝะตะฝะธั (ะตัะปะธ ัะบะฐะทะฐะฝั)

ะคะะะะะข ะะะะฃะงะะะะฏ:
- ะัะพ ะดะฐะป ะฟะพัััะตะฝะธะต (ะธะผั ััะบะพะฒะพะดะธัะตะปั)
- ะกััั ะฟะพัััะตะฝะธั (ััะพ ะฝัะถะฝะพ ัะดะตะปะฐัั, ะผะฐะบัะธะผะฐะปัะฝะพ ะบะพะฝะบัะตัะฝะพ, ั ะณะปะฐะณะพะปะพะผ ะดะตะนััะฒะธั)
- ะัะพ ะพัะฒะตัััะฒะตะฝะฝัะน ะทะฐ ะฒัะฟะพะปะฝะตะฝะธะต
- ะะพะณะดะฐ ะดะพะปะถะฝะพ ะฑััั ะฒัะฟะพะปะฝะตะฝะพ

ะะะะะ:
- ะัะปะธ ััะบะพะฒะพะดะธัะตะปะตะน ะฝะตัะบะพะปัะบะพ, ัะธะบัะธััะน ะฟะพัััะตะฝะธั ะพั ะบะฐะถะดะพะณะพ.
- ะัะปะธ ะฟะพัััะตะฝะธะต ะฑะตะท ััะพะบะฐ - ะพััะฐะฒะปัะน ะฟะพะปะต ะฟััััะผ.
- ะัะปะธ ะพัะฒะตัััะฒะตะฝะฝัะน ะฝะต ะฝะฐะทะฒะฐะฝ - ะพััะฐะฒะปัะน ะฟะพะปะต ะฟััััะผ.
- ะัะฟะพะปัะทัะน ัะพัะฝัะต ัะพัะผัะปะธัะพะฒะบะธ ะธะท ััะฐะฝัะบัะธะฟัะธะธ, ะฝะพ ะฟัะธะฒะพะดะธ ะธั ะบ ะธะผะฟะตัะฐัะธะฒะฝะพะผั ะฒะธะดั (ะฝะฐะฟัะธะผะตั, "ะัะถะฝะพ ัะดะตะปะฐัั ะพััะตั" -> "ะะพะดะณะพัะพะฒะธัั ะพััะตั")."""


def _build_od_user_prompt(
    transcription: str,
    diarization_data: Optional[Dict[str, Any]],
    participants: Optional[List[Dict[str, str]]],
    speaker_mapping: Optional[Dict[str, str]],
    meeting_date: Optional[str] = None,
    meeting_topic: Optional[str] = None
) -> str:
    """
    ะะพะปัะทะพะฒะฐัะตะปััะบะธะน ะฟัะพะผะฟั ะดะปั OD ะฟัะพัะพะบะพะปะฐ
    """
    # ะะทะฒะปะตะบะฐะตะผ ััะบะพะฒะพะดะธัะตะปะตะน ะธะท ัะฟะธัะบะฐ ััะฐััะฝะธะบะพะฒ
    managers = []
    if participants:
        for p in participants:
            role = p.get('role', '').lower()
            if any(keyword in role for keyword in ['ััะบะพะฒะพะดะธัะตะปั', 'ะดะธัะตะบัะพั', 'ะณะปะฐะฒะฐ', 'ะฝะฐัะฐะปัะฝะธะบ', 'ceo', 'cto', 'cfo']):
                managers.append(p['name'])
    
    # ะคะพัะผะธััะตะผ ะฑะปะพะบ ั ััะฐะฝัะบัะธะฟัะธะตะน
    if diarization_data and diarization_data.get("formatted_transcript"):
        transcription_text = (
            "ะขะะะะกะะะะะฆะะฏ ะะกะขะะะงะ ะก ะะะะะะะะะะะ ะะะะะะฏะฉะะฅ:\n\n"
            f"{diarization_data['formatted_transcript']}\n\n"
        )
    else:
        transcription_text = (
            "ะขะะะะกะะะะะฆะะฏ ะะกะขะะะงะ:\n\n"
            f"{transcription}\n\n"
        )
    
    # ะะฝัะพัะผะฐัะธั ะพะฑ ััะฐััะฝะธะบะฐั ะธ ััะบะพะฒะพะดะธัะตะปัั
    participants_info = ""
    if participants:
        participants_info = "ะฃะงะะกะขะะะะ ะะกะขะะะงะ:\n"
        for p in participants:
            role_text = f" โ {p['role']}" if p.get('role') else ""
            participants_info += f"- {p['name']}{role_text}\n"
        participants_info += "\n"
    
    if managers:
        participants_info += "ะะฃะะะะะะะขะะะ (ัะพะบัั ะฒะฝะธะผะฐะฝะธั):\n"
        for manager in managers:
            participants_info += f"- {manager}\n"
        participants_info += "\n"
    
    # ะกะพะฟะพััะฐะฒะปะตะฝะธะต ัะฟะธะบะตัะพะฒ
    mapping_info = ""
    if speaker_mapping:
        mapping_info = "ะกะะะะกะขะะะะะะะ ะกะะะะะะะ:\n"
        for speaker_id, name in speaker_mapping.items():
            mapping_info += f"- {speaker_id} = {name}\n"
        mapping_info += "\n"
    
    # ะะพะฟะพะปะฝะธัะตะปัะฝะฐั ะธะฝัะพัะผะฐัะธั
    meta_info = ""
    if meeting_date:
        meta_info += f"ะะฐัะฐ ะฒัััะตัะธ: {meeting_date}\n"
    if meeting_topic:
        meta_info += f"ะขะตะผะฐ ะฒัััะตัะธ: {meeting_topic}\n"
    if meta_info:
        meta_info += "\n"
    
    prompt = f"""{transcription_text}

{participants_info}{mapping_info}{meta_info}

ะะะะะะะ:
ะัะพะฐะฝะฐะปะธะทะธััะน ััะฐะฝัะบัะธะฟัะธั ะธ ะธะทะฒะปะตะบะธ ััััะบัััะธัะพะฒะฐะฝะฝัะน ะฟัะพัะพะบะพะป ะฟะพัััะตะฝะธะน.

ะกะขะะฃะะขะฃะะ ะะขะะะขะ:
ะะปั ะบะฐะถะดะพะน ะพะฑััะถะดะฐะตะผะพะน ะทะฐะดะฐัะธ/ะฟัะพะตะบัะฐ ะฒัะดะตะปะธ:
1. ะะฐะทะฒะฐะฝะธะต ะทะฐะดะฐัะธ (ะบะฐะบ ะฝะฐะทัะฒะฐัั ััะฐััะฝะธะบะธ)
2. ะัะต ะฟะพัััะตะฝะธั ะพั ััะบะพะฒะพะดะธัะตะปะตะน ะฟะพ ััะพะน ะทะฐะดะฐัะต

ะะปั ะบะฐะถะดะพะณะพ ะฟะพัััะตะฝะธั ัะบะฐะถะธ:
- manager_name: ะธะผั ััะบะพะฒะพะดะธัะตะปั, ะดะฐะฒัะตะณะพ ะธะปะธ ััะฒะตัะดะธะฒัะตะณะพ ะฟะพัััะตะฝะธะต
- instruction: ัััั ะฟะพัััะตะฝะธั (ััะพ ะฝัะถะฝะพ ัะดะตะปะฐัั, ะบะพะฝะบัะตัะฝะพะต ะดะตะนััะฒะธะต)
- responsible: ะพัะฒะตัััะฒะตะฝะฝัะน ะธัะฟะพะปะฝะธัะตะปั (ะตัะปะธ ัะบะฐะทะฐะฝ)
- deadline: ััะพะบ ะฒัะฟะพะปะฝะตะฝะธั (ะตัะปะธ ัะบะฐะทะฐะฝ)

ะะะกะขะะฃะะฆะะ:
1. ะะฝะธะผะฐัะตะปัะฝะพ ัะธัะฐะน ะฒััะบะฐะทัะฒะฐะฝะธั ััะบะพะฒะพะดะธัะตะปะตะน (ัะฟะธัะพะบ ะฒััะต).
2. ะขะฐะบะถะต ะพะฑัะฐัะฐะน ะฒะฝะธะผะฐะฝะธะต ะฝะฐ ะผะพะผะตะฝัั, ะณะดะต ััะบะพะฒะพะดะธัะตะปั ัะพะณะปะฐัะฐะตััั ั ะฟัะตะดะปะพะถะตะฝะธะตะผ ("ะะฐ, ะดะฐะฒะฐะนัะต ัะฐะบ", "ะะบ, ะดะตะปะฐะน"). ะ ััะพะผ ัะปััะฐะต ะฐะฒัะพัะพะผ ะฟะพัััะตะฝะธั ััะธัะฐะตััั ััะบะพะฒะพะดะธัะตะปั.
3. ะััะฟะฟะธััะน ะฟะพัััะตะฝะธั ะฟะพ ะทะฐะดะฐัะฐะผ/ะฟัะพะตะบัะฐะผ.
4. ะกะพััะฐะฝัะน ัะพัะฝัะต ัะพัะผัะปะธัะพะฒะบะธ, ะฝะพ ะดะตะปะฐะน ะธั ะฟะพะฝััะฝัะผะธ ะธ ะดะตะนััะฒะตะฝะฝัะผะธ.
5. ะัะปะธ ะธะฝัะพัะผะฐัะธะธ ะฝะตั (ะพัะฒะตัััะฒะตะฝะฝัะน, ััะพะบ) - ะพััะฐะฒะปัะน ะฟะพะปะต ะฟััััะผ.
6. ะัะฟะพะปัะทัะน ะธะผะตะฝะฐ ััะฐััะฝะธะบะพะฒ ะฒ ัะพัะผะฐัะต "ะะผั ะคะฐะผะธะปะธั".

ะกะพะทะดะฐะน ััััะบัััะธัะพะฒะฐะฝะฝัะน JSON ัะพะณะปะฐัะฝะพ ััะตะผะต ODProtocolSchema."""
    
    return prompt


def format_od_protocol(protocol_data: Dict[str, Any]) -> str:
    """
    ะคะพัะผะฐัะธััะตั OD ะฟัะพัะพะบะพะป ะฒ ัะธัะฐะตะผัะน ัะตะบัั
    
    Args:
        protocol_data: ะะฐะฝะฝัะต ะฟัะพัะพะบะพะปะฐ ะธะท ODProtocolSchema
        
    Returns:
        ะััะพัะผะฐัะธัะพะฒะฐะฝะฝัะน ัะตะบัั ะฟัะพัะพะบะพะปะฐ
    """
    result = []
    
    # ะะฐะณะพะปะพะฒะพะบ
    result.append("ะะะะขะะะะ ะะะะฃะงะะะะ\n")
    result.append("=" * 60 + "\n")
    
    # ะะตัะฐะดะฐะฝะฝัะต
    if protocol_data.get('meeting_date'):
        result.append(f"ะะฐัะฐ ะฒัััะตัะธ: {protocol_data['meeting_date']}\n")
    
    if protocol_data.get('managers'):
        result.append(f"ะัะบะพะฒะพะดะธัะตะปะธ: {protocol_data['managers']}\n")
    
    if protocol_data.get('participants'):
        result.append(f"ะฃัะฐััะฝะธะบะธ: {protocol_data['participants']}\n")
    
    result.append("\n" + "=" * 60 + "\n\n")
    
    # ะะฐะดะฐัะธ ะธ ะฟะพัััะตะฝะธั
    tasks = protocol_data.get('tasks', [])
    
    for i, task in enumerate(tasks, 1):
        task_name = task.get('task_name', 'ะะตะท ะฝะฐะทะฒะฐะฝะธั')
        result.append(f"{i}. {task_name}\n")
        
        assignments = task.get('assignments', [])
        if assignments:
            for assignment in assignments:
                instruction = assignment.get('instruction', '')
                manager = assignment.get('manager_name', '')
                responsible = assignment.get('responsible', '')
                deadline = assignment.get('deadline', '')
                
                # ะคะพัะผะฐัะธััะตะผ ะฟะพัััะตะฝะธะต
                result.append(f"   {instruction}")
                
                # ะะพะฑะฐะฒะปัะตะผ ััะบะพะฒะพะดะธัะตะปั ะตัะปะธ ะตััั
                if manager:
                    result.append(f" (ะพั {manager})")
                
                result.append(".\n")
                
                # ะะพะฑะฐะฒะปัะตะผ ะพัะฒะตัััะฒะตะฝะฝะพะณะพ ะธ ััะพะบ
                details = []
                if responsible:
                    details.append(f"ะัะฒ. {responsible}")
                if deadline:
                    details.append(f"ะกัะพะบ โ {deadline}")
                
                if details:
                    result.append(f"   {'. '.join(details)}.\n")
                
                result.append("\n")
        else:
            result.append("   (ะะพัััะตะฝะธะน ะฝะต ะทะฐัะธะบัะธัะพะฒะฐะฝะพ)\n\n")
    
    # ะะพะฟะพะปะฝะธัะตะปัะฝัะต ะทะฐะผะตัะบะธ
    if protocol_data.get('additional_notes'):
        result.append("\n" + "=" * 60 + "\n")
        result.append("ะะะะะะะะขะะะฌะะซะ ะะะะะขะะ:\n")
        result.append(protocol_data['additional_notes'] + "\n")
    
    return "".join(result)


async def generate_protocol_od(
    manager: 'LLMManager',
    provider_name: str,
    transcription: str,
    diarization_data: Optional[Dict[str, Any]] = None,
    participants: Optional[List[Dict[str, str]]] = None,
    speaker_mapping: Optional[Dict[str, str]] = None,
    meeting_date: Optional[str] = None,
    meeting_topic: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """
    ะะตะฝะตัะฐัะธั OD ะฟัะพัะพะบะพะปะฐ (ะฟัะพัะพะบะพะป ะฟะพัััะตะฝะธะน ััะบะพะฒะพะดะธัะตะปะตะน)
    
    Args:
        manager: ะะตะฝะตะดะถะตั LLM
        provider_name: ะะฐะทะฒะฐะฝะธะต ะฟัะพะฒะฐะนะดะตัะฐ (ะดะพะปะถะตะฝ ะฑััั 'openai' ะดะปั structured outputs)
        transcription: ะขะตะบัั ััะฐะฝัะบัะธะฟัะธะธ
        diarization_data: ะะฐะฝะฝัะต ะดะธะฐัะธะทะฐัะธะธ
        participants: ะกะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ ั ัะพะปัะผะธ
        speaker_mapping: ะกะพะฟะพััะฐะฒะปะตะฝะธะต ัะฟะธะบะตัะพะฒ ั ััะฐััะฝะธะบะฐะผะธ
        meeting_date: ะะฐัะฐ ะฒัััะตัะธ
        meeting_topic: ะขะตะผะฐ ะฒัััะตัะธ
        **kwargs: ะะพะฟะพะปะฝะธัะตะปัะฝัะต ะฟะฐัะฐะผะตััั (openai_model_key ะธ ะดั.)
        
    Returns:
        ะกะปะพะฒะฐัั ั OD ะฟัะพัะพะบะพะปะพะผ
    """
    from src.models.llm_schemas import OD_PROTOCOL_SCHEMA
    
    logger.info("ะะฐัะฐะปะพ ะณะตะฝะตัะฐัะธะธ OD ะฟัะพัะพะบะพะปะฐ")
    
    # OD ะฟัะพัะพะบะพะป ัะฐะฑะพัะฐะตั ัะพะปัะบะพ ั OpenAI (structured outputs)
    if provider_name != 'openai':
        raise ValueError(f"OD ะฟัะพัะพะบะพะป ะฟะพะดะดะตัะถะธะฒะฐะตััั ัะพะปัะบะพ ะดะปั OpenAI. ะขะตะบััะธะน ะฟัะพะฒะฐะนะดะตั: {provider_name}")
    
    # ะกััะพะธะผ ะฟัะพะผะฟัั
    system_prompt = _build_od_system_prompt()
    user_prompt = _build_od_user_prompt(
        transcription=transcription,
        diarization_data=diarization_data,
        participants=participants,
        speaker_mapping=speaker_mapping,
        meeting_date=meeting_date,
        meeting_topic=meeting_topic
    )
    
    # ะัะฑะธัะฐะตะผ ะผะพะดะตะปั
    openai_model_key = kwargs.get("openai_model_key")
    selected_model = settings.openai_model
    
    if openai_model_key:
        try:
            preset = next((p for p in settings.openai_models if p.key == openai_model_key), None)
            if preset:
                selected_model = preset.model
        except Exception as e:
            logger.warning(f"ะัะธะฑะบะฐ ะฟัะธ ะฒัะฑะพัะต ะผะพะดะตะปะธ ะฟะพ ะบะปััั: {e}")
    
    logger.info(f"ะะตะฝะตัะฐัะธั OD ะฟัะพัะพะบะพะปะฐ ั ะผะพะดะตะปัั {selected_model}")
    
    # ะะพะปััะฐะตะผ ะฟัะพะฒะฐะนะดะตัะฐ
    provider = manager.providers.get(provider_name)
    if not provider:
        raise ValueError(f"ะัะพะฒะฐะนะดะตั {provider_name} ะฝะต ะฝะฐะนะดะตะฝ")
    
    # ะะตะปะฐะตะผ ะทะฐะฟัะพั ะบ OpenAI
    try:
        # ะคะพัะผะธััะตะผ extra_headers ะดะปั ะฐััะธะฑััะธะธ
        extra_headers = {}
        if settings.http_referer:
            extra_headers["HTTP-Referer"] = settings.http_referer
        if settings.x_title:
            extra_headers["X-Title"] = settings.x_title

        # ะะพะณะธัะพะฒะฐะฝะธะต ะธะฝัะพัะผะฐัะธะธ ะพ ะทะฐะฟัะพัะต
        user_len = len(user_prompt)
        transcript_len = len(transcription)
        participants_count = len(participants) if participants else 0
        logger.info(
            f"OD ะฟัะพัะพะบะพะป ะทะฐะฟัะพั: model={selected_model}, "
            f"participants={participants_count}, transcription_chars={transcript_len}, prompt_chars={user_len}"
        )

        # DEBUG ะปะพะณะธัะพะฒะฐะฝะธะต ะทะฐะฟัะพัะฐ
        if settings.llm_debug_log:
            logger.debug("=" * 80)
            logger.debug("[DEBUG] OpenAI REQUEST - generate_protocol_od")
            logger.debug("=" * 80)
            logger.debug(f"Model: {selected_model}")
            logger.debug(f"Base URL: {settings.openai_base_url}")
            logger.debug(f"Temperature: 0.1")
            logger.debug(f"Response format: JSON Schema (OD_PROTOCOL)")
            logger.debug(f"Extra headers: {extra_headers}")
            logger.debug("-" * 80)
            logger.debug(f"System prompt:\n{system_prompt}")
            logger.debug("-" * 80)
            logger.debug(f"User prompt:\n{user_prompt}")
            logger.debug("=" * 80)

        logger.info(f"ะัะฟัะฐะฒะปัะตะผ OD ะฟัะพัะพะบะพะป ะทะฐะฟัะพั ะฒ OpenAI ั ะผะพะดะตะปัั {selected_model}")

        client = openai.OpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url or None
        )

        # ะัะฟะพะปะฝัะตะผ ัะธะฝััะพะฝะฝัะน ะฒัะทะพะฒ ะบะปะธะตะฝัะฐ ะฒ ะพัะดะตะปัะฝะพะผ ะฟะพัะพะบะต, ััะพะฑั ะฝะต ะฑะปะพะบะธัะพะฒะฐัั event loop
        async def _call_openai():
            return await asyncio.to_thread(
                client.chat.completions.create,
                model=selected_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={
                    "type": "json_schema",
                    "json_schema": OD_PROTOCOL_SCHEMA
                },
                temperature=0.1,
                extra_headers=extra_headers
            )

        response = await _call_openai()

        logger.info("ะะพะปััะตะฝ ะพัะฒะตั ะพั OpenAI API ะดะปั OD ะฟัะพัะพะบะพะปะฐ")

        # DEBUG ะปะพะณะธัะพะฒะฐะฝะธะต ะพัะฒะตัะฐ
        if settings.llm_debug_log:
            logger.debug("=" * 80)
            logger.debug("[DEBUG] OpenAI RESPONSE - generate_protocol_od")
            logger.debug("=" * 80)
            if hasattr(response, 'usage'):
                logger.debug(f"Token usage: {response.usage}")
            logger.debug("-" * 80)
            logger.debug(f"Response content:\n{response.choices[0].message.content}")
            logger.debug("=" * 80)
        
        # ะะฐััะธะผ ัะตะทัะปััะฐั
        import json
        result_text = response.choices[0].message.content
        protocol_data = json.loads(result_text)
        
        logger.info(f"OD ะฟัะพัะพะบะพะป ััะฟะตัะฝะพ ัะณะตะฝะตัะธัะพะฒะฐะฝ. ะะฐะดะฐั: {len(protocol_data.get('tasks', []))}")
        
        # ะคะพัะผะฐัะธััะตะผ ะฒ ัะตะบัั
        formatted_text = format_od_protocol(protocol_data)
        
        # ะะพะทะฒัะฐัะฐะตะผ ะฒ ัะพัะผะฐัะต, ัะพะฒะผะตััะธะผะพะผ ั ะพััะฐะปัะฝะพะน ัะธััะตะผะพะน
        return {
            'protocol_text': formatted_text,
            'raw_data': protocol_data,
            'mode': 'od_protokol'
        }
        
    except Exception as e:
        logger.error(f"ะัะธะฑะบะฐ ะฟัะธ ะณะตะฝะตัะฐัะธะธ OD ะฟัะพัะพะบะพะปะฐ: {e}")
        raise


async def generate_protocol_unified(
    manager: 'LLMManager',
    provider_name: str,
    transcription: str,
    template_variables: Dict[str, str],
    diarization_data: Optional[Dict[str, Any]] = None,
    diarization_analysis: Optional[Dict[str, Any]] = None,
    **kwargs
) -> Dict[str, Any]:
    """
    Unified ะณะตะฝะตัะฐัะธั ะฟัะพัะพะบะพะปะฐ: ะธะทะฒะปะตัะตะฝะธะต + self-reflection ะฒ ะพะดะฝะพะผ ะทะฐะฟัะพัะต
    
    ะัะตะธะผััะตััะฒะฐ:
    - ะะดะธะฝ ะทะฐะฟัะพั ะฒะผะตััะพ ะดะฒัั (Stage 1 + Stage 2)
    - ะะพะดะตะปั ะดะตะปะฐะตั self-reflection ะฒ ัะฐะผะบะฐั ะพะดะฝะพะณะพ ะบะพะฝัะตะบััะฐ
    - ะกะฝะธะถะตะฝะธะต ะปะฐัะตะฝัะฝะพััะธ ะธ ััะพะธะผะพััะธ
    
    Args:
        manager: ะะตะฝะตะดะถะตั LLM
        provider_name: ะะฐะทะฒะฐะฝะธะต ะฟัะพะฒะฐะนะดะตัะฐ
        transcription: ะขะตะบัั ััะฐะฝัะบัะธะฟัะธะธ
        template_variables: ะะตัะตะผะตะฝะฝัะต ัะฐะฑะปะพะฝะฐ
        diarization_data: ะะฐะฝะฝัะต ะดะธะฐัะธะทะฐัะธะธ
        diarization_analysis: ะะฝะฐะปะธะท ะดะธะฐัะธะทะฐัะธะธ
        **kwargs: ะะพะฟะพะปะฝะธัะตะปัะฝัะต ะฟะฐัะฐะผะตััั
        
    Returns:
        ะัะพัะพะบะพะป
    """
    from src.utils.context_extraction import build_structure_summary
    from src.models.llm_schemas import UNIFIED_PROTOCOL_SCHEMA
    
    logger.info("ะะฐัะฐะปะพ unified ะณะตะฝะตัะฐัะธะธ ะฟัะพัะพะบะพะปะฐ")
    
    # ะะทะฒะปะตะบะฐะตะผ ะฟะฐัะฐะผะตััั
    speaker_mapping = kwargs.get('speaker_mapping')
    meeting_topic = kwargs.get('meeting_topic')
    meeting_date = kwargs.get('meeting_date')
    meeting_time = kwargs.get('meeting_time')
    participants = kwargs.get('participants')
    
    # ะกะพะทะดะฐะตะผ ััััะบัััะธัะพะฒะฐะฝะฝะพะต ะฟัะตะดััะฐะฒะปะตะฝะธะต ะฒัััะตัะธ (ะตัะปะธ ะดะพัััะฟะฝะพ)
    structure_summary = ""

    
    # ะกััะพะธะผ ะฟัะพะผะฟั
    prompt = _build_unified_prompt(
        transcription=transcription,
        structure_summary=structure_summary,
        template_variables=template_variables,
        diarization_data=diarization_data,
        speaker_mapping=speaker_mapping,
        meeting_topic=meeting_topic,
        meeting_date=meeting_date,
        meeting_time=meeting_time,
        participants=participants
    )
    
    # System prompt: ะฟะตัะตะดะฐะตะผ ััะฐะฝัะบัะธะฟัะธั ัะพะปัะบะพ ะตัะปะธ ะฝะต ะธัะฟะพะปัะทัะตััั structure_summary
    # unified_mode=True ะดะปั ะธัะฟะพะปัะทะพะฒะฐะฝะธั ะฟัะฐะฒะธะปัะฝะพะณะพ ัะพัะผะฐัะฐ UnifiedProtocolSchema
    system_prompt = _build_system_prompt(
        transcription if not structure_summary else None,
        diarization_analysis,
        unified_mode=True
    )
    
    # ะัะทะพะฒ OpenAI
    if provider_name == "openai":
        provider = manager.providers[provider_name]
        openai_model_key = kwargs.get("openai_model_key")
        
        selected_model = settings.openai_model
        selected_base_url = settings.openai_base_url or "https://api.openai.com/v1"
        
        if openai_model_key:
            try:
                preset = next((p for p in settings.openai_models if p.key == openai_model_key), None)
                if preset:
                    selected_model = preset.model
                    if getattr(preset, 'base_url', None):
                        selected_base_url = preset.base_url
            except Exception:
                pass
        
        client = provider.client
        if client is None or (selected_base_url and getattr(client, 'base_url', None) != selected_base_url):
            import openai
            client = openai.OpenAI(
                api_key=settings.openai_api_key,
                base_url=selected_base_url,
                http_client=provider.http_client
            )
        
        extra_headers = {}
        if settings.http_referer:
            extra_headers["HTTP-Referer"] = settings.http_referer
        if settings.x_title:
            extra_headers["X-Title"] = settings.x_title
        
        if settings.llm_debug_log:
            logger.debug("=" * 80)
            logger.debug("[DEBUG] OpenAI REQUEST - Unified Protocol Generation")
            logger.debug("=" * 80)
            logger.debug(f"Model: {selected_model}")
            logger.debug(f"System prompt:\n{system_prompt}")
            logger.debug("-" * 80)
            logger.debug(f"User prompt:\n{prompt}")
            logger.debug("=" * 80)
        
        # ะัะทะพะฒ ั prompt caching (ะตัะปะธ ะฒะบะปััะตะฝะพ)
        if settings.enable_prompt_caching and transcription:
            from src.utils.context_extraction import add_prompt_caching_markers
            messages = add_prompt_caching_markers(system_prompt, transcription, prompt)
        else:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ]
        
        async def _call_openai():
            import asyncio
            import openai
            return await asyncio.to_thread(
                client.chat.completions.create,
                model=selected_model,
                messages=messages,
                temperature=0.1,
                response_format={"type": "json_schema", "json_schema": UNIFIED_PROTOCOL_SCHEMA},
                extra_headers=extra_headers
            )
        
        try:
            response = await _call_openai()
        except openai.APIStatusError as e:
            if e.status_code == 402:
                error_message = e.message
                if hasattr(e, 'response') and e.response:
                    try:
                        error_body = e.response.json()
                        if 'error' in error_body and 'message' in error_body['error']:
                            error_message = error_body['error']['message']
                    except:
                        pass
                logger.error(f"ะะตะดะพััะฐัะพัะฝะพ ะบัะตะดะธัะพะฒ ะดะปั LLM: {error_message}")
                raise LLMInsufficientCreditsError(
                    message=error_message,
                    provider="openai",
                    model=selected_model
                )
            raise
        
        content = response.choices[0].message.content
        
        if settings.llm_debug_log:
            logger.debug("=" * 80)
            logger.debug("[DEBUG] OpenAI RESPONSE - Unified Protocol Generation")
            logger.debug("=" * 80)
            if hasattr(response, 'usage'):
                logger.debug(f"Usage: {response.usage}")
            logger.debug(f"Content:\n{content}")
            logger.debug("=" * 80)
        
        # ะะพะณะธัะพะฒะฐะฝะธะต ะบะตัะธัะพะฒะฐะฝะฝัั ัะพะบะตะฝะพะฒ ะดะปั Unified Generation
        if settings.log_cache_metrics:
            log_cached_tokens_usage(
                response=response,
                context="Unified Protocol Generation",
                model_name=selected_model,
                provider="openai"
            )
        
        # ะะตะทะพะฟะฐัะฝัะน ะฟะฐััะธะฝะณ JSON ั ะพะฑัะฐะฑะพัะบะพะน ะพัะธะฑะพะบ
        try:
            result = safe_json_parse(content, context="Unified Protocol Generation")
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"โ ะัะธะฑะบะฐ ะฟะฐััะธะฝะณะฐ JSON ะฒ unified generation: {e}")
            logger.error(f"ะัะฒะตั ะผะพะดะตะปะธ (ะฟะตัะฒัะต 1000 ัะธะผะฒะพะปะพะฒ): {content[:1000]}")
            logger.warning("โ๏ธ ะะตัะตะบะปััะฐะตะผัั ะฝะฐ ะดะฒััััะฐะฟะฝัะน ัะตะถะธะผ ะณะตะฝะตัะฐัะธะธ (fallback)")
            
            # Fallback: ะธัะฟะพะปัะทัะตะผ ะดะฒััััะฐะฟะฝัะน ะฟะพะดัะพะด
            try:
                return await generate_protocol_two_stage(
                    manager=manager,
                    provider_name=provider_name,
                    transcription=transcription,
                    template_variables=template_variables,
                    diarization_data=diarization_data,
                    diarization_analysis=diarization_analysis,
                    **kwargs
                )
            except Exception as fallback_error:
                logger.error(f"โ Fallback ะฝะฐ ะดะฒััััะฐะฟะฝัะน ัะตะถะธะผ ัะฐะบะถะต ะทะฐะฒะตััะธะปัั ั ะพัะธะฑะบะพะน: {fallback_error}")
                raise ValueError(
                    f"Unified generation ะฝะต ัะดะฐะปัั (ะพัะธะฑะบะฐ ะฟะฐััะธะฝะณะฐ JSON), "
                    f"ะธ fallback ะฝะฐ ะดะฒััััะฐะฟะฝัะน ัะตะถะธะผ ัะฐะบะถะต ะฝะต ัะดะฐะปัั: {fallback_error}"
                )
        
        # ะะฐะปะธะดะฐัะธั ััััะบัััั ัะตะทัะปััะฐัะฐ
        if not isinstance(result, dict):
            logger.error(f"โ ะะตะทัะปััะฐั unified generation ะฝะต ัะฒะปัะตััั ัะปะพะฒะฐัะตะผ: {type(result)}")
            logger.warning("โ๏ธ ะะตัะตะบะปััะฐะตะผัั ะฝะฐ ะดะฒััััะฐะฟะฝัะน ัะตะถะธะผ ะณะตะฝะตัะฐัะธะธ (fallback)")
            return await generate_protocol_two_stage(
                manager=manager,
                provider_name=provider_name,
                transcription=transcription,
                template_variables=template_variables,
                diarization_data=diarization_data,
                diarization_analysis=diarization_analysis,
                **kwargs
            )
        
        # ะัะพะฒะตััะตะผ ะฝะฐะปะธัะธะต ะพะฑัะทะฐัะตะปัะฝะพะณะพ ะฟะพะปั protocol_data
        if 'protocol_data' not in result:
            logger.warning(f"โ๏ธ ะ ัะตะทัะปััะฐัะต unified generation ะพััััััะฒัะตั ะฟะพะปะต 'protocol_data'")
            logger.warning(f"ะะพัััะฟะฝัะต ะบะปััะธ: {list(result.keys())}")
            logger.warning("โ๏ธ ะะตัะตะบะปััะฐะตะผัั ะฝะฐ ะดะฒััััะฐะฟะฝัะน ัะตะถะธะผ ะณะตะฝะตัะฐัะธะธ (fallback)")
            return await generate_protocol_two_stage(
                manager=manager,
                provider_name=provider_name,
                transcription=transcription,
                template_variables=template_variables,
                diarization_data=diarization_data,
                diarization_analysis=diarization_analysis,
                **kwargs
            )
        
        # ะะพะทะฒัะฐัะฐะตะผ protocol_data (ะดะปั ัะพะฒะผะตััะธะผะพััะธ ั ัััะตััะฒัััะธะผ ะบะพะดะพะผ)
        protocol_data = result.get('protocol_data', {})
        
        # ะะพะฑะฐะฒะปัะตะผ speaker mapping ะตัะปะธ ะตััั
        if result.get('detected_speaker_mapping'):
            protocol_data['detected_speaker_mapping'] = result['detected_speaker_mapping']
        if result.get('speaker_confidence_scores'):
            protocol_data['speaker_confidence_scores'] = result['speaker_confidence_scores']
        
        logger.info(f"โ Unified generation ะทะฐะฒะตััะตะฝ ััะฟะตัะฝะพ, confidence={result.get('confidence_score', 0.0):.2f}")
        
        return protocol_data
    
    else:
        raise ValueError(f"Unified ะฟะพะดัะพะด ะฟะพะบะฐ ะฟะพะดะดะตัะถะธะฒะฐะตััั ัะพะปัะบะพ ะดะปั OpenAI, ะฟะพะปััะตะฝ: {provider_name}")


async def generate_protocol_consolidated_two_request(
    manager: 'LLMManager',
    provider_name: str,
    transcription: str,
    template_variables: Dict[str, str],
    diarization_data: Optional[Dict[str, Any]] = None,
    diarization_analysis: Optional[Dict[str, Any]] = None,
    participants_list: Optional[str] = None,
    meeting_metadata: Optional[Dict[str, str]] = None,
    **kwargs
) -> Dict[str, Any]:
    """
    ะะพะฝัะพะปะธะดะธัะพะฒะฐะฝะฝัะน ะผะตัะพะด ะณะตะฝะตัะฐัะธะธ ะฟัะพัะพะบะพะปะฐ: 2 ะทะฐะฟัะพัะฐ ะฒะผะตััะพ 5-6
    ะะฐะฟัะพั 1: ะกะพะฟะพััะฐะฒะปะตะฝะธะต ัะฟะธะบะตัะพะฒ + ะธะทะฒะปะตัะตะฝะธะต ััััะบัััั
    ะะฐะฟัะพั 2: ะคะธะฝะฐะปัะฝะฐั ะณะตะฝะตัะฐัะธั ะฟัะพัะพะบะพะปะฐ + QA

    Args:
        manager: ะะตะฝะตะดะถะตั LLM
        provider_name: ะะฐะทะฒะฐะฝะธะต ะฟัะพะฒะฐะนะดะตัะฐ
        transcription: ะขะตะบัั ััะฐะฝัะบัะธะฟัะธะธ
        template_variables: ะะตัะตะผะตะฝะฝัะต ัะฐะฑะปะพะฝะฐ
        diarization_data: ะะฐะฝะฝัะต ะดะธะฐัะธะทะฐัะธะธ
        diarization_analysis: ะะฝะฐะปะธะท ะดะธะฐัะธะทะฐัะธะธ
        participants_list: ะกะฟะธัะพะบ ััะฐััะฝะธะบะพะฒ
        meeting_metadata: ะะตัะฐะดะฐะฝะฝัะต ะฒัััะตัะธ
        **kwargs: ะะพะฟะพะปะฝะธัะตะปัะฝัะต ะฟะฐัะฐะผะตััั

    Returns:
        ะคะธะฝะฐะปัะฝัะน ะฟัะพัะพะบะพะป
    """
    from src.prompts.prompts import (
        build_extraction_prompt,
        build_extraction_system_prompt,
        build_protocol_prompt,
        build_protocol_system_prompt
    )
    from src.models.llm_schemas import get_schema_by_type
    from src.services.meeting_classifier import meeting_classifier

    logger.info("ะะฐัะฐะปะพ ะบะพะฝัะพะปะธะดะธัะพะฒะฐะฝะฝะพะน ะณะตะฝะตัะฐัะธะธ ะฟัะพัะพะบะพะปะฐ (2 ะทะฐะฟัะพัะฐ)")

    # ะะทะฒะปะตะบะฐะตะผ ะดะพะฟะพะปะฝะธัะตะปัะฝัะต ะฟะฐัะฐะผะตััั
    meeting_topic = kwargs.get('meeting_topic')
    meeting_date = kwargs.get('meeting_date')
    meeting_time = kwargs.get('meeting_time')
    participants = kwargs.get('participants')

    # ะคะพัะผะธััะตะผ ะผะตัะฐะดะฐะฝะฝัะต ะฒัััะตัะธ
    if not meeting_metadata:
        meeting_metadata = {}
    meeting_metadata.update({
        'meeting_topic': meeting_topic or '',
        'meeting_date': meeting_date or '',
        'meeting_time': meeting_time or '',
        'participants': participants or participants_list or ''
    })

    # ะะฟัะตะดะตะปัะตะผ ัะธะฟ ะฒัััะตัะธ ะตัะปะธ ะฒะบะปััะตะฝะฐ ะบะปะฐััะธัะธะบะฐัะธั
    meeting_type = "general"
    if settings.meeting_type_detection and transcription:
        try:
            meeting_type, _ = meeting_classifier.classify(
                transcription,
                diarization_analysis
            )
            logger.info(f"ะะฟัะตะดะตะปะตะฝ ัะธะฟ ะฒัััะตัะธ: {meeting_type}")
        except Exception as e:
            logger.warning(f"ะัะธะฑะบะฐ ะฟัะธ ะบะปะฐััะธัะธะบะฐัะธะธ ะฒัััะตัะธ: {e}")

    # =======================================================
    # ะะะะะะก 1: ะกะพะฟะพััะฐะฒะปะตะฝะธะต ัะฟะธะบะตัะพะฒ + ะธะทะฒะปะตัะตะฝะธะต ััััะบัััั
    # =======================================================
    logger.info("ะะฐะฟัะพั 1: ะกะพะฟะพััะฐะฒะปะตะฝะธะต ัะฟะธะบะตัะพะฒ + ะธะทะฒะปะตัะตะฝะธะต ััััะบัััั")

    extraction_prompt = build_extraction_prompt(
        transcription=transcription,
        participants_list=participants_list or participants,
        meeting_metadata=meeting_metadata,
        meeting_type=meeting_type
    )

    extraction_system_prompt = build_extraction_system_prompt()

    try:
        # ะะะะะะก 1: ะะทะฒะปะตัะตะฝะธะต
        if provider_name == "openai":
            provider = manager.providers[provider_name]
            selected_model = settings.openai_model

            # ะัะฑะพั ะฟัะตัะตัะฐ ะผะพะดะตะปะธ
            openai_model_key = kwargs.get("openai_model_key")
            if openai_model_key:
                try:
                    preset = next((p for p in settings.openai_models if p.key == openai_model_key), None)
                    if preset:
                        selected_model = preset.model
                        if getattr(preset, 'base_url', None):
                            selected_base_url = preset.base_url
                except Exception:
                    pass

            selected_base_url = settings.openai_base_url or "https://api.openai.com/v1"
            client = provider.client
            if client is None or (selected_base_url and getattr(client, 'base_url', None) != selected_base_url):
                client = openai.OpenAI(
                    api_key=settings.openai_api_key,
                    base_url=selected_base_url,
                    http_client=provider.http_client
                )

            # ะคะพัะผะธััะตะผ extra_headers
            extra_headers = {}
            if settings.http_referer:
                extra_headers["HTTP-Referer"] = settings.http_referer
            if settings.x_title:
                extra_headers["X-Title"] = settings.x_title

            async def _call_extraction():
                return await asyncio.to_thread(
                    client.chat.completions.create,
                    model=selected_model,
                    messages=[
                        {"role": "system", "content": extraction_system_prompt},
                        {"role": "user", "content": extraction_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=4000,
                    response_format={"type": "json_schema", "json_schema": get_schema_by_type('extraction')},
                    extra_headers=extra_headers
                )

            response = await _call_extraction()
            extraction_result = json.loads(response.choices[0].message.content)

        elif provider_name == "anthropic":
            # ะะปั Anthropic ะธัะฟะพะปัะทัะตะผ ัะฟัะพัะตะฝะฝัะน ะฟะพะดัะพะด
            import anthropic
            provider = manager.providers[provider_name]
            client = provider.client
            if not client:
                client = anthropic.Anthropic(api_key=settings.anthropic_api_key)

            response = await asyncio.to_thread(
                client.messages.create,
                model="claude-3-5-sonnet-20241022",
                max_tokens=4000,
                temperature=0.3,
                system=extraction_system_prompt,
                messages=[
                    {"role": "user", "content": extraction_prompt}
                ]
            )

            extraction_result = json.loads(response.content[0].text)
        else:
            raise ValueError(f"ะะตะฟะพะดะดะตัะถะธะฒะฐะตะผัะน ะฟัะพะฒะฐะนะดะตั: {provider_name}")

        logger.success(f"ะะฐะฟัะพั 1 ะทะฐะฒะตััะตะฝ ััะฟะตัะฝะพ. ะฃะฒะตัะตะฝะฝะพััั: {extraction_result.get('extraction_confidence', 0.0):.2f}")

    except Exception as e:
        logger.error(f"ะัะธะฑะบะฐ ะฒ ะทะฐะฟัะพัะต 1 (ะธะทะฒะปะตัะตะฝะธะต): {e}")
        # Fallback ะบ ััะฐะฝะดะฐััะฝะพะผั ะผะตัะพะดั
        logger.warning("ะะตัะตะบะปััะฐะตะผัั ะฝะฐ ััะฐะฝะดะฐััะฝัะน ะผะตัะพะด ะณะตะฝะตัะฐัะธะธ")
        return await manager.generate_protocol(
            provider_name, transcription, template_variables, diarization_data, **kwargs
        )

    # =======================================================
    # ะะะะะะก 2: ะคะธะฝะฐะปัะฝะฐั ะณะตะฝะตัะฐัะธั ะฟัะพัะพะบะพะปะฐ + QA
    # =======================================================
    logger.info("ะะฐะฟัะพั 2: ะคะธะฝะฐะปัะฝะฐั ะณะตะฝะตัะฐัะธั ะฟัะพัะพะบะพะปะฐ + QA")

    # ะะพะผะฑะธะฝะธััะตะผ ัะตะทัะปััะฐัั ั ัะฐะฑะปะพะฝะพะผ
    combined_data = {}
    if 'protocol_data' in extraction_result:
        combined_data.update(extraction_result['protocol_data'])
    else:
        # ะะปั ExtractionSchema - ะธะทะฒะปะตะบะฐะตะผ ะะกะ ะฟะพะปั, ะบะพัะพััะต ะธัะฟะพะปัะทััััั ัะฐะฑะปะพะฝะฐะผะธ
        protocol_fields = [
            # ะัะฝะพะฒะฝัะต ะฟะพะปั ะฟัะพัะพะบะพะปะฐ
            'meeting_title', 'meeting_date', 'meeting_time', 'participants',
            'agenda', 'discussion', 'key_points', 'decisions', 'action_items',
            'next_meeting', 'additional_notes',

            # ะะพะปั ัะพะฒะผะตััะธะผะพััะธ ะดะปั ัะฐะฑะปะพะฝะพะฒ
            'date', 'time', 'managers', 'platform',

            # ะะพะฟะพะปะฝะธัะตะปัะฝัะต ะฟะพะปั ะธัะฟะพะปัะทัะตะผัะต ัะฐะฑะปะพะฝะฐะผะธ
            'tasks', 'next_steps', 'deadlines', 'issues', 'questions',
            'risks_and_blockers', 'technical_issues', 'architecture_decisions',
            'technical_tasks', 'speaker_contributions', 'dialogue_analysis',
            'speakers_summary',

            # ะะฑัะฐะทะพะฒะฐัะตะปัะฝัะต ะฟะพะปั
            'learning_objectives', 'key_concepts', 'examples_and_cases',
            'practical_exercises', 'homework', 'materials',

            # Agile/DevOps ะฟะพะปั
            'next_sprint_plans'
        ]

        # ะะทะฒะปะตะบะฐะตะผ ะฒัะต ะฟะพะปั ะธะท extraction_result
        for field in protocol_fields:
            if field in extraction_result:
                combined_data[field] = extraction_result[field]
            else:
                # ะัะพะฒะตััะตะผ, ะตััั ะปะธ ะฟะพะปะต ะฒ template_variables ะบะฐะบ ะทะฐะฟะฐัะฝะพะน ะฒะฐัะธะฐะฝั
                if field in template_variables:
                    combined_data[field] = template_variables[field]
                else:
                    combined_data[field] = ''

    # ะะพะฑะฐะฒะปัะตะผ ะฟะตัะตะผะตะฝะฝัะต ัะฐะฑะปะพะฝะฐ
    combined_data.update(template_variables)

    protocol_prompt = build_protocol_prompt(
        extraction_result=extraction_result,
        template_variables=template_variables,
        meeting_type=meeting_type
    )

    protocol_system_prompt = build_protocol_system_prompt()

    try:
        # ะะะะะะก 2: ะคะธะฝะฐะปัะฝัะน ะฟัะพัะพะบะพะป
        if provider_name == "openai":
            provider = manager.providers[provider_name]
            selected_model = settings.openai_model

            # ะัะฑะพั ะฟัะตัะตัะฐ ะผะพะดะตะปะธ
            openai_model_key = kwargs.get("openai_model_key")
            if openai_model_key:
                try:
                    preset = next((p for p in settings.openai_models if p.key == openai_model_key), None)
                    if preset:
                        selected_model = preset.model
                        if getattr(preset, 'base_url', None):
                            selected_base_url = preset.base_url
                except Exception:
                    pass

            selected_base_url = settings.openai_base_url or "https://api.openai.com/v1"
            client = provider.client
            if client is None or (selected_base_url and getattr(client, 'base_url', None) != selected_base_url):
                client = openai.OpenAI(
                    api_key=settings.openai_api_key,
                    base_url=selected_base_url,
                    http_client=provider.http_client
                )

            # ะคะพัะผะธััะตะผ extra_headers
            extra_headers = {}
            if settings.http_referer:
                extra_headers["HTTP-Referer"] = settings.http_referer
            if settings.x_title:
                extra_headers["X-Title"] = settings.x_title

            async def _call_protocol():
                return await asyncio.to_thread(
                    client.chat.completions.create,
                    model=selected_model,
                    messages=[
                        {"role": "system", "content": protocol_system_prompt},
                        {"role": "user", "content": protocol_prompt}
                    ],
                    temperature=0.4,
                    max_tokens=3000,
                    response_format={"type": "json_schema", "json_schema": get_schema_by_type('consolidated_protocol')},
                    extra_headers=extra_headers
                )

            response = await _call_protocol()
            final_result = json.loads(response.choices[0].message.content)

        elif provider_name == "anthropic":
            # ะะปั Anthropic ะธัะฟะพะปัะทัะตะผ ัะฟัะพัะตะฝะฝัะน ะฟะพะดัะพะด
            import anthropic
            provider = manager.providers[provider_name]
            client = provider.client
            if not client:
                client = anthropic.Anthropic(api_key=settings.anthropic_api_key)

            response = await asyncio.to_thread(
                client.messages.create,
                model="claude-3-5-sonnet-20241022",
                max_tokens=3000,
                temperature=0.4,
                system=protocol_system_prompt,
                messages=[
                    {"role": "user", "content": protocol_prompt}
                ]
            )

            final_result = json.loads(response.content[0].text)
        else:
            raise ValueError(f"ะะตะฟะพะดะดะตัะถะธะฒะฐะตะผัะน ะฟัะพะฒะฐะนะดะตั: {provider_name}")

        logger.success(f"ะะฐะฟัะพั 2 ะทะฐะฒะตััะตะฝ ััะฟะตัะฝะพ. ะะฐัะตััะฒะพ ะฟัะพัะพะบะพะปะฐ: {final_result.get('protocol_quality_score', 0.0):.2f}")

        # =======================================================
        # ะะฐะปะธะดะฐัะธั ะบัะธัะธัะตัะบะธ ะฒะฐะถะฝัั ะฟะพะปะตะน
        # =======================================================
        # ะัะพะฒะตััะตะผ ะฝะฐะปะธัะธะต ะบัะธัะธัะตัะบะธ ะฒะฐะถะฝะพะน ะธะฝัะพัะผะฐัะธะธ
        critical_fields = ['participants', 'discussion', 'decisions']
        empty_critical_fields = []

        for field in critical_fields:
            field_value = final_result.get(field, '').strip()
            if not field_value or len(field_value) < 10:
                empty_critical_fields.append(field)

        if empty_critical_fields:
            logger.warning(f"ะัะธัะธัะตัะบะธ ะฒะฐะถะฝัะต ะฟะพะปั ะฟัะพัะพะบะพะปะฐ ะฟัััั ะธะปะธ ัะปะธัะบะพะผ ะบะพัะพัะบะธะต: {empty_critical_fields}")
            # ะัะปะธ ะบะปััะตะฒัะต ะฟะพะปั ะพััััััะฒััั, ะฟััะฐะตะผัั ะธะทะฒะปะตัั ะธั ะธะท extraction_result
            for field in empty_critical_fields:
                if field in extraction_result and extraction_result[field].strip():
                    final_result[field] = extraction_result[field]
                    logger.info(f"ะะพัััะฐะฝะพะฒะปะตะฝะพ ะฟะพะปะต {field} ะธะท extraction_result")
                else:
                    # ะัะพะฑัะตะผ ะธะทะฒะปะตัั ะธะท template_variables
                    if field in template_variables and template_variables[field].strip():
                        final_result[field] = template_variables[field]
                        logger.info(f"ะะพัััะฐะฝะพะฒะปะตะฝะพ ะฟะพะปะต {field} ะธะท template_variables")

        # ะะพะฟะพะปะฝะธัะตะปัะฝะฐั ะฟัะพะฒะตัะบะฐ ะบะฐัะตััะฒะฐ
        protocol_quality = final_result.get('protocol_quality_score', 0.0)
        if protocol_quality < 0.5:
            logger.warning(f"ะะธะทะบะพะต ะบะฐัะตััะฒะพ ะฟัะพัะพะบะพะปะฐ: {protocol_quality:.2f}. ะะตะบะพะผะตะฝะดัะตััั ะฟะพะฒัะพัะฝะฐั ะณะตะฝะตัะฐัะธั.")

        # =======================================================
        # ะะพะฝะฒะตััะธััะตะผ ัะตะทัะปััะฐั ะฒ ััะฐะฝะดะฐััะฝัะน ัะพัะผะฐั
        # =======================================================
        # ะะทะฒะปะตะบะฐะตะผ ะพัะฝะพะฒะฝัะต ะฟะพะปั ะฟัะพัะพะบะพะปะฐ
        protocol_data = {}
        for field in template_variables.keys():
            if field in final_result:
                protocol_data[field] = final_result[field]
            else:
                protocol_data[field] = "ะะต ัะบะฐะทะฐะฝะพ"

        # ะะพะฑะฐะฒะปัะตะผ ัะปัะถะตะฑะฝัั ะธะฝัะพัะผะฐัะธั
        protocol_data['_metadata'] = {
            'method': 'consolidated_two_request',
            'meeting_type': meeting_type,
            'speaker_mapping': extraction_result.get('speaker_mappings', {}),
            'extraction_confidence': extraction_result.get('extraction_confidence', 0.0),
            'protocol_quality_score': final_result.get('protocol_quality_score', 0.0),
            'consistency_checks': final_result.get('consistency_checks', {}),
            'improvement_suggestions': final_result.get('improvement_suggestions', []),
            'processing_time': 'consolidated_2_requests'
        }

        logger.info("ะะพะฝัะพะปะธะดะธัะพะฒะฐะฝะฝะฐั ะณะตะฝะตัะฐัะธั ะฟัะพัะพะบะพะปะฐ ััะฟะตัะฝะพ ะทะฐะฒะตััะตะฝะฐ")
        return protocol_data

    except Exception as e:
        logger.error(f"ะัะธะฑะบะฐ ะฒ ะทะฐะฟัะพัะต 2 (ัะธะฝะฐะปัะฝัะน ะฟัะพัะพะบะพะป): {e}")
        # ะัะพะฑัะตะผ ะธัะฟะพะปัะทะพะฒะฐัั ัะตะทัะปััะฐัั ะทะฐะฟัะพัะฐ 1 ะบะฐะบ fallback
        logger.warning("ะัะฟะพะปัะทัะตะผ ัะตะทัะปััะฐัั ะทะฐะฟัะพัะฐ 1 ะบะฐะบ fallback")
        fallback_result = {}
        for field in template_variables.keys():
            if field in combined_data:
                fallback_result[field] = combined_data[field]
            else:
                fallback_result[field] = "ะะต ัะบะฐะทะฐะฝะพ"

        fallback_result['_metadata'] = {
            'method': 'consolidated_two_request_fallback',
            'meeting_type': meeting_type,
            'speaker_mapping': extraction_result.get('speaker_mappings', {}),
            'extraction_confidence': extraction_result.get('extraction_confidence', 0.0),
            'protocol_quality_score': 0.5,  # ะกัะตะดะฝะธะน ะฟะพะบะฐะทะฐัะตะปั ะดะปั fallback
            'error': str(e)
        }

        return fallback_result


async def generate_protocol_consolidated_simplified(
    manager: 'LLMManager',
    provider_name: str,
    transcription: str,
    template_variables: Dict[str, str],
    participants_list: Optional[str] = None,
    **kwargs
) -> Dict[str, Any]:
    """
    ะฃะฟัะพัะตะฝะฝะฐั ะฒะตััะธั ะบะพะฝัะพะปะธะดะธัะพะฒะฐะฝะฝะพะณะพ ะผะตัะพะดะฐ ะฑะตะท ัะปะพะถะฝะพะน ะปะพะณะธะบะธ
    """
    logger.info("ะัะฟะพะปัะทัะตะผ ัะฟัะพัะตะฝะฝัะน ะบะพะฝัะพะปะธะดะธัะพะฒะฐะฝะฝัะน ะผะตัะพะด")

    # ะะทะฒะปะตะบะฐะตะผ ะฑะฐะทะพะฒัะต ะฟะฐัะฐะผะตััั
    meeting_metadata = {
        'meeting_topic': kwargs.get('meeting_topic', ''),
        'meeting_date': kwargs.get('meeting_date', ''),
        'meeting_time': kwargs.get('meeting_time', ''),
        'participants': kwargs.get('participants', participants_list or '')
    }

    # ะัะฟะพะปัะทัะตะผ ะพัะฝะพะฒะฝะพะน ะบะพะฝัะพะปะธะดะธัะพะฒะฐะฝะฝัะน ะผะตัะพะด
    return await generate_protocol_consolidated_two_request(
        manager=manager,
        provider_name=provider_name,
        transcription=transcription,
        template_variables=template_variables,
        participants_list=participants_list,
        meeting_metadata=meeting_metadata,
        **kwargs
    )


# ะะปะพะฑะฐะปัะฝัะน ัะบะทะตะผะฟะปัั ะผะตะฝะตะดะถะตัะฐ LLM
llm_manager = LLMManager()
