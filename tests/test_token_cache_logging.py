"""
–¢–µ—Å—Ç—ã –¥–ª—è —É—Ç–∏–ª–∏—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
"""

import pytest
from unittest.mock import Mock, MagicMock
from src.utils.token_cache_logger import (
    check_cache_support,
    log_cached_tokens_usage,
    format_cache_summary,
    _get_token_cost
)


class TestCheckCacheSupport:
    """–¢–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def test_openai_gpt4o_supported(self):
        """GPT-4o –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        result = check_cache_support("gpt-4o", "openai")
        
        assert result["supported"] is True
        assert result["method"] == "automatic"
        assert result["min_tokens"] == 1024
        assert result["discount"] == 0.5
    
    def test_openai_gpt4o_mini_supported(self):
        """GPT-4o-mini –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        result = check_cache_support("gpt-4o-mini", "openai")
        
        assert result["supported"] is True
        assert result["method"] == "automatic"
        assert result["discount"] == 0.5
    
    def test_openai_gpt35_not_supported(self):
        """GPT-3.5-turbo –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        result = check_cache_support("gpt-3.5-turbo", "openai")
        
        assert result["supported"] is False
        assert result["method"] is None
        assert result["discount"] == 0.0
    
    def test_anthropic_claude35_supported(self):
        """Claude 3.5 Sonnet –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        result = check_cache_support("claude-3-5-sonnet-20241022", "anthropic")
        
        assert result["supported"] is True
        assert result["method"] == "explicit"
        assert result["min_tokens"] == 1024
        assert result["discount"] == 0.9
    
    def test_anthropic_claude3_opus_supported(self):
        """Claude 3 Opus –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        result = check_cache_support("claude-3-opus-20240229", "anthropic")
        
        assert result["supported"] is True
        assert result["method"] == "explicit"
        assert result["discount"] == 0.9
    
    def test_unknown_provider_not_supported(self):
        """–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        result = check_cache_support("unknown-model", "unknown")
        
        assert result["supported"] is False
        assert result["method"] is None


class TestGetTokenCost:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤"""
    
    def test_gpt4o_input_cost(self):
        """–°—Ç–æ–∏–º–æ—Å—Ç—å input —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è GPT-4o"""
        cost = _get_token_cost("gpt-4o", "input")
        assert cost == 0.0025
    
    def test_gpt4o_cached_cost(self):
        """–°—Ç–æ–∏–º–æ—Å—Ç—å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è GPT-4o"""
        cost = _get_token_cost("gpt-4o", "cached_input")
        assert cost == 0.00125  # 50% —Å–∫–∏–¥–∫–∞
    
    def test_gpt4o_mini_input_cost(self):
        """–°—Ç–æ–∏–º–æ—Å—Ç—å input —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è GPT-4o-mini"""
        cost = _get_token_cost("gpt-4o-mini", "input")
        assert cost == 0.00015
    
    def test_claude35_cached_cost(self):
        """–°—Ç–æ–∏–º–æ—Å—Ç—å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è Claude 3.5"""
        cost = _get_token_cost("claude-3-5-sonnet-20241022", "cached_input")
        assert cost == 0.0003  # 90% —Å–∫–∏–¥–∫–∞
    
    def test_unknown_model_fallback(self):
        """–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç fallback –Ω–∞ GPT-4o"""
        cost = _get_token_cost("unknown-model", "input")
        assert cost == 0.0025  # Fallback –Ω–∞ gpt-4o


class TestLogCachedTokensUsage:
    """–¢–µ—Å—Ç—ã –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
    
    def test_openai_with_cached_tokens(self):
        """OpenAI –æ—Ç–≤–µ—Ç —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏"""
        # –°–æ–∑–¥–∞–µ–º mock response
        mock_response = Mock()
        mock_response.usage = Mock()
        mock_response.usage.prompt_tokens = 20000
        mock_response.usage.completion_tokens = 3000
        mock_response.usage.total_tokens = 23000
        
        # Mock –¥–ª—è prompt_tokens_details
        mock_details = Mock()
        mock_details.cached_tokens = 15000
        mock_response.usage.prompt_tokens_details = mock_details
        
        # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é
        metrics = log_cached_tokens_usage(
            response=mock_response,
            context="Test",
            model_name="gpt-4o",
            provider="openai"
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        assert metrics["prompt_tokens"] == 20000
        assert metrics["completion_tokens"] == 3000
        assert metrics["total_tokens"] == 23000
        assert metrics["cached_tokens"] == 15000
        assert metrics["cache_hit_rate"] == 0.75  # 15000 / 20000
        assert metrics["cost_saved"] > 0
        assert metrics["savings_percent"] > 0
    
    def test_openai_without_cached_tokens(self):
        """OpenAI –æ—Ç–≤–µ—Ç –±–µ–∑ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
        mock_response = Mock()
        mock_response.usage = Mock()
        mock_response.usage.prompt_tokens = 20000
        mock_response.usage.completion_tokens = 3000
        mock_response.usage.total_tokens = 23000
        mock_response.usage.prompt_tokens_details = None
        
        metrics = log_cached_tokens_usage(
            response=mock_response,
            context="Test",
            model_name="gpt-4o",
            provider="openai"
        )
        
        assert metrics["cached_tokens"] == 0
        assert metrics["cache_hit_rate"] == 0.0
        assert metrics["cost_saved"] == 0.0
    
    def test_anthropic_with_cache_read(self):
        """Anthropic –æ—Ç–≤–µ—Ç —Å cache_read_input_tokens"""
        mock_response = Mock()
        mock_response.usage = Mock()
        mock_response.usage.prompt_tokens = 20000
        mock_response.usage.completion_tokens = 3000
        mock_response.usage.total_tokens = 23000
        mock_response.usage.cache_read_input_tokens = 18000
        mock_response.usage.cache_creation_input_tokens = 0
        
        metrics = log_cached_tokens_usage(
            response=mock_response,
            context="Test",
            model_name="claude-3-5-sonnet-20241022",
            provider="anthropic"
        )
        
        assert metrics["cached_tokens"] == 18000
        assert metrics["cache_hit_rate"] == 0.9  # 18000 / 20000
    
    def test_no_usage_in_response(self):
        """Response –±–µ–∑ usage –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        mock_response = Mock(spec=[])  # No attributes
        
        metrics = log_cached_tokens_usage(
            response=mock_response,
            context="Test",
            provider="openai"
        )
        
        # –î–æ–ª–∂–Ω—ã –≤–µ—Ä–Ω—É—Ç—å—Å—è –Ω—É–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        assert metrics["prompt_tokens"] == 0
        assert metrics["cached_tokens"] == 0
        assert metrics["cache_hit_rate"] == 0.0
    
    def test_cost_calculation_accuracy(self):
        """–¢–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏"""
        mock_response = Mock()
        mock_response.usage = Mock()
        mock_response.usage.prompt_tokens = 10000
        mock_response.usage.completion_tokens = 2000
        mock_response.usage.total_tokens = 12000
        
        mock_details = Mock()
        mock_details.cached_tokens = 5000
        mock_response.usage.prompt_tokens_details = mock_details
        
        metrics = log_cached_tokens_usage(
            response=mock_response,
            context="Test",
            model_name="gpt-4o",
            provider="openai"
        )
        
        # –†–∞—Å—á–µ—Ç –≤—Ä—É—á–Ω—É—é –¥–ª—è GPT-4o:
        # Input: $0.0025 per 1K, Cached: $0.00125 per 1K, Output: $0.010 per 1K
        # Without cache: (10000/1000)*0.0025 + (2000/1000)*0.010 = 0.025 + 0.020 = 0.045
        # With cache: (5000/1000)*0.0025 + (5000/1000)*0.00125 + (2000/1000)*0.010 = 0.0125 + 0.00625 + 0.020 = 0.03875
        # Saved: 0.045 - 0.03875 = 0.00625
        
        assert abs(metrics["cost_without_cache"] - 0.045) < 0.001
        assert abs(metrics["cost_with_cache"] - 0.03875) < 0.001
        assert abs(metrics["cost_saved"] - 0.00625) < 0.001
        assert abs(metrics["savings_percent"] - 13.89) < 0.5  # ~13.89%


class TestFormatCacheSummary:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–≤–æ–¥–∫–∏ –ø–æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—é"""
    
    def test_summary_with_multiple_metrics(self):
        """–°–≤–æ–¥–∫–∞ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        metrics_list = [
            {
                "prompt_tokens": 20000,
                "completion_tokens": 3000,
                "cached_tokens": 15000,
                "cost_saved": 0.0375,
                "cost_with_cache": 0.0375,
                "cost_without_cache": 0.075
            },
            {
                "prompt_tokens": 13000,
                "completion_tokens": 2500,
                "cached_tokens": 10000,
                "cost_saved": 0.025,
                "cost_with_cache": 0.025,
                "cost_without_cache": 0.05
            }
        ]
        
        summary = format_cache_summary(metrics_list)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–≤–æ–¥–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        assert "33,000" in summary  # Total prompt tokens (20000 + 13000)
        assert "25,000" in summary  # Total cached tokens (15000 + 10000)
        assert "75.8" in summary or "76" in summary  # Cache rate % (25000/33000)
        assert "$0.0625" in summary  # Total cost saved (0.0375 + 0.025)
    
    def test_summary_with_empty_list(self):
        """–°–≤–æ–¥–∫–∞ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞"""
        summary = format_cache_summary([])
        
        assert "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö" in summary
    
    def test_summary_formatting(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–≤–æ–¥–∫–∏"""
        metrics_list = [
            {
                "prompt_tokens": 10000,
                "completion_tokens": 1000,
                "cached_tokens": 5000,
                "cost_saved": 0.01,
                "cost_with_cache": 0.02,
                "cost_without_cache": 0.03
            }
        ]
        
        summary = format_cache_summary(metrics_list)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        assert "üìä –°–≤–æ–¥–∫–∞ –ø–æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—é —Ç–æ–∫–µ–Ω–æ–≤:" in summary
        assert "–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: 1" in summary
        assert "–¢–æ–∫–µ–Ω—ã:" in summary
        assert "–ö–µ—à–∏—Ä–æ–≤–∞–Ω–æ:" in summary
        assert "–°—Ç–æ–∏–º–æ—Å—Ç—å:" in summary
        assert "–≠–∫–æ–Ω–æ–º–∏—è:" in summary


class TestEdgeCases:
    """–¢–µ—Å—Ç—ã –¥–ª—è –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤"""
    
    def test_zero_prompt_tokens(self):
        """–ù—É–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ prompt —Ç–æ–∫–µ–Ω–æ–≤"""
        mock_response = Mock()
        mock_response.usage = Mock()
        mock_response.usage.prompt_tokens = 0
        mock_response.usage.completion_tokens = 1000
        mock_response.usage.total_tokens = 1000
        mock_response.usage.prompt_tokens_details = None
        
        metrics = log_cached_tokens_usage(
            response=mock_response,
            context="Test",
            provider="openai"
        )
        
        assert metrics["cache_hit_rate"] == 0.0  # –ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å division by zero
    
    def test_cached_more_than_total(self):
        """–ö–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –±–æ–ª—å—à–µ —á–µ–º total (–Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)"""
        mock_response = Mock()
        mock_response.usage = Mock()
        mock_response.usage.prompt_tokens = 10000
        mock_response.usage.completion_tokens = 1000
        mock_response.usage.total_tokens = 11000
        
        mock_details = Mock()
        mock_details.cached_tokens = 15000  # –ë–æ–ª—å—à–µ —á–µ–º prompt_tokens!
        mock_response.usage.prompt_tokens_details = mock_details
        
        # –ù–µ –¥–æ–ª–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å –æ—à–∏–±–∫—É
        metrics = log_cached_tokens_usage(
            response=mock_response,
            context="Test",
            provider="openai"
        )
        
        assert metrics["cached_tokens"] == 15000
        assert metrics["cache_hit_rate"] == 1.5  # –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –Ω–æ –Ω–µ –∫—Ä–∞—à
    
    def test_model_name_case_insensitive(self):
        """–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ"""
        result1 = check_cache_support("GPT-4O", "openai")
        result2 = check_cache_support("gpt-4o", "openai")
        result3 = check_cache_support("GpT-4O", "openai")
        
        assert result1["supported"] == result2["supported"] == result3["supported"]
        assert result1["discount"] == result2["discount"] == result3["discount"]


if __name__ == "__main__":
    pytest.main([__file__, "-v"])

