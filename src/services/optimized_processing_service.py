"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
"""

import asyncio
import time
import os
import aiofiles
from typing import Dict, Any, Optional
from loguru import logger

from src.services.base_processing_service import BaseProcessingService
from src.models.processing import ProcessingRequest, ProcessingResult
from src.exceptions.processing import ProcessingError
from src.performance.cache_system import performance_cache, cache_transcription, cache_llm_response
from src.performance.metrics import metrics_collector, PerformanceTimer, performance_timer
from src.performance.async_optimization import (
    task_pool, thread_manager, optimized_file_processing,
    OptimizedHTTPClient, async_lru_cache
)
from src.performance.memory_management import memory_optimizer
from reliability.middleware import monitoring_middleware
from database import db
from src.utils.telegram_safe import safe_send_message

# –ù–æ–≤—ã–µ —Å–µ—Ä–≤–∏—Å—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
from src.services.transcription_preprocessor import get_preprocessor
from src.services.diarization_analyzer import diarization_analyzer
from src.services.protocol_validator import protocol_validator
from src.services.segmentation_service import segmentation_service
from src.services.meeting_structure_builder import get_structure_builder
from src.services.smart_template_selector import smart_selector
from llm_providers import generate_protocol_two_stage, generate_protocol_chain_of_thought, llm_manager
from config import settings


class OptimizedProcessingService(BaseProcessingService):
    """–°–µ—Ä–≤–∏—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def __init__(self):
        super().__init__()
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –±—É–¥–µ—Ç –∑–∞–ø—É—â–µ–Ω –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        self._monitoring_started = False
    
    def _format_speaker_mapping_message(
        self,
        speaker_mapping: Dict[str, str],
        total_participants: int
    ) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤
        
        Args:
            speaker_mapping: –°–ª–æ–≤–∞—Ä—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è {speaker_id: participant_name}
            total_participants: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
            
        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        """
        if not speaker_mapping:
            return (
                "‚ÑπÔ∏è *–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ*\n\n"
                "–ü—Ä–æ—Ç–æ–∫–æ–ª –±—É–¥–µ—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ —Å–ø–∏–∫–µ—Ä–æ–≤ –∫ –∏–º–µ–Ω–∞–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤."
            )
        
        mapped_count = len(speaker_mapping)
        message_lines = [
            "‚úÖ *–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ*\n",
            f"–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ {mapped_count} –∏–∑ {total_participants} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤:\n"
        ]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ speaker_id –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞
        sorted_mapping = sorted(speaker_mapping.items())
        
        for speaker_id, participant_name in sorted_mapping:
            message_lines.append(f"‚Ä¢ {speaker_id} ‚Üí {participant_name}")
        
        return "\n".join(message_lines)
    
    @performance_timer("file_processing")
    async def process_file(self, request: ProcessingRequest, progress_tracker=None) -> ProcessingResult:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞"""
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        await self._ensure_monitoring_started()
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
        processing_metrics = metrics_collector.start_processing_metrics(
            request.file_name, request.user_id
        )
        monitoring_start_time = time.time()

        def record_monitoring(success: bool) -> None:
            duration = (
                processing_metrics.total_duration
                if processing_metrics.total_duration
                else time.time() - monitoring_start_time
            )
            monitoring_middleware.record_protocol_request(
                user_id=request.user_id,
                duration=duration,
                success=success
            )
        
        try:
            # –ù–∞—á–∏–Ω–∞–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–ø–µ—Ä–≤—ã–π –≤–∏–¥–∏–º—ã–π —ç—Ç–∞–ø ‚Äî "preparation")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            cache_key = self._generate_result_cache_key(request)
            cached_result = await performance_cache.get(cache_key)
            
            if cached_result:
                logger.info(f"–ù–∞–π–¥–µ–Ω –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {request.file_name}")
                processing_metrics.end_time = processing_metrics.start_time  # –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                metrics_collector.finish_processing_metrics(processing_metrics)
                record_monitoring(True)
                await self._save_processing_history(request, cached_result)
                if progress_tracker:
                    await progress_tracker.complete_all()
                return cached_result
            
            # –ï—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç, –≤—ã–ø–æ–ª–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            result = await self._process_file_optimized(request, processing_metrics, progress_tracker)
            
            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            await performance_cache.set(
                cache_key, result, 
                cache_type="processing_result"
            )
            
            metrics_collector.finish_processing_metrics(processing_metrics)
            record_monitoring(True)
            await self._save_processing_history(request, result)
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ {request.file_name}: {e}")
            metrics_collector.finish_processing_metrics(processing_metrics, e)
            record_monitoring(False)
            raise

    async def _save_processing_history(
        self,
        request: ProcessingRequest,
        result: ProcessingResult
    ) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤ –ë–î"""
        try:
            user = await self.user_service.get_user_by_telegram_id(request.user_id)
            if not user:
                logger.warning(
                    f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {request.user_id} –Ω–µ –Ω–∞–π–¥–µ–Ω"
                )
                return

            transcription_text = ""
            if getattr(result, "transcription_result", None):
                transcription_text = getattr(
                    result.transcription_result,
                    "transcription",
                    ""
                ) or ""

            await db.save_processing_result(
                user_id=user.id,
                file_name=request.file_name,
                template_id=request.template_id,
                llm_provider=result.llm_provider_used,
                transcription_text=transcription_text,
                result_text=result.protocol_text or ""
            )
        except Exception as err:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {err}")
    
    async def _process_file_optimized(self, request: ProcessingRequest, 
                                    processing_metrics, progress_tracker=None) -> ProcessingResult:
        
        # –î–û–ë–ê–í–õ–ï–ù–û: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ ProcessingRequest –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        logger.info(f"üîç –î–∞–Ω–Ω—ã–µ –∏–∑ ProcessingRequest –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        if request.participants_list:
            logger.info(f"  participants_list: {len(request.participants_list)} —á–µ–ª.")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —É—á–∞—Å—Ç–Ω–∏–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            for i, p in enumerate(request.participants_list[:3], 1):
                logger.info(f"    {i}. {p.get('name')} ({p.get('role', '–±–µ–∑ —Ä–æ–ª–∏')})")
            if len(request.participants_list) > 3:
                logger.info(f"    ... –∏ –µ—â–µ {len(request.participants_list) - 3} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
        else:
            logger.warning("  participants_list: None (–ù–ï –ü–ï–†–ï–î–ê–ù –í REQUEST!)")
        logger.info(f"  meeting_topic: {request.meeting_topic}")
        logger.info(f"  meeting_date: {request.meeting_date}")
        logger.info(f"  meeting_time: {request.meeting_time}")
        logger.info(f"  speaker_mapping: {request.speaker_mapping}")
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        
        async with optimized_file_processing() as resources:
            http_client = resources["http_client"]
            
            # –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            with PerformanceTimer("data_loading", metrics_collector):
                user = await self.user_service.get_user_by_telegram_id(request.user_id)
                
                if not user:
                    raise ProcessingError(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {request.user_id} –Ω–µ –Ω–∞–π–¥–µ–Ω", 
                                        request.file_name, "validation")
            
            processing_metrics.validation_duration = 0.5  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è
            
            # –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–∞
            if progress_tracker:
                await progress_tracker.start_stage("preparation")
            
            with PerformanceTimer("file_download", metrics_collector):
                if request.is_external_file:
                    # –î–ª—è –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø—É—Ç—å —É–∂–µ —É–∫–∞–∑–∞–Ω
                    temp_file_path = request.file_path
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                    if os.path.exists(temp_file_path):
                        file_size = os.path.getsize(temp_file_path)
                        processing_metrics.file_size_bytes = file_size
                        processing_metrics.download_duration = 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
                    else:
                        raise ProcessingError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {temp_file_path}", 
                                            request.file_name, "file_preparation")
                else:
                    # –î–ª—è Telegram —Ñ–∞–π–ª–æ–≤ - —Å–∫–∞—á–∏–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
                    file_url = await self.file_service.get_telegram_file_url(request.file_id)
                    temp_file_path = f"temp/{request.file_name}"
                    
                    download_result = await http_client.download_file(file_url, temp_file_path)
                    
                    if not download_result["success"]:
                        raise ProcessingError(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {download_result['error']}", 
                                            request.file_name, "download")
                    
                    processing_metrics.download_duration = download_result["duration"]
                    processing_metrics.file_size_bytes = download_result["bytes_downloaded"]
                
                processing_metrics.file_format = os.path.splitext(request.file_name)[1]
            
            # –≠—Ç–∞–ø 2: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
            if progress_tracker:
                await progress_tracker.start_stage("transcription")
                
            transcription_result = await self._optimized_transcription(
                temp_file_path, request, processing_metrics, progress_tracker
            )
            
            # –≠—Ç–∞–ø 2.3: –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤ —Å —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Å–ø–∏—Å–æ–∫)
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ª–æ–≥–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –¥–ª—è speaker mapping: participants_list={request.participants_list is not None} ({len(request.participants_list) if request.participants_list else 0} —á–µ–ª.), diarization={transcription_result.diarization is not None}")
            
            if request.participants_list and transcription_result.diarization:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –±—ã—Å—Ç—Ä–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è
                # –∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ç—Ä–µ–∫–µ—Ä–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                
                try:
                    from src.services.speaker_mapping_service import speaker_mapping_service
                    
                    logger.info(f"üé≠ –ù–ê–ß–ê–õ–û –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø –°–ü–ò–ö–ï–†–û–í: {len(request.participants_list)} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
                    logger.info(f"–°–ø–∏—Å–æ–∫ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:")
                    for i, p in enumerate(request.participants_list[:5], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                        logger.info(f"  {i}. {p.get('name')} ({p.get('role', '–±–µ–∑ —Ä–æ–ª–∏')})")
                    if len(request.participants_list) > 5:
                        logger.info(f"  ... –∏ –µ—â–µ {len(request.participants_list) - 5} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
                    
                    speaker_mapping = await speaker_mapping_service.map_speakers_to_participants(
                        diarization_data=transcription_result.diarization,
                        participants=request.participants_list,
                        transcription_text=transcription_result.transcription,
                        llm_provider=request.llm_provider
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º mapping –≤ request –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                    request.speaker_mapping = speaker_mapping
                    
                    logger.info(f"‚úÖ –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û: {len(speaker_mapping)} —Å–ø–∏–∫–µ—Ä–æ–≤ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ")
                    if speaker_mapping:
                        logger.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:")
                        for speaker_id, name in speaker_mapping.items():
                            logger.info(f"  {speaker_id} ‚Üí {name}")
                    else:
                        logger.warning("‚ö†Ô∏è Speaker mapping –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –ø—Ä–æ—Ç–æ–∫–æ–ª –±—É–¥–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –±–µ–∑ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤")
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
                    if progress_tracker:
                        try:
                            from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
                            import json
                            
                            notification_text = self._format_speaker_mapping_message(
                                speaker_mapping,
                                len(request.participants_list)
                            )
                            
                            # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ –¥–µ–π—Å—Ç–≤–∏–π
                            keyboard_buttons = []
                            
                            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, –¥–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                            if speaker_mapping:
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è callback (–æ–≥—Ä–∞–Ω–∏—á–∏–º —Ä–∞–∑–º–µ—Ä)
                                callback_data = {
                                    "action": "edit_mapping",
                                    "task_id": str(request.user_id)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º user_id –∫–∞–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä
                                }
                                keyboard_buttons.append([InlineKeyboardButton(
                                    text="‚úèÔ∏è –ò–∑–º–µ–Ω–∏—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ",
                                    callback_data=f"edit_mapping:{request.user_id}"
                                )])
                            
                            # –ö–Ω–æ–ø–∫–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞)
                            keyboard_buttons.append([InlineKeyboardButton(
                                text="‚úÖ –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å —Ç–µ–∫—É—â–∏–º",
                                callback_data=f"continue_mapping:{request.user_id}"
                            )])
                            
                            keyboard = InlineKeyboardMarkup(inline_keyboard=keyboard_buttons) if keyboard_buttons else None
                            
                            await safe_send_message(
                                progress_tracker.bot,
                                progress_tracker.chat_id,
                                notification_text,
                                parse_mode="Markdown",
                                reply_markup=keyboard
                            )
                            logger.debug("–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é")
                        except Exception as notify_error:
                            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {notify_error}")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û–®–ò–ë–ö–ê –ü–†–ò –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ò –°–ü–ò–ö–ï–†–û–í: {e}", exc_info=True)
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ mapping
                    request.speaker_mapping = None
            else:
                if not request.participants_list:
                    logger.info("‚ÑπÔ∏è Speaker mapping –ø—Ä–æ–ø—É—â–µ–Ω: —Å–ø–∏—Å–æ–∫ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
                elif not transcription_result.diarization:
                    logger.warning("‚ö†Ô∏è Speaker mapping –ø—Ä–æ–ø—É—â–µ–Ω: –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                request.speaker_mapping = None
            
            # –≠—Ç–∞–ø 2.5: –£–º–Ω—ã–π –≤—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            template = await self._suggest_template_if_needed(
                request, transcription_result, progress_tracker
            )
            
            if not template:
                raise ProcessingError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å —à–∞–±–ª–æ–Ω", 
                                    request.file_name, "template_selection")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º request —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º —à–∞–±–ª–æ–Ω–æ–º
            request.template_id = template.id
            
            # –≠—Ç–∞–ø 3: –ê–Ω–∞–ª–∏–∑ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
            if progress_tracker:
                await progress_tracker.start_stage("analysis")
                
            llm_result = await self._optimized_llm_generation(
                transcription_result, template, request, processing_metrics
            )
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–≤–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —ç—Ç–∞–ø –∞–Ω–∞–ª–∏–∑–∞)
            if progress_tracker:
                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ —Ä–∞–º–∫–∞—Ö —ç—Ç–∞–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
                pass
                
            with PerformanceTimer("formatting", metrics_collector):
                processing_metrics.formatting_duration = 0.1
                
                protocol_text = self._format_protocol(
                    template, llm_result, transcription_result
                )
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—É —Å–ø–∏–∫–µ—Ä–æ–≤ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞
                if request.speaker_mapping:
                    from src.utils.text_processing import replace_speakers_in_text
                    protocol_text = replace_speakers_in_text(protocol_text, request.speaker_mapping)
                    logger.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω–∞ –∑–∞–º–µ–Ω–∞ —Å–ø–∏–∫–µ—Ä–æ–≤ –Ω–∞ –∏–º–µ–Ω–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
            
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ —Ñ–æ–Ω–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤)
            if request.is_external_file:
                asyncio.create_task(self._cleanup_temp_file(temp_file_path))
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return ProcessingResult(
                transcription_result=transcription_result,
                protocol_text=protocol_text,
                template_used=template.model_dump() if hasattr(template, 'model_dump') else template.__dict__,
                llm_provider_used=request.llm_provider,
                processing_duration=processing_metrics.total_duration
            )
    
    async def _suggest_template_if_needed(
        self,
        request: ProcessingRequest,
        transcription_result: Any,
        progress_tracker=None
    ) -> Optional[Any]:
        """
        –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å —É–º–Ω—ã–π –≤—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –µ—Å–ª–∏ template_id –Ω–µ –∑–∞–¥–∞–Ω
        
        Returns:
            Template –∏–ª–∏ None –µ—Å–ª–∏ —É–∂–µ –≤—ã–±—Ä–∞–Ω
        """
        # –ï—Å–ª–∏ —à–∞–±–ª–æ–Ω —É–∂–µ –≤—ã–±—Ä–∞–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ
        if request.template_id:
            return await self.template_service.get_template_by_id(request.template_id)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã
        templates = await self.template_service.get_user_templates(request.user_id)
        
        if not templates:
            # Fallback –Ω–∞ –ø–µ—Ä–≤—ã–π –±–∞–∑–æ–≤—ã–π —à–∞–±–ª–æ–Ω
            all_templates = await self.template_service.get_all_templates()
            return all_templates[0] if all_templates else None
        
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫
        user_stats = await db.get_user_stats(request.user_id)
        template_history = []
        if user_stats and user_stats.get('favorite_templates'):
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º ID, –ø—Ä–æ–ø—É—Å–∫–∞—è –∑–∞–ø–∏—Å–∏ –±–µ–∑ id
            template_history = [
                t['id'] for t in user_stats['favorite_templates'] 
                if isinstance(t, dict) and 'id' in t
            ]
        
        # ML-based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        suggestions = await smart_selector.suggest_templates(
            transcription=transcription_result.transcription,
            templates=templates,  # —É–∂–µ —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ Template
            top_k=3,
            user_history=template_history
        )
        
        if suggestions:
            best_template, confidence = suggestions[0]
            logger.info(
                f"–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω —à–∞–±–ª–æ–Ω '{best_template.name}' "
                f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%})"
            )
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
            return best_template
        
        # Fallback - templates[0] —É–∂–µ –æ–±—ä–µ–∫—Ç Template
        return templates[0]
    
    @cache_transcription()
    async def _optimized_transcription(self, file_path: str, request: ProcessingRequest,
                                     processing_metrics, progress_tracker=None) -> Any:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
        file_hash = await self._calculate_file_hash(file_path)
        cache_key = f"transcription:{file_hash}:{request.language}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_transcription = await performance_cache.get(cache_key)
        if cached_transcription:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
            processing_metrics.transcription_duration = 0.1  # –ú–≥–Ω–æ–≤–µ–Ω–Ω–æ –∏–∑ –∫—ç—à–∞
            return cached_transcription
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ –¥–ª—è –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∏—è
        with PerformanceTimer("transcription", metrics_collector):
            start_time = time.time()
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            logger.info(f"–ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Ñ–∞–π–ª–∞: {file_path}")
            transcription_result = await self._run_transcription_async(
                file_path, request.language
            )
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–µ–Ω: {hasattr(transcription_result, 'transcription')}")
            
            processing_metrics.transcription_duration = time.time() - start_time
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            if hasattr(transcription_result, 'transcription'):
                processing_metrics.transcription_length = len(transcription_result.transcription)
            
            # –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —ç—Ç–∞–ø —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            if hasattr(transcription_result, 'diarization') and transcription_result.diarization:
                diarization_data = transcription_result.diarization
                if isinstance(diarization_data, dict):
                    processing_metrics.speakers_count = diarization_data.get('total_speakers', 0)
                    processing_metrics.diarization_duration = 5.0  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è
        
        # –≠—Ç–∞–ø –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        if settings.enable_text_preprocessing and hasattr(transcription_result, 'transcription'):
            logger.info("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞")
            preprocessor = get_preprocessor(request.language)
            
            preprocessed = preprocessor.preprocess(
                text=transcription_result.transcription,
                formatted_transcript=getattr(transcription_result, 'formatted_transcript', None)
            )
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –æ—á–∏—â–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
            transcription_result.transcription = preprocessed['cleaned_text']
            if preprocessed['cleaned_formatted']:
                transcription_result.formatted_transcript = preprocessed['cleaned_formatted']
            
            logger.info(
                f"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ {preprocessed['statistics']['reduction_percent']}%"
            )
        
        # –≠—Ç–∞–ø —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
        if settings.enable_diarization_analysis and hasattr(transcription_result, 'diarization'):
            if transcription_result.diarization:
                logger.info("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏")
                
                analysis_result = diarization_analyzer.enrich_diarization_data(
                    transcription_result.diarization,
                    transcription_result.transcription
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
                transcription_result.diarization_analysis = analysis_result
                
                logger.info(
                    f"–ê–Ω–∞–ª–∏–∑ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω: {analysis_result.total_speakers} —Å–ø–∏–∫–µ—Ä–æ–≤, "
                    f"—Ç–∏–ø –≤—Å—Ç—Ä–µ—á–∏: {analysis_result.meeting_type}"
                )
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        await performance_cache.set(cache_key, transcription_result, cache_type="transcription")
        
        return transcription_result
    
    async def _run_transcription_async(self, file_path: str, language: str):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è"""
        return await self.transcription_service.transcribe_with_diarization(
            file_path, language
        )
    
    @cache_llm_response()
    async def _optimized_llm_generation(self, transcription_result: Any, template: Dict,
                                      request: ProcessingRequest, processing_metrics) -> Any:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è LLM —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º, –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏ —à–∞–±–ª–æ–Ω–∞
        transcription_hash = hash(str(transcription_result.transcription))
        template_hash = hash(str(template))
        cache_key = f"llm:{request.llm_provider}:{transcription_hash}:{template_hash}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_llm_result = await performance_cache.get(cache_key)
        if cached_llm_result:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç LLM")
            processing_metrics.llm_duration = 0.1
            return cached_llm_result
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é LLM
        with PerformanceTimer("llm_generation", metrics_collector):
            start_time = time.time()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è LLM - –∏–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ —à–∞–±–ª–æ–Ω–∞
            template_variables = self._get_template_variables_from_template(template)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á –ø—Ä–µ—Å–µ—Ç–∞ –º–æ–¥–µ–ª–∏ OpenAI –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
            openai_model_key = None
            try:
                user = await self.user_service.get_user_by_telegram_id(request.user_id)
                if user and request.llm_provider == 'openai':
                    openai_model_key = getattr(user, 'preferred_openai_model_key', None)
            except Exception:
                openai_model_key = None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            diarization_analysis = None
            if hasattr(transcription_result, 'diarization_analysis'):
                analysis_obj = transcription_result.diarization_analysis
                if analysis_obj:
                    # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —Å–ª–æ–≤–∞—Ä—å (–∏–∑ –∫—ç—à–∞), –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é
                    if isinstance(analysis_obj, dict):
                        diarization_analysis = analysis_obj
                    # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ä–µ–∫—Ç DiarizationAnalysisResult, –≤—ã–∑—ã–≤–∞–µ–º to_dict()
                    elif hasattr(analysis_obj, 'to_dict'):
                        diarization_analysis = analysis_obj.to_dict()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—Å—Ç—Ä–µ—á–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ Chain-of-Thought
            estimated_duration_minutes = None
            diarization_data_raw = getattr(transcription_result, 'diarization', None)
            if diarization_data_raw:
                estimated_duration_minutes = diarization_data_raw.get('total_duration', 0) / 60
            
            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤—Å—Ç—Ä–µ—á–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
            meeting_structure = None
            if settings.enable_meeting_structure:
                try:
                    logger.info("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤—Å—Ç—Ä–µ—á–∏")
                    structure_start_time = time.time()
                    
                    # –ü–æ–ª—É—á–∞–µ–º builder —Å LLM manager
                    structure_builder = get_structure_builder(llm_manager)
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –≤—Å—Ç—Ä–µ—á–∏ –µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                    meeting_type = "general"
                    if diarization_analysis:
                        meeting_type = diarization_analysis.get('meeting_type', 'general')
                    
                    # –°—Ç—Ä–æ–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                    meeting_structure = await structure_builder.build_from_transcription(
                        transcription=transcription_result.transcription,
                        diarization_analysis=diarization_analysis,
                        meeting_type=meeting_type,
                        language=request.language
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    processing_metrics.structure_building_duration = time.time() - structure_start_time
                    processing_metrics.topics_extracted = len(meeting_structure.topics)
                    processing_metrics.decisions_extracted = len(meeting_structure.decisions)
                    processing_metrics.actions_extracted = len(meeting_structure.action_items)
                    
                    validation = meeting_structure.validate_structure()
                    processing_metrics.structure_validation_passed = validation['valid']
                    
                    logger.info(
                        f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –∑–∞ {processing_metrics.structure_building_duration:.2f}—Å: "
                        f"{processing_metrics.topics_extracted} —Ç–µ–º, {processing_metrics.decisions_extracted} —Ä–µ—à–µ–Ω–∏–π, "
                        f"{processing_metrics.actions_extracted} –∑–∞–¥–∞—á"
                    )
                    
                    # –ö—ç—à–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
                    if settings.cache_meeting_structures:
                        structure_cache_key = f"structure:{transcription_hash}"
                        await performance_cache.set(structure_cache_key, meeting_structure.to_dict(), cache_type="meeting_structure")
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤—Å—Ç—Ä–µ—á–∏: {e}", exc_info=True)
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                    meeting_structure = None
            
            # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: Chain-of-Thought > –î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π > –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å Chain-of-Thought –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –≤—Å—Ç—Ä–µ—á
            should_use_cot = segmentation_service.should_use_segmentation(
                transcription=transcription_result.transcription,
                estimated_duration_minutes=estimated_duration_minutes
            )
            
            if should_use_cot and request.llm_provider == 'openai':
                logger.info("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Chain-of-Thought –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –¥–ª–∏–Ω–Ω–æ–π –≤—Å—Ç—Ä–µ—á–∏")
                
                # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è, –∏–Ω–∞—á–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                if diarization_data_raw and diarization_data_raw.get('formatted_transcript'):
                    logger.info("–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º")
                    segments = segmentation_service.segment_by_speakers(
                        diarization_data=diarization_data_raw,
                        transcription=transcription_result.transcription
                    )
                else:
                    logger.info("–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
                    segments = segmentation_service.segment_by_time(
                        transcription=transcription_result.transcription,
                        diarization_data=diarization_data_raw,
                        target_minutes=int(settings.chain_of_thought_threshold_minutes / 6)  # ~5 –º–∏–Ω —Å–µ–≥–º–µ–Ω—Ç—ã
                    )
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                for segment in segments:
                    logger.info(segmentation_service.create_segment_summary(segment))
                
                # Chain-of-Thought –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                llm_result_data = await generate_protocol_chain_of_thought(
                    manager=llm_manager,
                    provider_name=request.llm_provider,
                    transcription=transcription_result.transcription,
                    template_variables=template_variables,
                    segments=segments,
                    diarization_data=diarization_data_raw,
                    diarization_analysis=diarization_analysis,
                    openai_model_key=openai_model_key,
                    speaker_mapping=request.speaker_mapping,
                    meeting_topic=request.meeting_topic,
                    meeting_date=request.meeting_date,
                    meeting_time=request.meeting_time
                )
                
            elif settings.two_stage_processing and request.llm_provider == 'openai':
                logger.info("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
                
                # –î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                llm_result_data = await generate_protocol_two_stage(
                    manager=llm_manager,
                    provider_name=request.llm_provider,
                    transcription=transcription_result.transcription,
                    template_variables=template_variables,
                    diarization_data=diarization_data_raw,
                    diarization_analysis=diarization_analysis,
                    openai_model_key=openai_model_key,
                    speaker_mapping=request.speaker_mapping,
                    meeting_topic=request.meeting_topic,
                    meeting_date=request.meeting_date,
                    meeting_time=request.meeting_time
                )
            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                llm_task_id = f"llm_{request.user_id}_{int(time.time())}"
                
                llm_result = await task_pool.submit_task(
                    llm_task_id,
                    self._generate_llm_response,
                    transcription_result,
                    template,
                    template_variables,
                    request.llm_provider,
                    openai_model_key,
                    request.speaker_mapping,
                    request.meeting_topic,
                    request.meeting_date,
                    request.meeting_time,
                    request.participants_list
                )
                
                if not llm_result.success:
                    raise ProcessingError(f"–û—à–∏–±–∫–∞ LLM: {llm_result.error}", 
                                        request.file_name, "llm")
                
                llm_result_data = llm_result.result
            
            processing_metrics.llm_duration = time.time() - start_time
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
            if settings.enable_protocol_validation:
                logger.info("–ó–∞–ø—É—Å–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
                
                validation_result = protocol_validator.calculate_quality_score(
                    protocol=llm_result_data,
                    transcription=transcription_result.transcription,
                    template_variables=template_variables,
                    diarization_data=getattr(transcription_result, 'diarization', None)
                )
                
                logger.info(
                    f"–í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ {validation_result.overall_score}, "
                    f"–ø–æ–ª–Ω–æ—Ç–∞ {validation_result.completeness_score}, "
                    f"—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ {validation_result.structure_score}"
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –º–µ—Ç—Ä–∏–∫–∏
                processing_metrics.protocol_quality_score = validation_result.overall_score
                
                # –ï—Å–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∏–∑–∫–æ–µ, –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
                if validation_result.overall_score < 0.7:
                    logger.warning(
                        f"–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ ({validation_result.overall_score}). "
                        f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {validation_result.warnings}"
                    )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
                llm_result_data['_validation'] = validation_result.to_dict()
            
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        await performance_cache.set(cache_key, llm_result_data, cache_type="llm_response")
        
        return llm_result_data
    
    def _get_template_variables_from_template(self, template) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ—á—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —à–∞–±–ª–æ–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
            if hasattr(template, 'content'):
                template_content = template.content
            elif isinstance(template, dict):
                template_content = template.get('content', '')
            else:
                template_content = str(template)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ —à–∞–±–ª–æ–Ω–∞
            variables_list = self.template_service.extract_template_variables(template_content)
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–Ω–∞–∑–≤–∞–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–∞–∫ –∫–ª—é—á–∏ –∏ –∑–Ω–∞—á–µ–Ω–∏—è)
            template_variables = {}
            for var in variables_list:
                template_variables[var] = var  # LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä –æ–∂–∏–¥–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ —à–∞–±–ª–æ–Ω–∞: {list(template_variables.keys())}")
            return template_variables
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ —à–∞–±–ª–æ–Ω–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π –Ω–∞–±–æ—Ä –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–∞–∫ fallback
            return self._get_template_variables()

    async def _generate_llm_response(self, transcription_result, template,
                                   template_variables, llm_provider, openai_model_key=None, speaker_mapping=None,
                                   meeting_topic=None, meeting_date=None, meeting_time=None, participants=None):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ LLM —Å –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        llm_result = await self.llm_service.generate_protocol_with_fallback(
            llm_provider, transcription_result.transcription, template_variables,
            transcription_result.diarization if hasattr(transcription_result, 'diarization') else None,
            openai_model_key=openai_model_key,
            speaker_mapping=speaker_mapping,
            meeting_topic=meeting_topic,
            meeting_date=meeting_date,
            meeting_time=meeting_time,
            participants=participants
        )
        
        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        return self._post_process_llm_result(llm_result)
    
    def _post_process_llm_result(self, llm_result: Dict[str, Any]) -> Dict[str, Any]:
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ LLM –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö"""
        if not isinstance(llm_result, dict):
            return llm_result
            
        processed_result = {}
        
        for key, value in llm_result.items():
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–∂–Ω—ã–µ —Ç–∏–ø—ã (dict, list) –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
            processed_value = self._convert_complex_to_markdown(value)
            processed_result[key] = processed_value
        
        return processed_result
    
    def _convert_complex_to_markdown(self, value: Any) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ —Ç–∏–ø—ã (dict, list) –≤ —á–∏—Ç–∞–µ–º—ã–π Markdown-—Ç–µ–∫—Å—Ç"""
        
        # –ï—Å–ª–∏ —É–∂–µ —Å—Ç—Ä–æ–∫–∞ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ JSON –≤–Ω—É—Ç—Ä–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
        if isinstance(value, str):
            return self._fix_json_in_text(value)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º dict –≤ —Ç–µ–∫—Å—Ç
        if isinstance(value, dict):
            return self._format_dict_to_text(value)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º list –≤ —Ç–µ–∫—Å—Ç
        if isinstance(value, list):
            return self._format_list_to_text(value)
        
        # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤ - –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        return str(value)
    
    def _format_dict_to_text(self, data: dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç"""
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏/–¥–∞—Ç—ã —Å milestones, constraints
        if 'constraints' in data or 'milestones' in data or 'meetings' in data:
            parts = []
            if 'constraints' in data:
                constraints = data['constraints']
                if isinstance(constraints, list):
                    parts.append("–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\n" + "\n".join([f"- {c}" for c in constraints]))
            if 'milestones' in data:
                milestones = data['milestones']
                if isinstance(milestones, list):
                    milestone_texts = []
                    for m in milestones:
                        if isinstance(m, dict):
                            date = m.get('date', '')
                            event = m.get('event', '')
                            milestone_texts.append(f"- {date}: {event}")
                        else:
                            milestone_texts.append(f"- {m}")
                    parts.append("–í–∞–∂–Ω—ã–µ –¥–∞—Ç—ã:\n" + "\n".join(milestone_texts))
            if 'meetings' in data:
                meetings = data['meetings']
                if isinstance(meetings, list):
                    meeting_texts = []
                    for m in meetings:
                        if isinstance(m, dict):
                            slot = m.get('slot', '')
                            event = m.get('event', '')
                            meeting_texts.append(f"- {slot}: {event}")
                        else:
                            meeting_texts.append(f"- {m}")
                    parts.append("–í—Å—Ç—Ä–µ—á–∏:\n" + "\n".join(meeting_texts))
            return "\n\n".join(parts) if parts else "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —É—á–∞—Å—Ç–Ω–∏–∫–∞ —Å name –∏ role
        if 'name' in data and 'role' in data:
            name = data.get('name', '')
            role = data.get('role', '')
            notes = data.get('notes', '')
            if notes:
                return f"{name} ({role}): {notes}"
            return f"{name} ({role})" if role else name
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è —Å decision
        if 'decision' in data:
            decision = data.get('decision', '')
            decision_maker = data.get('decision_maker', '')
            if decision_maker and decision_maker != '–ù–µ —É–∫–∞–∑–∞–Ω–æ':
                return f"- {decision} (—Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—è–ª: {decision_maker})"
            return f"- {decision}"
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–¥–∞—á–∏ —Å item
        if 'item' in data or 'task' in data:
            item = data.get('item', data.get('task', ''))
            assignee = data.get('assignee', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
            due = data.get('due', '')
            if due:
                return f"- {item} ‚Äî –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: {assignee}, —Å—Ä–æ–∫: {due}"
            return f"- {item} ‚Äî –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π: {assignee}"
        
        # –û–±—â–∏–π —Å–ª—É—á–∞–π - key: value –ø–∞—Ä—ã
        lines = []
        for k, v in data.items():
            if isinstance(v, (dict, list)):
                v_str = self._convert_complex_to_markdown(v)
                lines.append(f"**{k}:** {v_str}")
            else:
                lines.append(f"**{k}:** {v}")
        return "\n".join(lines) if lines else "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
    
    def _format_list_to_text(self, data: list) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç"""
        if not data:
            return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        first = data[0]
        
        # –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π
        if isinstance(first, dict):
            items = []
            for item in data:
                formatted = self._format_dict_to_text(item)
                # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–∂–µ —Å –¥–µ—Ñ–∏—Å–æ–º, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –µ—â–µ –æ–¥–∏–Ω
                if formatted.strip().startswith('-'):
                    items.append(formatted.strip())
                else:
                    items.append(f"- {formatted}")
            return "\n".join(items)
        
        # –°–ø–∏—Å–æ–∫ –ø—Ä–æ—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        return "\n".join([f"- {item}" for item in data])
    
    def _fix_json_in_text(self, text: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤ —Ç–µ–∫—Å—Ç–µ, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –∏—Ö –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        import json
        import re
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ JSON-–æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
        json_pattern = r'\{[^{}]*\}'
        
        def replace_json_object(match):
            json_str = match.group(0)
            try:
                json_obj = json.loads(json_str)
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º JSON-–æ–±—ä–µ–∫—Ç –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
                if isinstance(json_obj, dict):
                    if 'decision' in json_obj:
                        # –≠—Ç–æ –æ–±—ä–µ–∫—Ç —Ä–µ—à–µ–Ω–∏—è
                        decision = json_obj.get('decision', '')
                        decision_maker = json_obj.get('decision_maker', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
                        return f"‚Ä¢ {decision} (—Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—è–ª: {decision_maker})"
                    elif 'item' in json_obj:
                        # –≠—Ç–æ –æ–±—ä–µ–∫—Ç –¥–µ–π—Å—Ç–≤–∏—è
                        item = json_obj.get('item', '')
                        assignee = json_obj.get('assignee', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
                        due = json_obj.get('due', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
                        status = json_obj.get('status', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
                        return f"‚Ä¢ {item} - {assignee}, –¥–æ {due}"
                    else:
                        # –û–±—â–∏–π —Å–ª—É—á–∞–π - –ø—Ä–æ—Å—Ç–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
                        values = [str(v) for v in json_obj.values() if v != '–ù–µ —É–∫–∞–∑–∞–Ω–æ']
                        return ' - '.join(values) if values else '–ù–µ —É–∫–∞–∑–∞–Ω–æ'
                        
            except (json.JSONDecodeError, TypeError):
                # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –≤–∞–ª–∏–¥–Ω—ã–π JSON, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                pass
                
            return json_str
        
        # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ JSON-–æ–±—ä–µ–∫—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ
        result = re.sub(json_pattern, replace_json_object, text)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: —É–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∑–∞–ø—è—Ç—ã–µ –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ —Å–ø–∏—Å–∫–∞
        result = re.sub(r'},\s*\{', '\n', result)
        result = re.sub(r'^\s*,\s*', '', result, flags=re.MULTILINE)
        
        return result
    
    async def _calculate_file_hash(self, file_path: str) -> str:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —Ö—ç—à —Ñ–∞–π–ª–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        import hashlib
        
        hash_obj = hashlib.sha256()
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —á–∞—Å—Ç—è–º–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
        async with aiofiles.open(file_path, 'rb') as f:
            while chunk := await f.read(8192):
                hash_obj.update(chunk)
        
        return hash_obj.hexdigest()[:16]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 16 —Å–∏–º–≤–æ–ª–æ–≤
    
    async def _cleanup_temp_file(self, file_path: str):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        try:
            await asyncio.sleep(1)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
            if os.path.exists(file_path):
                os.remove(file_path)
                logger.debug(f"–£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {file_path}: {e}")
    
    def _generate_result_cache_key(self, request: ProcessingRequest) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        # –í–∫–ª—é—á–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        key_data = {
            "file_id": request.file_id if not request.is_external_file else None,
            "file_path": request.file_path if request.is_external_file else None,
            "file_name": request.file_name,  # –î–æ–±–∞–≤–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
            "template_id": request.template_id,
            "llm_provider": request.llm_provider,
            "language": request.language,
            "is_external_file": request.is_external_file
        }
        return performance_cache._generate_key("full_result", key_data)
    
    def _format_protocol(self, template: Any, llm_result: Any, 
                        transcription_result: Any) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Å –º—è–≥–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ç–∏–ø–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ LLM"""
        from jinja2 import Template as Jinja2Template
        
        # –ï—Å–ª–∏ LLM –≤–µ—Ä–Ω—É–ª —Å—Ç—Ä–æ–∫—É ‚Äî —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –≥–æ—Ç–æ–≤—ã–º —Ç–µ–∫—Å—Ç–æ–º –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
        if isinstance(llm_result, str):
            text = llm_result.strip()
            if text:
                return text
            # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –ø–∞–¥–∞–µ–º –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç
            return f"# –ü—Ä–æ—Ç–æ–∫–æ–ª\n\n{transcription_result.transcription}"
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —à–∞–±–ª–æ–Ω–∞
        if hasattr(template, 'content'):
            template_content = template.content
        elif isinstance(template, dict):
            template_content = template.get('content', '')
        else:
            template_content = str(template)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –º–∞–ø–ø–∏–Ω–≥ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º Jinja2 –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏
        try:
            if isinstance(llm_result, dict):
                jinja_template = Jinja2Template(template_content)
                return jinja_template.render(**llm_result)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ Jinja –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: {e}")
        
        # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        return f"# –ü—Ä–æ—Ç–æ–∫–æ–ª\n\n{transcription_result.transcription}"
    
    async def get_performance_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        cache_stats = performance_cache.get_stats()
        metrics_stats = metrics_collector.get_current_stats()
        task_pool_stats = task_pool.get_stats()
        
        return {
            "cache": cache_stats,
            "metrics": metrics_stats,
            "task_pool": task_pool_stats,
            "optimizations": {
                "transcription_cache_enabled": True,
                "llm_cache_enabled": True,
                "parallel_processing": True,
                "async_file_operations": True,
                "connection_pooling": True
            }
        }
    
    async def optimize_cache(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫—ç—à–∞"""
        # –û—á–∏—â–∞–µ–º –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        await performance_cache.cleanup_expired()
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = performance_cache.get_stats()
        logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞: hit_rate={stats['hit_rate_percent']}%, "
                   f"memory={stats['memory_usage_mb']}MB, "
                   f"entries={stats['memory_entries']+stats['disk_entries']}")
    
    async def _ensure_monitoring_started(self):
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        if not self._monitoring_started:
            try:
                if not metrics_collector.is_monitoring:
                    metrics_collector.start_monitoring()
                    
                if not memory_optimizer.is_optimizing:
                    memory_optimizer.start_optimization()
                    
                self._monitoring_started = True
                logger.info("–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—É—â–µ–Ω")
                
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: {e}")
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –±–µ–∑ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    
    def get_reliability_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            stats = {
                "performance_cache": {
                    "stats": performance_cache.get_stats() if hasattr(performance_cache, 'get_stats') else {}
                },
                "metrics": {
                    "collected": True if hasattr(metrics_collector, 'get_stats') else False
                },
                "thread_manager": {
                    "active": True if thread_manager else False
                },
                "optimizations": {
                    "async_enabled": True,
                    "cache_enabled": True,
                    "thread_pool_enabled": True
                }
            }
            
            return stats
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏: {e}")
            return {"error": str(e), "status": "error"}


# –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
class OptimizedServiceFactory:
    """–§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤"""
    
    @staticmethod
    def create_processing_service() -> OptimizedProcessingService:
        """–°–æ–∑–¥–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        return OptimizedProcessingService()
    
    @staticmethod
    async def create_with_prewarming() -> OptimizedProcessingService:
        """–°–æ–∑–¥–∞—Ç—å —Å–µ—Ä–≤–∏—Å —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–µ–≤–æ–º"""
        service = OptimizedProcessingService()
        
        # –ü—Ä–æ–≥—Ä–µ–≤–∞–µ–º –∫—ç—à –∏ —Å–∏—Å—Ç–µ–º—ã
        await service._prewarm_systems()
        
        return service
    
    async def _prewarm_systems(self):
        """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ–≤ —Å–∏—Å—Ç–µ–º"""
        logger.info("–ü—Ä–æ–≥—Ä–µ–≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º...")
        
        # –ü—Ä–æ–≥—Ä–µ–≤–∞–µ–º HTTP –∫–ª–∏–µ–Ω—Ç
        async with OptimizedHTTPClient() as client:
            pass
        
        # –ü—Ä–æ–≥—Ä–µ–≤–∞–µ–º thread pool
        await thread_manager.run_in_thread(lambda: True)
        
        logger.info("–°–∏—Å—Ç–µ–º—ã –ø—Ä–æ–≥—Ä–µ—Ç—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞–±–æ—Ç–µ")
